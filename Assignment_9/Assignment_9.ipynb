{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Problem statement: https://ovgu-ailab.github.io/idl2020w/ass9.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zinTw4wlnRFN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Activation,Dense, Flatten, MaxPooling2D, Dropout, Conv2D\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRJ6_J7Fn7HY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Load CIFAR Data set.\n",
        "cifar10 = tf.keras.datasets.cifar10 # tf.keras.datasets.cifar10.load_data()\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(train_images[0].shape)\n",
        "\n",
        "input_shape = train_images[0].shape\n",
        "#show the first image.\n",
        "plt.imshow(train_images[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEi3R6ZdoE6l",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, train_labels.reshape(-1,).astype(np.int32)))\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, test_labels.reshape(-1,).astype(np.int32)))\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJmTJ8abr7J-",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(32,32)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqRjg5P_uyPh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def get_model(units_in_layer,num_classes):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(32, 32,3)))\n",
        "\n",
        "  for idx , units in enumerate(units_in_layer):\n",
        "    model.add(tf.keras.layers.Dense(units=units))\n",
        "  else:\n",
        "    model.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gxqMFvwTn5U",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def Genreate_CNN_Arch(conv_layers,dense_layers,num_classes,lastlayeractivation='softmax'):\n",
        "  model = Sequential()\n",
        "\n",
        "  for idx in range(len(conv_layers)):\n",
        "    layer = conv_layers[idx]\n",
        "    if idx == 0:\n",
        "      print(\"Adding layer\",idx)\n",
        "      model.add(Conv2D(layer[0],(layer[1],layer[1]),strides=(layer[2],layer[2]),padding=layer[3],activation=layer[4],input_shape=(32,32,3)))\n",
        "      model.add(MaxPooling2D(pool_size=(layer[5],layer[5]),strides=(layer[6],layer[6]),padding=layer[7]))\n",
        "    else:\n",
        "      print(\"Adding Next layer\",idx)\n",
        "      model.add(Conv2D(layer[0],(layer[1],layer[1]),strides=(layer[2],layer[2]),padding=layer[3],activation=layer[4]))\n",
        "      model.add(MaxPooling2D(pool_size=(layer[5],layer[5]),strides=(layer[6],layer[6]),padding=layer[7]))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Add Denselayer\n",
        "  for idx in range(len(dense_layers)):\n",
        "    layer = dense_layers[idx]\n",
        "    model.add(Dense(units=layer[0],activation=layer[1]))\n",
        "\n",
        "  #output layer.\n",
        "  model.add(Dense(num_classes,activation=lastlayeractivation ))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pju-KWX7K9i",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#@tf.function\n",
        "def train_adversarial_models(model,epochs,data,epsilon,norm):\n",
        "  for epoch in range(epochs):\n",
        "    print(\"Epoch: {}\".format(epoch))\n",
        "    for step, (img_batch,lbl_batch) in enumerate(data):\n",
        "      with tf.GradientTape(persistent=True) as tape:\n",
        "        tape.watch(img_batch)\n",
        "        logits = model(img_batch)\n",
        "        xent = loss_fn(lbl_batch,logits)\n",
        "\n",
        "      input_grads = tape.gradient(xent,img_batch)\n",
        "      grads = tape.gradient(xent,model.trainable_variables)\n",
        "      #print(\"grads: \",grads)\n",
        "      optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
        "\n",
        "      adveserial_img_batch = img_batch + (epsilon * normalize_input_grads(input_grads,norm))\n",
        "\n",
        "      adveserial_img_batch = tf.stop_gradient(adveserial_img_batch)\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        adv_logits = model(adveserial_img_batch)\n",
        "        adv_xent = loss_fn(lbl_batch,adv_logits)\n",
        "        \n",
        "      adv_grads = tape.gradient(adv_xent,model.trainable_variables)\n",
        "      #print(\"adv_grads: \",adv_grads)\n",
        "      optimizer.apply_gradients(zip(adv_grads,model.trainable_variables))\n",
        "\n",
        "\n",
        "      if not step % 100:\n",
        "        print(\"original Loss : {} and Adversarial Loss: {}\".format(xent,adv_xent))\n",
        "\n",
        "def normalize_input_grads(inputs,type='sign'):\n",
        "  if type == 'norm':\n",
        "    inputs /= tf.norm(inputs)\n",
        "  elif type == 'sign':\n",
        "    inputs = tf.sign(inputs)\n",
        "\n",
        "  return inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEDUGZkwtfqU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def test_adv_Net(model,test_data,epsilon=0.01):\n",
        "  \n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  model.compile(optimizer=optimizer,loss=loss_fn,metrics='accuracy')\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  count = 0\n",
        "  for (img_batch,lbl_batch) in test_data:\n",
        "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "      tape.watch(img_batch)\n",
        "      logits = model(img_batch)\n",
        "      xent = loss_fn(lbl_batch,logits)\n",
        "\n",
        "    inupt_grads = tape.gradient(xent,img_batch)\n",
        "\n",
        "    adv_test_data = img_batch + epsilon * normalize_input_grads(inupt_grads)\n",
        "    test_loss, test_accuracy = model.evaluate(adv_test_data, lbl_batch)\n",
        "    \n",
        "    total_loss += test_loss\n",
        "\n",
        "    total_acc += test_accuracy\n",
        "    count += 1\n",
        "\n",
        "  return total_loss/count, total_acc/count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWnlCXK036HA",
        "outputId": "d94bee77-f784-48e5-e3f7-8aec619cebd2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding layer 0\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 14400)             0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               1843328   \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,846,410\n",
            "Trainable params: 1,846,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch: 0\n",
            "original Loss : 2.2978782653808594 and Adversarial Loss: 9.568439483642578\n",
            "original Loss : 1.684030294418335 and Adversarial Loss: 1.6373658180236816\n",
            "original Loss : 1.587348461151123 and Adversarial Loss: 1.527218222618103\n",
            "original Loss : 1.6619020700454712 and Adversarial Loss: 1.54823637008667\n",
            "Epoch: 1\n",
            "original Loss : 1.5710200071334839 and Adversarial Loss: 1.485487937927246\n",
            "original Loss : 1.4467909336090088 and Adversarial Loss: 1.4104738235473633\n",
            "original Loss : 1.435173749923706 and Adversarial Loss: 1.3669812679290771\n",
            "original Loss : 1.3110218048095703 and Adversarial Loss: 1.259621024131775\n",
            "Epoch: 2\n",
            "original Loss : 1.2332634925842285 and Adversarial Loss: 1.2106338739395142\n",
            "original Loss : 1.2868010997772217 and Adversarial Loss: 1.2516560554504395\n",
            "original Loss : 1.4465781450271606 and Adversarial Loss: 1.3840479850769043\n",
            "original Loss : 1.33914053440094 and Adversarial Loss: 1.2769144773483276\n",
            "Epoch: 3\n",
            "original Loss : 1.1318223476409912 and Adversarial Loss: 1.10939621925354\n",
            "original Loss : 1.2171928882598877 and Adversarial Loss: 1.1500067710876465\n",
            "original Loss : 1.0599002838134766 and Adversarial Loss: 0.9932960271835327\n",
            "original Loss : 1.3664724826812744 and Adversarial Loss: 1.2621431350708008\n",
            "Epoch: 4\n",
            "original Loss : 1.229156732559204 and Adversarial Loss: 1.1538410186767578\n",
            "original Loss : 0.9670147895812988 and Adversarial Loss: 0.9053432941436768\n",
            "original Loss : 1.0051932334899902 and Adversarial Loss: 0.9529798030853271\n",
            "original Loss : 1.3568388223648071 and Adversarial Loss: 1.270646333694458\n",
            "Epoch: 5\n",
            "original Loss : 1.108755111694336 and Adversarial Loss: 1.0044550895690918\n",
            "original Loss : 0.9576592445373535 and Adversarial Loss: 0.8889502882957458\n",
            "original Loss : 1.0155563354492188 and Adversarial Loss: 0.9249856472015381\n",
            "original Loss : 1.2554728984832764 and Adversarial Loss: 1.211989402770996\n",
            "Epoch: 6\n",
            "original Loss : 0.9449563026428223 and Adversarial Loss: 0.8955135941505432\n",
            "original Loss : 0.8145918846130371 and Adversarial Loss: 0.8016588687896729\n",
            "original Loss : 1.0023378133773804 and Adversarial Loss: 0.9253109693527222\n",
            "original Loss : 0.9492751359939575 and Adversarial Loss: 0.8997226357460022\n",
            "Epoch: 7\n",
            "original Loss : 0.9382302761077881 and Adversarial Loss: 0.8922853469848633\n",
            "original Loss : 0.9574826955795288 and Adversarial Loss: 0.7747510671615601\n",
            "original Loss : 0.9875873923301697 and Adversarial Loss: 0.976355791091919\n",
            "original Loss : 0.8638253211975098 and Adversarial Loss: 0.8112922310829163\n",
            "Epoch: 8\n",
            "original Loss : 0.8512744903564453 and Adversarial Loss: 0.725570559501648\n",
            "original Loss : 0.8617415428161621 and Adversarial Loss: 0.7825833559036255\n",
            "original Loss : 0.8471497893333435 and Adversarial Loss: 0.8154017925262451\n",
            "original Loss : 0.75051349401474 and Adversarial Loss: 0.7390705347061157\n",
            "Epoch: 9\n",
            "original Loss : 0.7958948016166687 and Adversarial Loss: 0.7285071611404419\n",
            "original Loss : 0.7924067974090576 and Adversarial Loss: 0.7762534022331238\n",
            "original Loss : 0.8369114398956299 and Adversarial Loss: 0.6933563351631165\n",
            "original Loss : 1.0862637758255005 and Adversarial Loss: 0.9668983817100525\n",
            "Epoch: 10\n",
            "original Loss : 0.8172092437744141 and Adversarial Loss: 0.7663918137550354\n",
            "original Loss : 0.7869749069213867 and Adversarial Loss: 0.7395274639129639\n",
            "original Loss : 0.8837060928344727 and Adversarial Loss: 0.7389499545097351\n",
            "original Loss : 0.6641948223114014 and Adversarial Loss: 0.6205464005470276\n",
            "Epoch: 11\n",
            "original Loss : 0.5737464427947998 and Adversarial Loss: 0.5391279458999634\n",
            "original Loss : 0.7467021942138672 and Adversarial Loss: 0.591425895690918\n",
            "original Loss : 0.6544659733772278 and Adversarial Loss: 0.6204328536987305\n",
            "original Loss : 0.6819491982460022 and Adversarial Loss: 0.680452823638916\n",
            "Epoch: 12\n",
            "original Loss : 0.7982056140899658 and Adversarial Loss: 0.7220941185951233\n",
            "original Loss : 1.0024596452713013 and Adversarial Loss: 0.8026741743087769\n",
            "original Loss : 0.6467574834823608 and Adversarial Loss: 0.5781140923500061\n",
            "original Loss : 0.7027528285980225 and Adversarial Loss: 0.65102618932724\n",
            "Epoch: 13\n",
            "original Loss : 0.592793345451355 and Adversarial Loss: 0.5814273357391357\n",
            "original Loss : 0.5997881889343262 and Adversarial Loss: 0.5053302049636841\n",
            "original Loss : 0.6129403114318848 and Adversarial Loss: 0.5914828181266785\n",
            "original Loss : 0.6352910995483398 and Adversarial Loss: 0.5784417390823364\n",
            "Epoch: 14\n",
            "original Loss : 0.6243108510971069 and Adversarial Loss: 0.5754284858703613\n",
            "original Loss : 0.616619348526001 and Adversarial Loss: 0.5571011900901794\n",
            "original Loss : 0.6776335835456848 and Adversarial Loss: 0.6180735230445862\n",
            "original Loss : 0.7854578495025635 and Adversarial Loss: 0.7690844535827637\n",
            "Epoch: 15\n",
            "original Loss : 0.7438372373580933 and Adversarial Loss: 0.7331076264381409\n",
            "original Loss : 0.6138380169868469 and Adversarial Loss: 0.5302764177322388\n",
            "original Loss : 0.7983659505844116 and Adversarial Loss: 0.6960906386375427\n",
            "original Loss : 0.5121806263923645 and Adversarial Loss: 0.47920751571655273\n",
            "Epoch: 16\n",
            "original Loss : 0.6546441316604614 and Adversarial Loss: 0.5467066764831543\n",
            "original Loss : 0.6655631065368652 and Adversarial Loss: 0.5500729084014893\n",
            "original Loss : 0.6061577200889587 and Adversarial Loss: 0.5179821848869324\n",
            "original Loss : 0.775759756565094 and Adversarial Loss: 0.6759153604507446\n",
            "Epoch: 17\n",
            "original Loss : 0.5400055050849915 and Adversarial Loss: 0.4621313512325287\n",
            "original Loss : 0.47042056918144226 and Adversarial Loss: 0.44014984369277954\n",
            "original Loss : 0.6369946599006653 and Adversarial Loss: 0.5109042525291443\n",
            "original Loss : 0.6946172714233398 and Adversarial Loss: 0.620013415813446\n",
            "Epoch: 18\n",
            "original Loss : 0.5980991721153259 and Adversarial Loss: 0.5792412161827087\n",
            "original Loss : 0.5915031433105469 and Adversarial Loss: 0.5159949064254761\n",
            "original Loss : 0.5373989343643188 and Adversarial Loss: 0.4635847210884094\n",
            "original Loss : 0.6741800308227539 and Adversarial Loss: 0.4068042039871216\n",
            "Epoch: 19\n",
            "original Loss : 0.4449045658111572 and Adversarial Loss: 0.418979674577713\n",
            "original Loss : 0.5887052416801453 and Adversarial Loss: 0.46204328536987305\n",
            "original Loss : 0.7186864614486694 and Adversarial Loss: 0.6061468124389648\n",
            "original Loss : 0.7281209230422974 and Adversarial Loss: 0.5418235063552856\n",
            "Epoch: 20\n",
            "original Loss : 0.6223711371421814 and Adversarial Loss: 0.5320590138435364\n",
            "original Loss : 0.4992588460445404 and Adversarial Loss: 0.4696890711784363\n",
            "original Loss : 0.510777473449707 and Adversarial Loss: 0.41147714853286743\n",
            "original Loss : 0.5506974458694458 and Adversarial Loss: 0.39782261848449707\n",
            "Epoch: 21\n",
            "original Loss : 0.440902978181839 and Adversarial Loss: 0.3980167508125305\n",
            "original Loss : 0.46324047446250916 and Adversarial Loss: 0.4141561985015869\n",
            "original Loss : 0.453359454870224 and Adversarial Loss: 0.3375021815299988\n",
            "original Loss : 0.7764564752578735 and Adversarial Loss: 0.5355366468429565\n",
            "Epoch: 22\n",
            "original Loss : 0.6497330665588379 and Adversarial Loss: 0.5335719585418701\n",
            "original Loss : 0.49341440200805664 and Adversarial Loss: 0.45216697454452515\n",
            "original Loss : 0.6560760736465454 and Adversarial Loss: 0.5230097770690918\n",
            "original Loss : 0.5320785045623779 and Adversarial Loss: 0.4809722900390625\n",
            "Epoch: 23\n",
            "original Loss : 0.35242989659309387 and Adversarial Loss: 0.2821468114852905\n",
            "original Loss : 0.39978355169296265 and Adversarial Loss: 0.34559696912765503\n",
            "original Loss : 0.6641771197319031 and Adversarial Loss: 0.5182085037231445\n",
            "original Loss : 0.588127613067627 and Adversarial Loss: 0.495339572429657\n",
            "Epoch: 24\n",
            "original Loss : 0.4895470440387726 and Adversarial Loss: 0.3864016830921173\n",
            "original Loss : 0.49297574162483215 and Adversarial Loss: 0.43864375352859497\n",
            "original Loss : 0.6601052284240723 and Adversarial Loss: 0.4843776226043701\n",
            "original Loss : 0.6327056884765625 and Adversarial Loss: 0.47235822677612305\n",
            "Epoch: 25\n",
            "original Loss : 0.5507490038871765 and Adversarial Loss: 0.5065010190010071\n",
            "original Loss : 0.2497517168521881 and Adversarial Loss: 0.2238786667585373\n",
            "original Loss : 0.43073636293411255 and Adversarial Loss: 0.3524593412876129\n",
            "original Loss : 0.4353257417678833 and Adversarial Loss: 0.3666043281555176\n",
            "Epoch: 26\n",
            "original Loss : 0.45856672525405884 and Adversarial Loss: 0.4346180558204651\n",
            "original Loss : 0.32661911845207214 and Adversarial Loss: 0.2717323899269104\n",
            "original Loss : 0.44772517681121826 and Adversarial Loss: 0.29766812920570374\n",
            "original Loss : 0.4445669949054718 and Adversarial Loss: 0.319169819355011\n",
            "Epoch: 27\n",
            "original Loss : 0.4220869541168213 and Adversarial Loss: 0.28411924839019775\n",
            "original Loss : 0.5021647810935974 and Adversarial Loss: 0.4324793219566345\n",
            "original Loss : 0.5639733076095581 and Adversarial Loss: 0.43160712718963623\n",
            "original Loss : 0.47059524059295654 and Adversarial Loss: 0.3881150782108307\n",
            "Epoch: 28\n",
            "original Loss : 0.676371157169342 and Adversarial Loss: 0.46332088112831116\n",
            "original Loss : 0.34669312834739685 and Adversarial Loss: 0.3455113172531128\n",
            "original Loss : 0.4839003384113312 and Adversarial Loss: 0.43419063091278076\n",
            "original Loss : 0.7014510631561279 and Adversarial Loss: 0.556684672832489\n",
            "Epoch: 29\n",
            "original Loss : 0.3284783363342285 and Adversarial Loss: 0.27914685010910034\n",
            "original Loss : 0.3011149764060974 and Adversarial Loss: 0.25879114866256714\n",
            "original Loss : 0.7133402824401855 and Adversarial Loss: 0.5720598101615906\n",
            "original Loss : 0.3742435574531555 and Adversarial Loss: 0.2985019385814667\n",
            "Epoch: 30\n",
            "original Loss : 0.2585519552230835 and Adversarial Loss: 0.23552416265010834\n",
            "original Loss : 0.35191887617111206 and Adversarial Loss: 0.3290397524833679\n",
            "original Loss : 0.3416082262992859 and Adversarial Loss: 0.3180462718009949\n",
            "original Loss : 0.3547021150588989 and Adversarial Loss: 0.2812030613422394\n",
            "Epoch: 31\n",
            "original Loss : 0.4563075304031372 and Adversarial Loss: 0.4124530553817749\n",
            "original Loss : 0.6764957904815674 and Adversarial Loss: 0.46779608726501465\n",
            "original Loss : 0.5248217582702637 and Adversarial Loss: 0.43021494150161743\n",
            "original Loss : 0.5998091697692871 and Adversarial Loss: 0.4575890600681305\n",
            "Epoch: 32\n",
            "original Loss : 0.5458141565322876 and Adversarial Loss: 0.37398263812065125\n",
            "original Loss : 0.23680470883846283 and Adversarial Loss: 0.21947385370731354\n",
            "original Loss : 0.4305804967880249 and Adversarial Loss: 0.3366938531398773\n",
            "original Loss : 0.7034196257591248 and Adversarial Loss: 0.5022789239883423\n",
            "Epoch: 33\n",
            "original Loss : 0.3616270124912262 and Adversarial Loss: 0.32973581552505493\n",
            "original Loss : 0.3576909005641937 and Adversarial Loss: 0.3135193884372711\n",
            "original Loss : 0.4944504499435425 and Adversarial Loss: 0.43656665086746216\n",
            "original Loss : 0.2789912819862366 and Adversarial Loss: 0.25716227293014526\n",
            "Epoch: 34\n",
            "original Loss : 0.25215479731559753 and Adversarial Loss: 0.22733548283576965\n",
            "original Loss : 0.40517911314964294 and Adversarial Loss: 0.3883543014526367\n",
            "original Loss : 0.5840194225311279 and Adversarial Loss: 0.46331357955932617\n",
            "original Loss : 0.5560163259506226 and Adversarial Loss: 0.33084991574287415\n",
            "Epoch: 35\n",
            "original Loss : 0.25855395197868347 and Adversarial Loss: 0.26351451873779297\n",
            "original Loss : 0.4664996266365051 and Adversarial Loss: 0.35491594672203064\n",
            "original Loss : 0.46288663148880005 and Adversarial Loss: 0.3888317942619324\n",
            "original Loss : 0.41396084427833557 and Adversarial Loss: 0.39186155796051025\n",
            "Epoch: 36\n",
            "original Loss : 0.41714560985565186 and Adversarial Loss: 0.35972273349761963\n",
            "original Loss : 0.3603334426879883 and Adversarial Loss: 0.2771516442298889\n",
            "original Loss : 0.2037864625453949 and Adversarial Loss: 0.18853041529655457\n",
            "original Loss : 0.4780200719833374 and Adversarial Loss: 0.34990623593330383\n",
            "Epoch: 37\n",
            "original Loss : 0.4529786705970764 and Adversarial Loss: 0.3878576159477234\n",
            "original Loss : 0.3885551691055298 and Adversarial Loss: 0.3450905978679657\n",
            "original Loss : 0.49971267580986023 and Adversarial Loss: 0.38092124462127686\n",
            "original Loss : 0.4816581904888153 and Adversarial Loss: 0.34140533208847046\n",
            "Epoch: 38\n",
            "original Loss : 0.557771623134613 and Adversarial Loss: 0.3492167592048645\n",
            "original Loss : 0.3072544038295746 and Adversarial Loss: 0.2644927203655243\n",
            "original Loss : 0.3160272538661957 and Adversarial Loss: 0.2932577431201935\n",
            "original Loss : 0.37633877992630005 and Adversarial Loss: 0.3351293206214905\n",
            "Epoch: 39\n",
            "original Loss : 0.35260406136512756 and Adversarial Loss: 0.25137752294540405\n",
            "original Loss : 0.2600594162940979 and Adversarial Loss: 0.20596429705619812\n",
            "original Loss : 0.3695625066757202 and Adversarial Loss: 0.2563275694847107\n",
            "original Loss : 0.40817421674728394 and Adversarial Loss: 0.359127938747406\n",
            "Epoch: 40\n",
            "original Loss : 0.34339261054992676 and Adversarial Loss: 0.260039746761322\n",
            "original Loss : 0.4667315185070038 and Adversarial Loss: 0.4416182339191437\n",
            "original Loss : 0.6101210713386536 and Adversarial Loss: 0.41177231073379517\n",
            "original Loss : 0.4215504825115204 and Adversarial Loss: 0.31947416067123413\n",
            "Epoch: 41\n",
            "original Loss : 0.48727983236312866 and Adversarial Loss: 0.42748627066612244\n",
            "original Loss : 0.3706303536891937 and Adversarial Loss: 0.36467692255973816\n",
            "original Loss : 0.4240304231643677 and Adversarial Loss: 0.2927429676055908\n",
            "original Loss : 0.5555112361907959 and Adversarial Loss: 0.42626893520355225\n",
            "Epoch: 42\n",
            "original Loss : 0.37561678886413574 and Adversarial Loss: 0.34785130620002747\n",
            "original Loss : 0.3045887351036072 and Adversarial Loss: 0.28469064831733704\n",
            "original Loss : 0.7445922493934631 and Adversarial Loss: 0.6010535359382629\n",
            "original Loss : 0.6089493036270142 and Adversarial Loss: 0.4035027325153351\n",
            "Epoch: 43\n",
            "original Loss : 0.42700955271720886 and Adversarial Loss: 0.3395637273788452\n",
            "original Loss : 0.36019307374954224 and Adversarial Loss: 0.3282858431339264\n",
            "original Loss : 0.26904550194740295 and Adversarial Loss: 0.2755110561847687\n",
            "original Loss : 0.36940523982048035 and Adversarial Loss: 0.32209011912345886\n",
            "Epoch: 44\n",
            "original Loss : 0.4753573536872864 and Adversarial Loss: 0.38891956210136414\n",
            "original Loss : 0.3658818304538727 and Adversarial Loss: 0.2579779326915741\n",
            "original Loss : 0.331055223941803 and Adversarial Loss: 0.26773369312286377\n",
            "original Loss : 0.34476029872894287 and Adversarial Loss: 0.3337342143058777\n",
            "Epoch: 45\n",
            "original Loss : 0.24345046281814575 and Adversarial Loss: 0.22076451778411865\n",
            "original Loss : 0.23612895607948303 and Adversarial Loss: 0.22724920511245728\n",
            "original Loss : 0.36299657821655273 and Adversarial Loss: 0.3010488450527191\n",
            "original Loss : 0.41109275817871094 and Adversarial Loss: 0.2983000576496124\n",
            "Epoch: 46\n",
            "original Loss : 0.17488527297973633 and Adversarial Loss: 0.1711934506893158\n",
            "original Loss : 0.49912285804748535 and Adversarial Loss: 0.4447731673717499\n",
            "original Loss : 0.2976834774017334 and Adversarial Loss: 0.24097444117069244\n",
            "original Loss : 0.3053053617477417 and Adversarial Loss: 0.29260489344596863\n",
            "Epoch: 47\n",
            "original Loss : 0.39464789628982544 and Adversarial Loss: 0.262665718793869\n",
            "original Loss : 0.22848674654960632 and Adversarial Loss: 0.21107792854309082\n",
            "original Loss : 0.36403048038482666 and Adversarial Loss: 0.2369627058506012\n",
            "original Loss : 0.41599059104919434 and Adversarial Loss: 0.23533008992671967\n",
            "Epoch: 48\n",
            "original Loss : 0.2980969250202179 and Adversarial Loss: 0.24603673815727234\n",
            "original Loss : 0.2628094553947449 and Adversarial Loss: 0.27085256576538086\n",
            "original Loss : 0.33906447887420654 and Adversarial Loss: 0.3186923861503601\n",
            "original Loss : 0.324911892414093 and Adversarial Loss: 0.29527151584625244\n",
            "Epoch: 49\n",
            "original Loss : 0.4627670645713806 and Adversarial Loss: 0.30896294116973877\n",
            "original Loss : 0.3499326705932617 and Adversarial Loss: 0.26791447401046753\n",
            "original Loss : 0.3490031361579895 and Adversarial Loss: 0.31623604893684387\n",
            "original Loss : 0.3954780697822571 and Adversarial Loss: 0.37514573335647583\n"
          ]
        }
      ],
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.optimizers.Adam(0.01)\n",
        "# number_of_filters, filter_size, convstride, convpadding, activation, max_pool_size, maxpoolstrides, maxpoolpadding.\n",
        "conv_layers = [[64,3,1,\"valid\",'relu',1,2,\"valid\"]]\n",
        "#number_of_units, activation function.\n",
        "dense_layers = [[128,'relu']]\n",
        "norm = 'norm'\n",
        "model_conv = Genreate_CNN_Arch(conv_layers,dense_layers,10)\n",
        "model_conv.summary()\n",
        "\n",
        "data = data.shuffle(50000).batch(128)\n",
        "epochs = 50\n",
        "epsilon = 0.01\n",
        "train_adversarial_models(model_conv,epochs,data,epsilon,norm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLrOmnqW8_Qp",
        "outputId": "cd70568f-8efb-405e-9815-51fa42700849",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 45.7730 - accuracy: 0.1823\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.8176 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 47.8987 - accuracy: 0.1562\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.5126 - accuracy: 0.1875\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.2210 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 39.2983 - accuracy: 0.1797\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 39.3045 - accuracy: 0.1562\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 50.8886 - accuracy: 0.1641\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 39.1715 - accuracy: 0.1797\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 53.7748 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 51.3297 - accuracy: 0.1406\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 48.4555 - accuracy: 0.1406\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 52.2681 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 46.5546 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 53.0036 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 39.3660 - accuracy: 0.1719\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 43.0027 - accuracy: 0.1641\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 37.9761 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 46.2989 - accuracy: 0.1406\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 50.3064 - accuracy: 0.1406\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 48.6472 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 48.7936 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 43.6629 - accuracy: 0.1562\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 45.3253 - accuracy: 0.1562\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 43.3458 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 38.6582 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 40.1468 - accuracy: 0.1719\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 46.7445 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 43.5125 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 46.1666 - accuracy: 0.1172\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 46.9510 - accuracy: 0.1406\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.4819 - accuracy: 0.1875\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 40.6261 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 46.3205 - accuracy: 0.1719\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 51.6248 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 41.7463 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 47.3037 - accuracy: 0.1797\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 46.1560 - accuracy: 0.1641\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 46.0324 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 40.7029 - accuracy: 0.1953\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 41.4265 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 51.7173 - accuracy: 0.1562\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 43.5281 - accuracy: 0.1641\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 53.4787 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 53.7274 - accuracy: 0.1719\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 43.6140 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.1501 - accuracy: 0.1562\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 42.0467 - accuracy: 0.1719\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 40.3645 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.4493 - accuracy: 0.1406\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 42.4445 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 43.2030 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 48.0721 - accuracy: 0.1172\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 42.9193 - accuracy: 0.1953\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.4480 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 52.6142 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 53.2309 - accuracy: 0.1172\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 40.3186 - accuracy: 0.1797\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 40.7199 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 44.6409 - accuracy: 0.1875\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 41.1689 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 50.7312 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 51.6187 - accuracy: 0.0938\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 45.3753 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.0293 - accuracy: 0.1562\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 45.3111 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 38.3162 - accuracy: 0.1875\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 45.1888 - accuracy: 0.1719\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 46.5117 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.6053 - accuracy: 0.1172\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 40.8500 - accuracy: 0.1641\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 46.1742 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 41.0640 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 43.5194 - accuracy: 0.1406\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 38.6890 - accuracy: 0.1562\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 48.9644 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 44.5743 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 42.9334 - accuracy: 0.1797\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 40.8806 - accuracy: 0.3125\n",
            "test_loss: 45.15069879459429 test_acc: 0.1473496835443038\n"
          ]
        }
      ],
      "source": [
        "test_data_b = test_data.shuffle(10000).batch(128)\n",
        "test_loss, test_acc = test_adv_Net(model_conv,test_data_b,epsilon)\n",
        "print(\"test_loss: {} test_acc: {}\".format(test_loss,test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmd3In4g-Evy",
        "outputId": "9d45a240-deeb-4bd5-a794-68532d684fbc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding layer 0\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 14400)             0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               1843328   \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,846,410\n",
            "Trainable params: 1,846,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch: 0\n",
            "original Loss : 2.344310760498047 and Adversarial Loss: 20.94800567626953\n",
            "original Loss : 1.8155416250228882 and Adversarial Loss: 2.0461058616638184\n",
            "original Loss : 1.649907112121582 and Adversarial Loss: 1.8321410417556763\n",
            "original Loss : 1.8717825412750244 and Adversarial Loss: 2.1576762199401855\n",
            "Epoch: 1\n",
            "original Loss : 1.5723259449005127 and Adversarial Loss: 1.8552130460739136\n",
            "original Loss : 1.6906896829605103 and Adversarial Loss: 2.0292043685913086\n",
            "original Loss : 1.642170786857605 and Adversarial Loss: 1.9798905849456787\n",
            "original Loss : 1.6037416458129883 and Adversarial Loss: 1.9164988994598389\n",
            "Epoch: 2\n",
            "original Loss : 1.6642534732818604 and Adversarial Loss: 1.9542038440704346\n",
            "original Loss : 1.493472695350647 and Adversarial Loss: 1.8416104316711426\n",
            "original Loss : 1.5820577144622803 and Adversarial Loss: 1.952224612236023\n",
            "original Loss : 1.4860429763793945 and Adversarial Loss: 1.8115028142929077\n",
            "Epoch: 3\n",
            "original Loss : 1.3349523544311523 and Adversarial Loss: 1.60958731174469\n",
            "original Loss : 1.485281229019165 and Adversarial Loss: 1.8441569805145264\n",
            "original Loss : 1.54871666431427 and Adversarial Loss: 1.947996973991394\n",
            "original Loss : 1.407476782798767 and Adversarial Loss: 1.8459069728851318\n",
            "Epoch: 4\n",
            "original Loss : 1.5674540996551514 and Adversarial Loss: 1.9039944410324097\n",
            "original Loss : 1.5503582954406738 and Adversarial Loss: 1.9495015144348145\n",
            "original Loss : 1.310158371925354 and Adversarial Loss: 1.6617380380630493\n",
            "original Loss : 1.4471888542175293 and Adversarial Loss: 1.8020389080047607\n",
            "Epoch: 5\n",
            "original Loss : 1.464336633682251 and Adversarial Loss: 1.926978588104248\n",
            "original Loss : 1.6588926315307617 and Adversarial Loss: 1.9972783327102661\n",
            "original Loss : 1.5346521139144897 and Adversarial Loss: 1.956590175628662\n",
            "original Loss : 1.4875595569610596 and Adversarial Loss: 1.8273745775222778\n",
            "Epoch: 6\n",
            "original Loss : 1.3875702619552612 and Adversarial Loss: 1.8328471183776855\n",
            "original Loss : 1.4437240362167358 and Adversarial Loss: 1.848703384399414\n",
            "original Loss : 1.5415501594543457 and Adversarial Loss: 1.9515633583068848\n",
            "original Loss : 1.5832233428955078 and Adversarial Loss: 1.9721810817718506\n",
            "Epoch: 7\n",
            "original Loss : 1.3370023965835571 and Adversarial Loss: 1.8101012706756592\n",
            "original Loss : 1.5117547512054443 and Adversarial Loss: 1.989412784576416\n",
            "original Loss : 1.4961135387420654 and Adversarial Loss: 1.927833080291748\n",
            "original Loss : 1.5396134853363037 and Adversarial Loss: 1.9192088842391968\n",
            "Epoch: 8\n",
            "original Loss : 1.2467397451400757 and Adversarial Loss: 1.619373083114624\n",
            "original Loss : 1.5079524517059326 and Adversarial Loss: 1.902576208114624\n",
            "original Loss : 1.5419615507125854 and Adversarial Loss: 2.0475621223449707\n",
            "original Loss : 1.5100367069244385 and Adversarial Loss: 1.9533320665359497\n",
            "Epoch: 9\n",
            "original Loss : 1.5486245155334473 and Adversarial Loss: 1.8545808792114258\n",
            "original Loss : 1.3025802373886108 and Adversarial Loss: 1.7203421592712402\n",
            "original Loss : 1.232269287109375 and Adversarial Loss: 1.7020237445831299\n",
            "original Loss : 1.4875681400299072 and Adversarial Loss: 1.8446776866912842\n",
            "Epoch: 10\n",
            "original Loss : 1.304219365119934 and Adversarial Loss: 1.6837551593780518\n",
            "original Loss : 1.3659460544586182 and Adversarial Loss: 1.7973463535308838\n",
            "original Loss : 1.3709962368011475 and Adversarial Loss: 1.8059909343719482\n",
            "original Loss : 1.3573248386383057 and Adversarial Loss: 1.8320791721343994\n",
            "Epoch: 11\n",
            "original Loss : 1.3045573234558105 and Adversarial Loss: 1.7534490823745728\n",
            "original Loss : 1.4046576023101807 and Adversarial Loss: 1.8440057039260864\n",
            "original Loss : 1.4336541891098022 and Adversarial Loss: 1.8615925312042236\n",
            "original Loss : 1.2575628757476807 and Adversarial Loss: 1.6659023761749268\n",
            "Epoch: 12\n",
            "original Loss : 1.263993501663208 and Adversarial Loss: 1.745025873184204\n",
            "original Loss : 1.352298617362976 and Adversarial Loss: 1.779520034790039\n",
            "original Loss : 1.3121336698532104 and Adversarial Loss: 1.689768671989441\n",
            "original Loss : 1.505408525466919 and Adversarial Loss: 1.886309266090393\n",
            "Epoch: 13\n",
            "original Loss : 1.4046039581298828 and Adversarial Loss: 1.9095314741134644\n",
            "original Loss : 1.3257668018341064 and Adversarial Loss: 1.7634568214416504\n",
            "original Loss : 1.3162938356399536 and Adversarial Loss: 1.8305425643920898\n",
            "original Loss : 1.4850107431411743 and Adversarial Loss: 1.8950693607330322\n",
            "Epoch: 14\n",
            "original Loss : 1.4130918979644775 and Adversarial Loss: 1.867199420928955\n",
            "original Loss : 1.4477722644805908 and Adversarial Loss: 1.8093520402908325\n",
            "original Loss : 1.3377275466918945 and Adversarial Loss: 1.830703616142273\n",
            "original Loss : 1.3758960962295532 and Adversarial Loss: 1.8541895151138306\n",
            "Epoch: 15\n",
            "original Loss : 1.5204012393951416 and Adversarial Loss: 1.9322752952575684\n",
            "original Loss : 1.4287835359573364 and Adversarial Loss: 2.0193285942077637\n",
            "original Loss : 1.5353515148162842 and Adversarial Loss: 2.096665382385254\n",
            "original Loss : 1.4237008094787598 and Adversarial Loss: 1.8722959756851196\n",
            "Epoch: 16\n",
            "original Loss : 1.5729820728302002 and Adversarial Loss: 2.0272762775421143\n",
            "original Loss : 1.2844979763031006 and Adversarial Loss: 1.8634439706802368\n",
            "original Loss : 1.2362735271453857 and Adversarial Loss: 1.721307396888733\n",
            "original Loss : 1.4643921852111816 and Adversarial Loss: 1.9899682998657227\n",
            "Epoch: 17\n",
            "original Loss : 1.6086937189102173 and Adversarial Loss: 2.090892791748047\n",
            "original Loss : 1.4470446109771729 and Adversarial Loss: 2.006248950958252\n",
            "original Loss : 1.1263625621795654 and Adversarial Loss: 1.5730936527252197\n",
            "original Loss : 1.3323062658309937 and Adversarial Loss: 1.8948578834533691\n",
            "Epoch: 18\n",
            "original Loss : 1.251395344734192 and Adversarial Loss: 1.7644245624542236\n",
            "original Loss : 1.7423365116119385 and Adversarial Loss: 2.264859676361084\n",
            "original Loss : 1.2991316318511963 and Adversarial Loss: 1.7724087238311768\n",
            "original Loss : 1.398470163345337 and Adversarial Loss: 1.9165667295455933\n",
            "Epoch: 19\n",
            "original Loss : 1.2834539413452148 and Adversarial Loss: 1.6900434494018555\n",
            "original Loss : 1.479551076889038 and Adversarial Loss: 1.927893877029419\n",
            "original Loss : 1.2318825721740723 and Adversarial Loss: 1.8005785942077637\n",
            "original Loss : 1.3685245513916016 and Adversarial Loss: 1.7444807291030884\n",
            "Epoch: 20\n",
            "original Loss : 1.2604074478149414 and Adversarial Loss: 1.7163273096084595\n",
            "original Loss : 1.3507553339004517 and Adversarial Loss: 1.9056929349899292\n",
            "original Loss : 1.2910289764404297 and Adversarial Loss: 1.736189365386963\n",
            "original Loss : 1.2910921573638916 and Adversarial Loss: 1.7314109802246094\n",
            "Epoch: 21\n",
            "original Loss : 1.312647819519043 and Adversarial Loss: 1.7620724439620972\n",
            "original Loss : 1.2078161239624023 and Adversarial Loss: 1.7966361045837402\n",
            "original Loss : 1.313620924949646 and Adversarial Loss: 1.9335603713989258\n",
            "original Loss : 1.3118072748184204 and Adversarial Loss: 1.8807446956634521\n",
            "Epoch: 22\n",
            "original Loss : 1.5345911979675293 and Adversarial Loss: 2.012859344482422\n",
            "original Loss : 1.2790319919586182 and Adversarial Loss: 1.7011213302612305\n",
            "original Loss : 1.458966612815857 and Adversarial Loss: 1.869621753692627\n",
            "original Loss : 1.28963303565979 and Adversarial Loss: 1.7939918041229248\n",
            "Epoch: 23\n",
            "original Loss : 1.241468906402588 and Adversarial Loss: 1.7601964473724365\n",
            "original Loss : 1.6841734647750854 and Adversarial Loss: 2.1907706260681152\n",
            "original Loss : 1.2324929237365723 and Adversarial Loss: 1.75531005859375\n",
            "original Loss : 1.2978711128234863 and Adversarial Loss: 1.6746251583099365\n",
            "Epoch: 24\n",
            "original Loss : 1.087199330329895 and Adversarial Loss: 1.6526799201965332\n",
            "original Loss : 1.3184446096420288 and Adversarial Loss: 1.8386896848678589\n",
            "original Loss : 1.2357800006866455 and Adversarial Loss: 1.8860769271850586\n",
            "original Loss : 1.3292683362960815 and Adversarial Loss: 1.8876399993896484\n",
            "Epoch: 25\n",
            "original Loss : 1.1894073486328125 and Adversarial Loss: 1.7210452556610107\n",
            "original Loss : 1.2279821634292603 and Adversarial Loss: 1.7238870859146118\n",
            "original Loss : 1.4102996587753296 and Adversarial Loss: 1.9535828828811646\n",
            "original Loss : 1.2412502765655518 and Adversarial Loss: 1.834796667098999\n",
            "Epoch: 26\n",
            "original Loss : 1.3187483549118042 and Adversarial Loss: 1.830912709236145\n",
            "original Loss : 1.2706894874572754 and Adversarial Loss: 1.8472020626068115\n",
            "original Loss : 1.1653941869735718 and Adversarial Loss: 1.6370865106582642\n",
            "original Loss : 1.0674262046813965 and Adversarial Loss: 1.5990986824035645\n",
            "Epoch: 27\n",
            "original Loss : 1.3667714595794678 and Adversarial Loss: 1.891261339187622\n",
            "original Loss : 1.5882585048675537 and Adversarial Loss: 2.0906472206115723\n",
            "original Loss : 1.2658119201660156 and Adversarial Loss: 1.7174829244613647\n",
            "original Loss : 1.3640990257263184 and Adversarial Loss: 1.9753204584121704\n",
            "Epoch: 28\n",
            "original Loss : 1.0370948314666748 and Adversarial Loss: 1.551939606666565\n",
            "original Loss : 1.248255968093872 and Adversarial Loss: 1.9278061389923096\n",
            "original Loss : 1.6020125150680542 and Adversarial Loss: 2.21883487701416\n",
            "original Loss : 1.0972135066986084 and Adversarial Loss: 1.5822725296020508\n",
            "Epoch: 29\n",
            "original Loss : 1.302649736404419 and Adversarial Loss: 1.8373290300369263\n",
            "original Loss : 1.2909185886383057 and Adversarial Loss: 1.8138571977615356\n",
            "original Loss : 1.1594592332839966 and Adversarial Loss: 1.723130464553833\n",
            "original Loss : 1.5234158039093018 and Adversarial Loss: 2.1128101348876953\n",
            "Epoch: 30\n",
            "original Loss : 1.272888422012329 and Adversarial Loss: 1.9057748317718506\n",
            "original Loss : 1.4473497867584229 and Adversarial Loss: 2.1124374866485596\n",
            "original Loss : 1.3350156545639038 and Adversarial Loss: 1.9372503757476807\n",
            "original Loss : 1.3674685955047607 and Adversarial Loss: 1.8957197666168213\n",
            "Epoch: 31\n",
            "original Loss : 1.2829035520553589 and Adversarial Loss: 1.6913151741027832\n",
            "original Loss : 1.201120138168335 and Adversarial Loss: 1.8065681457519531\n",
            "original Loss : 1.4638421535491943 and Adversarial Loss: 2.2096753120422363\n",
            "original Loss : 1.3218371868133545 and Adversarial Loss: 1.9659712314605713\n",
            "Epoch: 32\n",
            "original Loss : 1.220373272895813 and Adversarial Loss: 1.7851945161819458\n",
            "original Loss : 1.2450438737869263 and Adversarial Loss: 1.8887968063354492\n",
            "original Loss : 1.1963872909545898 and Adversarial Loss: 1.7888498306274414\n",
            "original Loss : 1.3773826360702515 and Adversarial Loss: 1.953082799911499\n",
            "Epoch: 33\n",
            "original Loss : 1.2044641971588135 and Adversarial Loss: 1.7327313423156738\n",
            "original Loss : 1.3477712869644165 and Adversarial Loss: 2.014561176300049\n",
            "original Loss : 1.1974483728408813 and Adversarial Loss: 1.7599139213562012\n",
            "original Loss : 1.280475378036499 and Adversarial Loss: 1.7924467325210571\n",
            "Epoch: 34\n",
            "original Loss : 1.285578966140747 and Adversarial Loss: 1.7990596294403076\n",
            "original Loss : 1.2637194395065308 and Adversarial Loss: 1.8646109104156494\n",
            "original Loss : 1.154176950454712 and Adversarial Loss: 1.7776516675949097\n",
            "original Loss : 1.3188526630401611 and Adversarial Loss: 1.9718884229660034\n",
            "Epoch: 35\n",
            "original Loss : 1.4556200504302979 and Adversarial Loss: 2.0676825046539307\n",
            "original Loss : 1.180101752281189 and Adversarial Loss: 1.6726629734039307\n",
            "original Loss : 1.1678826808929443 and Adversarial Loss: 1.7934576272964478\n",
            "original Loss : 1.3395752906799316 and Adversarial Loss: 1.8928782939910889\n",
            "Epoch: 36\n",
            "original Loss : 1.449559211730957 and Adversarial Loss: 1.9819450378417969\n",
            "original Loss : 1.1685692071914673 and Adversarial Loss: 1.7674211263656616\n",
            "original Loss : 1.166715145111084 and Adversarial Loss: 1.6765391826629639\n",
            "original Loss : 1.2426999807357788 and Adversarial Loss: 1.8843836784362793\n",
            "Epoch: 37\n",
            "original Loss : 1.141203761100769 and Adversarial Loss: 1.7448534965515137\n",
            "original Loss : 1.3000202178955078 and Adversarial Loss: 1.879514217376709\n",
            "original Loss : 1.234813928604126 and Adversarial Loss: 1.8585569858551025\n",
            "original Loss : 1.3014013767242432 and Adversarial Loss: 1.839223027229309\n",
            "Epoch: 38\n",
            "original Loss : 1.3249449729919434 and Adversarial Loss: 1.8847391605377197\n",
            "original Loss : 1.3479790687561035 and Adversarial Loss: 1.7887715101242065\n",
            "original Loss : 1.143627405166626 and Adversarial Loss: 1.771989345550537\n",
            "original Loss : 1.0755223035812378 and Adversarial Loss: 1.7043712139129639\n",
            "Epoch: 39\n",
            "original Loss : 1.007821798324585 and Adversarial Loss: 1.5553133487701416\n",
            "original Loss : 1.1516752243041992 and Adversarial Loss: 1.8071386814117432\n",
            "original Loss : 1.354365348815918 and Adversarial Loss: 1.996698021888733\n",
            "original Loss : 1.2844947576522827 and Adversarial Loss: 1.8129658699035645\n",
            "Epoch: 40\n",
            "original Loss : 1.0729410648345947 and Adversarial Loss: 1.617565393447876\n",
            "original Loss : 1.2249720096588135 and Adversarial Loss: 1.859884262084961\n",
            "original Loss : 1.220036268234253 and Adversarial Loss: 1.7476921081542969\n",
            "original Loss : 1.4442676305770874 and Adversarial Loss: 2.0843558311462402\n",
            "Epoch: 41\n",
            "original Loss : 1.1530249118804932 and Adversarial Loss: 1.7602996826171875\n",
            "original Loss : 1.143965482711792 and Adversarial Loss: 1.6430649757385254\n",
            "original Loss : 1.054750680923462 and Adversarial Loss: 1.5173932313919067\n",
            "original Loss : 1.2502543926239014 and Adversarial Loss: 1.894844651222229\n",
            "Epoch: 42\n",
            "original Loss : 1.3063863515853882 and Adversarial Loss: 1.8856468200683594\n",
            "original Loss : 1.2394671440124512 and Adversarial Loss: 1.8873034715652466\n",
            "original Loss : 1.1705433130264282 and Adversarial Loss: 1.7843360900878906\n",
            "original Loss : 1.311099886894226 and Adversarial Loss: 1.8241102695465088\n",
            "Epoch: 43\n",
            "original Loss : 1.2168227434158325 and Adversarial Loss: 1.7730045318603516\n",
            "original Loss : 1.2994369268417358 and Adversarial Loss: 2.086530923843384\n",
            "original Loss : 1.1795079708099365 and Adversarial Loss: 1.7286303043365479\n",
            "original Loss : 1.3611646890640259 and Adversarial Loss: 2.0128285884857178\n",
            "Epoch: 44\n",
            "original Loss : 1.0897798538208008 and Adversarial Loss: 1.5879367589950562\n",
            "original Loss : 1.0864825248718262 and Adversarial Loss: 1.692720651626587\n",
            "original Loss : 1.2849431037902832 and Adversarial Loss: 1.8469346761703491\n",
            "original Loss : 1.2240792512893677 and Adversarial Loss: 1.801750898361206\n",
            "Epoch: 45\n",
            "original Loss : 1.170572280883789 and Adversarial Loss: 1.7618318796157837\n",
            "original Loss : 1.0303995609283447 and Adversarial Loss: 1.6262166500091553\n",
            "original Loss : 1.2602972984313965 and Adversarial Loss: 1.9547157287597656\n",
            "original Loss : 1.1470204591751099 and Adversarial Loss: 1.7595537900924683\n",
            "Epoch: 46\n",
            "original Loss : 1.2145822048187256 and Adversarial Loss: 1.7327455282211304\n",
            "original Loss : 1.2581104040145874 and Adversarial Loss: 1.9471511840820312\n",
            "original Loss : 1.2809194326400757 and Adversarial Loss: 1.7395131587982178\n",
            "original Loss : 1.1341850757598877 and Adversarial Loss: 1.672581434249878\n",
            "Epoch: 47\n",
            "original Loss : 1.1611671447753906 and Adversarial Loss: 1.6309845447540283\n",
            "original Loss : 1.0282237529754639 and Adversarial Loss: 1.4679830074310303\n",
            "original Loss : 1.0428102016448975 and Adversarial Loss: 1.6190776824951172\n",
            "original Loss : 1.0614863634109497 and Adversarial Loss: 1.6462287902832031\n",
            "Epoch: 48\n",
            "original Loss : 0.9900496602058411 and Adversarial Loss: 1.6327060461044312\n",
            "original Loss : 1.0883010625839233 and Adversarial Loss: 1.6671183109283447\n",
            "original Loss : 1.2037887573242188 and Adversarial Loss: 1.885589361190796\n",
            "original Loss : 1.2359625101089478 and Adversarial Loss: 1.9367055892944336\n",
            "Epoch: 49\n",
            "original Loss : 1.0007116794586182 and Adversarial Loss: 1.4811584949493408\n",
            "original Loss : 1.088183879852295 and Adversarial Loss: 1.6854709386825562\n",
            "original Loss : 1.0772840976715088 and Adversarial Loss: 1.5984495878219604\n",
            "original Loss : 1.0840778350830078 and Adversarial Loss: 1.6979621648788452\n"
          ]
        }
      ],
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.optimizers.Adam(0.01)\n",
        "# number_of_filters, filter_size, convstride, convpadding, activation, max_pool_size, maxpoolstrides, maxpoolpadding.\n",
        "conv_layers = [[64,3,1,\"valid\",'relu',1,2,\"valid\"]]\n",
        "#number_of_units, activation function.\n",
        "dense_layers = [[128,'relu']]\n",
        "norm = 'sign'\n",
        "model_conv = Genreate_CNN_Arch(conv_layers,dense_layers,10)\n",
        "model_conv.summary()\n",
        "\n",
        "#data = data.shuffle(50000).batch(128)\n",
        "epochs = 50\n",
        "epsilon = 0.01\n",
        "train_adversarial_models(model_conv,epochs,data,epsilon,norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoJONp0aA-WI",
        "outputId": "7ee8b6da-fd56-4192-f927-d57826964ccd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2451 - accuracy: 0.3729\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3243 - accuracy: 0.3516\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4332 - accuracy: 0.2812\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2211 - accuracy: 0.3359\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.9773 - accuracy: 0.2266\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4638 - accuracy: 0.2656\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.6535 - accuracy: 0.2578\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.2117 - accuracy: 0.3281\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.1589 - accuracy: 0.3359\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5367 - accuracy: 0.2422\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.5931 - accuracy: 0.3125\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4523 - accuracy: 0.2266\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.1033 - accuracy: 0.3203\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2540 - accuracy: 0.2344\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3225 - accuracy: 0.2734\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6378 - accuracy: 0.3281\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6939 - accuracy: 0.2969\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4813 - accuracy: 0.2656\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2868 - accuracy: 0.3125\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.3337 - accuracy: 0.2578\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5462 - accuracy: 0.2734\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4898 - accuracy: 0.2109\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2523 - accuracy: 0.2969\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5537 - accuracy: 0.3047\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5977 - accuracy: 0.2500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.7194 - accuracy: 0.2969\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6437 - accuracy: 0.2812\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.0802 - accuracy: 0.3984\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4085 - accuracy: 0.3281\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.1925 - accuracy: 0.3438\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6604 - accuracy: 0.2891\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3678 - accuracy: 0.2891\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2364 - accuracy: 0.3672\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5125 - accuracy: 0.2500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2922 - accuracy: 0.2578\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.7158 - accuracy: 0.2500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5082 - accuracy: 0.3047\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.4502 - accuracy: 0.2422\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6250 - accuracy: 0.2500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5126 - accuracy: 0.2422\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6538 - accuracy: 0.2969\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4028 - accuracy: 0.2891\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5368 - accuracy: 0.2031\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5290 - accuracy: 0.2344\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.1473 - accuracy: 0.3203\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.3332 - accuracy: 0.3125\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3784 - accuracy: 0.2812\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.7979 - accuracy: 0.2344\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.5788 - accuracy: 0.3359\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4790 - accuracy: 0.2891\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5517 - accuracy: 0.3125\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6329 - accuracy: 0.2344\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2454 - accuracy: 0.3359\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6264 - accuracy: 0.2500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2070 - accuracy: 0.3047\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.7098 - accuracy: 0.2656\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4810 - accuracy: 0.2578\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5781 - accuracy: 0.2578\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.7095 - accuracy: 0.2109\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.1650 - accuracy: 0.2969\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3499 - accuracy: 0.3594\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6720 - accuracy: 0.2266\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6311 - accuracy: 0.2500\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5455 - accuracy: 0.2734\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.1945 - accuracy: 0.3125\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.6487 - accuracy: 0.2266\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.5360 - accuracy: 0.2891\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3257 - accuracy: 0.3047\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2081 - accuracy: 0.2812\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4669 - accuracy: 0.2891\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5670 - accuracy: 0.2188\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3567 - accuracy: 0.3203\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.5085 - accuracy: 0.2656\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.4432 - accuracy: 0.2578\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.0451 - accuracy: 0.2969\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.8273 - accuracy: 0.2422\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3553 - accuracy: 0.2891\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3795 - accuracy: 0.2578\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 2.1935 - accuracy: 0.3750\n",
            "test_loss: 2.4517706617524353 test_acc: 0.2837223101265823\n"
          ]
        }
      ],
      "source": [
        "test_data_b = test_data.shuffle(10000).batch(128)\n",
        "test_loss, test_acc = test_adv_Net(model_conv,test_data_b,epsilon)\n",
        "print(\"test_loss: {} test_acc: {}\".format(test_loss,test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw2PE164BFkO",
        "outputId": "5365e823-cfcc-4a30-f068-218e621ab96c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding layer 0\n",
            "Adding Next layer 1\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,219,786\n",
            "Trainable params: 1,219,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch: 0\n",
            "original Loss : 2.319406509399414 and Adversarial Loss: 13.377429008483887\n",
            "original Loss : 1.861248254776001 and Adversarial Loss: 1.847933292388916\n",
            "original Loss : 1.9486756324768066 and Adversarial Loss: 1.817458987236023\n",
            "original Loss : 1.527817964553833 and Adversarial Loss: 1.523477554321289\n",
            "Epoch: 1\n",
            "original Loss : 1.596177339553833 and Adversarial Loss: 1.629837989807129\n",
            "original Loss : 1.7322676181793213 and Adversarial Loss: 1.6500766277313232\n",
            "original Loss : 1.4349758625030518 and Adversarial Loss: 1.3947045803070068\n",
            "original Loss : 1.5300614833831787 and Adversarial Loss: 1.5216560363769531\n",
            "Epoch: 2\n",
            "original Loss : 1.7435261011123657 and Adversarial Loss: 1.6019492149353027\n",
            "original Loss : 1.6600499153137207 and Adversarial Loss: 1.5020939111709595\n",
            "original Loss : 1.4390673637390137 and Adversarial Loss: 1.4427986145019531\n",
            "original Loss : 1.6691334247589111 and Adversarial Loss: 1.6511144638061523\n",
            "Epoch: 3\n",
            "original Loss : 1.5461137294769287 and Adversarial Loss: 1.5199682712554932\n",
            "original Loss : 1.5133686065673828 and Adversarial Loss: 1.4826899766921997\n",
            "original Loss : 1.5525214672088623 and Adversarial Loss: 1.5139527320861816\n",
            "original Loss : 1.5401502847671509 and Adversarial Loss: 1.4731155633926392\n",
            "Epoch: 4\n",
            "original Loss : 1.416176199913025 and Adversarial Loss: 1.3953771591186523\n",
            "original Loss : 1.5379096269607544 and Adversarial Loss: 1.5045936107635498\n",
            "original Loss : 1.43965482711792 and Adversarial Loss: 1.4375836849212646\n",
            "original Loss : 1.5368366241455078 and Adversarial Loss: 1.519394874572754\n",
            "Epoch: 5\n",
            "original Loss : 1.4208507537841797 and Adversarial Loss: 1.4031732082366943\n",
            "original Loss : 1.4152411222457886 and Adversarial Loss: 1.4072966575622559\n",
            "original Loss : 1.396148681640625 and Adversarial Loss: 1.371849536895752\n",
            "original Loss : 1.507882833480835 and Adversarial Loss: 1.4665031433105469\n",
            "Epoch: 6\n",
            "original Loss : 1.4537913799285889 and Adversarial Loss: 1.4784750938415527\n",
            "original Loss : 1.524968147277832 and Adversarial Loss: 1.529590368270874\n",
            "original Loss : 1.3190627098083496 and Adversarial Loss: 1.2626354694366455\n",
            "original Loss : 1.3954131603240967 and Adversarial Loss: 1.3839861154556274\n",
            "Epoch: 7\n",
            "original Loss : 1.3901517391204834 and Adversarial Loss: 1.3858673572540283\n",
            "original Loss : 1.6151745319366455 and Adversarial Loss: 1.579918384552002\n",
            "original Loss : 1.3471086025238037 and Adversarial Loss: 1.3437856435775757\n",
            "original Loss : 1.5555583238601685 and Adversarial Loss: 1.5740737915039062\n",
            "Epoch: 8\n",
            "original Loss : 1.3083093166351318 and Adversarial Loss: 1.2840542793273926\n",
            "original Loss : 1.4308754205703735 and Adversarial Loss: 1.4591714143753052\n",
            "original Loss : 1.3670169115066528 and Adversarial Loss: 1.3763649463653564\n",
            "original Loss : 1.620619773864746 and Adversarial Loss: 1.632189154624939\n",
            "Epoch: 9\n",
            "original Loss : 1.5602543354034424 and Adversarial Loss: 1.5387853384017944\n",
            "original Loss : 1.4267210960388184 and Adversarial Loss: 1.4437980651855469\n",
            "original Loss : 1.4315729141235352 and Adversarial Loss: 1.4400779008865356\n",
            "original Loss : 1.415902853012085 and Adversarial Loss: 1.4196083545684814\n",
            "Epoch: 10\n",
            "original Loss : 1.3117876052856445 and Adversarial Loss: 1.253657579421997\n",
            "original Loss : 1.4214881658554077 and Adversarial Loss: 1.4370478391647339\n",
            "original Loss : 1.3922979831695557 and Adversarial Loss: 1.3845374584197998\n",
            "original Loss : 1.2750470638275146 and Adversarial Loss: 1.2014012336730957\n",
            "Epoch: 11\n",
            "original Loss : 1.5631334781646729 and Adversarial Loss: 1.521437168121338\n",
            "original Loss : 1.3285415172576904 and Adversarial Loss: 1.3053025007247925\n",
            "original Loss : 1.4232535362243652 and Adversarial Loss: 1.407442569732666\n",
            "original Loss : 1.339247465133667 and Adversarial Loss: 1.334218978881836\n",
            "Epoch: 12\n",
            "original Loss : 1.2139192819595337 and Adversarial Loss: 1.2186610698699951\n",
            "original Loss : 1.3160258531570435 and Adversarial Loss: 1.3217566013336182\n",
            "original Loss : 1.3372008800506592 and Adversarial Loss: 1.3253185749053955\n",
            "original Loss : 1.342411994934082 and Adversarial Loss: 1.3304545879364014\n",
            "Epoch: 13\n",
            "original Loss : 1.2891110181808472 and Adversarial Loss: 1.2636959552764893\n",
            "original Loss : 1.4895780086517334 and Adversarial Loss: 1.4738999605178833\n",
            "original Loss : 1.2759556770324707 and Adversarial Loss: 1.2619493007659912\n",
            "original Loss : 1.540216088294983 and Adversarial Loss: 1.5164437294006348\n",
            "Epoch: 14\n",
            "original Loss : 1.2960916757583618 and Adversarial Loss: 1.2755284309387207\n",
            "original Loss : 1.3752448558807373 and Adversarial Loss: 1.3782671689987183\n",
            "original Loss : 1.5676312446594238 and Adversarial Loss: 1.486151933670044\n",
            "original Loss : 1.3493106365203857 and Adversarial Loss: 1.3141111135482788\n",
            "Epoch: 15\n",
            "original Loss : 1.4259119033813477 and Adversarial Loss: 1.439875841140747\n",
            "original Loss : 1.3397177457809448 and Adversarial Loss: 1.3509849309921265\n",
            "original Loss : 1.3442965745925903 and Adversarial Loss: 1.3331496715545654\n",
            "original Loss : 1.3981194496154785 and Adversarial Loss: 1.3518543243408203\n",
            "Epoch: 16\n",
            "original Loss : 1.3447699546813965 and Adversarial Loss: 1.3400393724441528\n",
            "original Loss : 1.3830580711364746 and Adversarial Loss: 1.3465231657028198\n",
            "original Loss : 1.4681270122528076 and Adversarial Loss: 1.4593267440795898\n",
            "original Loss : 1.4216729402542114 and Adversarial Loss: 1.3806440830230713\n",
            "Epoch: 17\n",
            "original Loss : 1.370339035987854 and Adversarial Loss: 1.275458574295044\n",
            "original Loss : 1.287455439567566 and Adversarial Loss: 1.2429418563842773\n",
            "original Loss : 1.5132570266723633 and Adversarial Loss: 1.38667631149292\n",
            "original Loss : 1.3468372821807861 and Adversarial Loss: 1.3299145698547363\n",
            "Epoch: 18\n",
            "original Loss : 1.5336183309555054 and Adversarial Loss: 1.4861345291137695\n",
            "original Loss : 1.338512659072876 and Adversarial Loss: 1.2893927097320557\n",
            "original Loss : 1.4328008890151978 and Adversarial Loss: 1.3671965599060059\n",
            "original Loss : 1.3522934913635254 and Adversarial Loss: 1.3038408756256104\n",
            "Epoch: 19\n",
            "original Loss : 1.3544461727142334 and Adversarial Loss: 1.3521850109100342\n",
            "original Loss : 1.3894275426864624 and Adversarial Loss: 1.3629980087280273\n",
            "original Loss : 1.2443164587020874 and Adversarial Loss: 1.2406206130981445\n",
            "original Loss : 1.3815937042236328 and Adversarial Loss: 1.3951984643936157\n",
            "Epoch: 20\n",
            "original Loss : 1.5060603618621826 and Adversarial Loss: 1.3381216526031494\n",
            "original Loss : 1.471807837486267 and Adversarial Loss: 1.4317071437835693\n",
            "original Loss : 1.3516544103622437 and Adversarial Loss: 1.3357393741607666\n",
            "original Loss : 1.4306576251983643 and Adversarial Loss: 1.3997886180877686\n",
            "Epoch: 21\n",
            "original Loss : 1.3717470169067383 and Adversarial Loss: 1.3439698219299316\n",
            "original Loss : 1.4895700216293335 and Adversarial Loss: 1.4677448272705078\n",
            "original Loss : 1.2071280479431152 and Adversarial Loss: 1.2015653848648071\n",
            "original Loss : 1.2797856330871582 and Adversarial Loss: 1.3200852870941162\n",
            "Epoch: 22\n",
            "original Loss : 1.4042881727218628 and Adversarial Loss: 1.3849071264266968\n",
            "original Loss : 1.2584986686706543 and Adversarial Loss: 1.2345802783966064\n",
            "original Loss : 1.3355276584625244 and Adversarial Loss: 1.3375368118286133\n",
            "original Loss : 1.4155030250549316 and Adversarial Loss: 1.3806853294372559\n",
            "Epoch: 23\n",
            "original Loss : 1.4941565990447998 and Adversarial Loss: 1.4519460201263428\n",
            "original Loss : 1.414124846458435 and Adversarial Loss: 1.3939299583435059\n",
            "original Loss : 1.4775316715240479 and Adversarial Loss: 1.3733954429626465\n",
            "original Loss : 1.6122403144836426 and Adversarial Loss: 1.56348717212677\n",
            "Epoch: 24\n",
            "original Loss : 1.2820096015930176 and Adversarial Loss: 1.2708289623260498\n",
            "original Loss : 1.3168926239013672 and Adversarial Loss: 1.3135168552398682\n",
            "original Loss : 1.3904848098754883 and Adversarial Loss: 1.3800125122070312\n",
            "original Loss : 1.4719622135162354 and Adversarial Loss: 1.4361176490783691\n",
            "Epoch: 25\n",
            "original Loss : 1.2275179624557495 and Adversarial Loss: 1.19381582736969\n",
            "original Loss : 1.2968018054962158 and Adversarial Loss: 1.2483373880386353\n",
            "original Loss : 1.2593287229537964 and Adversarial Loss: 1.2737895250320435\n",
            "original Loss : 1.4447139501571655 and Adversarial Loss: 1.3737126588821411\n",
            "Epoch: 26\n",
            "original Loss : 1.3668580055236816 and Adversarial Loss: 1.379927396774292\n",
            "original Loss : 1.3763649463653564 and Adversarial Loss: 1.3823552131652832\n",
            "original Loss : 1.3850172758102417 and Adversarial Loss: 1.3613512516021729\n",
            "original Loss : 1.2623481750488281 and Adversarial Loss: 1.2709152698516846\n",
            "Epoch: 27\n",
            "original Loss : 1.4493917226791382 and Adversarial Loss: 1.470043659210205\n",
            "original Loss : 1.5580850839614868 and Adversarial Loss: 1.5568280220031738\n",
            "original Loss : 1.4569531679153442 and Adversarial Loss: 1.4367754459381104\n",
            "original Loss : 1.4240856170654297 and Adversarial Loss: 1.40389084815979\n",
            "Epoch: 28\n",
            "original Loss : 1.5514870882034302 and Adversarial Loss: 1.561010479927063\n",
            "original Loss : 1.3665999174118042 and Adversarial Loss: 1.316431999206543\n",
            "original Loss : 1.1808710098266602 and Adversarial Loss: 1.1576650142669678\n",
            "original Loss : 1.1303324699401855 and Adversarial Loss: 1.127824068069458\n",
            "Epoch: 29\n",
            "original Loss : 1.2710503339767456 and Adversarial Loss: 1.2582778930664062\n",
            "original Loss : 1.418426275253296 and Adversarial Loss: 1.440126895904541\n",
            "original Loss : 1.4502894878387451 and Adversarial Loss: 1.4462082386016846\n",
            "original Loss : 1.5119143724441528 and Adversarial Loss: 1.4313409328460693\n",
            "Epoch: 30\n",
            "original Loss : 1.3856199979782104 and Adversarial Loss: 1.3510284423828125\n",
            "original Loss : 1.4095162153244019 and Adversarial Loss: 1.4069737195968628\n",
            "original Loss : 1.48602294921875 and Adversarial Loss: 1.3886752128601074\n",
            "original Loss : 1.577745795249939 and Adversarial Loss: 1.4466184377670288\n",
            "Epoch: 31\n",
            "original Loss : 1.2658889293670654 and Adversarial Loss: 1.2708494663238525\n",
            "original Loss : 1.20836341381073 and Adversarial Loss: 1.1953048706054688\n",
            "original Loss : 1.4170026779174805 and Adversarial Loss: 1.4216574430465698\n",
            "original Loss : 1.4072507619857788 and Adversarial Loss: 1.366309404373169\n",
            "Epoch: 32\n",
            "original Loss : 1.19541335105896 and Adversarial Loss: 1.1752417087554932\n",
            "original Loss : 1.261583685874939 and Adversarial Loss: 1.2684086561203003\n",
            "original Loss : 1.3868076801300049 and Adversarial Loss: 1.368239402770996\n",
            "original Loss : 1.5700936317443848 and Adversarial Loss: 1.5589675903320312\n",
            "Epoch: 33\n",
            "original Loss : 1.1970860958099365 and Adversarial Loss: 1.2097160816192627\n",
            "original Loss : 1.2164689302444458 and Adversarial Loss: 1.1722511053085327\n",
            "original Loss : 1.381080985069275 and Adversarial Loss: 1.3349390029907227\n",
            "original Loss : 1.323969841003418 and Adversarial Loss: 1.3879289627075195\n",
            "Epoch: 34\n",
            "original Loss : 1.5638426542282104 and Adversarial Loss: 1.502375602722168\n",
            "original Loss : 1.3673717975616455 and Adversarial Loss: 1.31723952293396\n",
            "original Loss : 1.4922287464141846 and Adversarial Loss: 1.4503318071365356\n",
            "original Loss : 1.3967161178588867 and Adversarial Loss: 1.3707348108291626\n",
            "Epoch: 35\n",
            "original Loss : 1.3625612258911133 and Adversarial Loss: 1.3398348093032837\n",
            "original Loss : 1.528871774673462 and Adversarial Loss: 1.451425313949585\n",
            "original Loss : 1.5164024829864502 and Adversarial Loss: 1.4445359706878662\n",
            "original Loss : 1.26214599609375 and Adversarial Loss: 1.24789297580719\n",
            "Epoch: 36\n",
            "original Loss : 1.3512369394302368 and Adversarial Loss: 1.344850778579712\n",
            "original Loss : 1.4169363975524902 and Adversarial Loss: 1.3772218227386475\n",
            "original Loss : 1.3872569799423218 and Adversarial Loss: 1.3854420185089111\n",
            "original Loss : 1.6063029766082764 and Adversarial Loss: 1.6105901002883911\n",
            "Epoch: 37\n",
            "original Loss : 0.9949955940246582 and Adversarial Loss: 1.016120195388794\n",
            "original Loss : 1.4823482036590576 and Adversarial Loss: 1.480220079421997\n",
            "original Loss : 1.4511299133300781 and Adversarial Loss: 1.536262035369873\n",
            "original Loss : 1.2741044759750366 and Adversarial Loss: 1.2450499534606934\n",
            "Epoch: 38\n",
            "original Loss : 1.3671435117721558 and Adversarial Loss: 1.3668997287750244\n",
            "original Loss : 1.3350766897201538 and Adversarial Loss: 1.3540241718292236\n",
            "original Loss : 1.2694363594055176 and Adversarial Loss: 1.2623870372772217\n",
            "original Loss : 1.407632827758789 and Adversarial Loss: 1.3065121173858643\n",
            "Epoch: 39\n",
            "original Loss : 1.5910927057266235 and Adversarial Loss: 1.6111438274383545\n",
            "original Loss : 1.3121974468231201 and Adversarial Loss: 1.2846827507019043\n",
            "original Loss : 1.2081447839736938 and Adversarial Loss: 1.2080215215682983\n",
            "original Loss : 1.5585052967071533 and Adversarial Loss: 1.5325531959533691\n",
            "Epoch: 40\n",
            "original Loss : 1.1735976934432983 and Adversarial Loss: 1.1724283695220947\n",
            "original Loss : 1.604480504989624 and Adversarial Loss: 1.571069359779358\n",
            "original Loss : 1.3313969373703003 and Adversarial Loss: 1.2775455713272095\n",
            "original Loss : 1.5634403228759766 and Adversarial Loss: 1.548248052597046\n",
            "Epoch: 41\n",
            "original Loss : 1.381110668182373 and Adversarial Loss: 1.3635832071304321\n",
            "original Loss : 1.618680715560913 and Adversarial Loss: 1.4803030490875244\n",
            "original Loss : 1.386852741241455 and Adversarial Loss: 1.3597002029418945\n",
            "original Loss : 1.3483474254608154 and Adversarial Loss: 1.3085453510284424\n",
            "Epoch: 42\n",
            "original Loss : 1.1467384099960327 and Adversarial Loss: 1.1406850814819336\n",
            "original Loss : 1.177520990371704 and Adversarial Loss: 1.1411887407302856\n",
            "original Loss : 1.4323875904083252 and Adversarial Loss: 1.3655747175216675\n",
            "original Loss : 1.4560694694519043 and Adversarial Loss: 1.4300146102905273\n",
            "Epoch: 43\n",
            "original Loss : 1.3718022108078003 and Adversarial Loss: 1.3173246383666992\n",
            "original Loss : 1.3280305862426758 and Adversarial Loss: 1.268383264541626\n",
            "original Loss : 1.3388681411743164 and Adversarial Loss: 1.3135926723480225\n",
            "original Loss : 1.4436194896697998 and Adversarial Loss: 1.411768913269043\n",
            "Epoch: 44\n",
            "original Loss : 1.327826976776123 and Adversarial Loss: 1.3103876113891602\n",
            "original Loss : 1.269521713256836 and Adversarial Loss: 1.2391717433929443\n",
            "original Loss : 1.3900071382522583 and Adversarial Loss: 1.3678134679794312\n",
            "original Loss : 1.229569435119629 and Adversarial Loss: 1.2126305103302002\n",
            "Epoch: 45\n",
            "original Loss : 1.1891916990280151 and Adversarial Loss: 1.189976453781128\n",
            "original Loss : 1.4845103025436401 and Adversarial Loss: 1.4906996488571167\n",
            "original Loss : 1.5081000328063965 and Adversarial Loss: 1.5647379159927368\n",
            "original Loss : 1.3210761547088623 and Adversarial Loss: 1.2391680479049683\n",
            "Epoch: 46\n",
            "original Loss : 1.2401432991027832 and Adversarial Loss: 1.2253674268722534\n",
            "original Loss : 1.4236624240875244 and Adversarial Loss: 1.3438411951065063\n",
            "original Loss : 1.2149070501327515 and Adversarial Loss: 1.200671911239624\n",
            "original Loss : 1.3145241737365723 and Adversarial Loss: 1.294967770576477\n",
            "Epoch: 47\n",
            "original Loss : 1.5136257410049438 and Adversarial Loss: 1.4688235521316528\n",
            "original Loss : 1.3860878944396973 and Adversarial Loss: 1.34779953956604\n",
            "original Loss : 1.417386531829834 and Adversarial Loss: 1.341670036315918\n",
            "original Loss : 1.4505021572113037 and Adversarial Loss: 1.4339423179626465\n",
            "Epoch: 48\n",
            "original Loss : 1.4912035465240479 and Adversarial Loss: 1.4870738983154297\n",
            "original Loss : 1.2701382637023926 and Adversarial Loss: 1.2494816780090332\n",
            "original Loss : 1.5067503452301025 and Adversarial Loss: 1.4448765516281128\n",
            "original Loss : 1.4759725332260132 and Adversarial Loss: 1.4895259141921997\n",
            "Epoch: 49\n",
            "original Loss : 1.060375690460205 and Adversarial Loss: 1.044823408126831\n",
            "original Loss : 1.3396356105804443 and Adversarial Loss: 1.3201618194580078\n",
            "original Loss : 1.1168911457061768 and Adversarial Loss: 1.0708624124526978\n",
            "original Loss : 1.445632815361023 and Adversarial Loss: 1.43341064453125\n"
          ]
        }
      ],
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.optimizers.Adam(0.01)\n",
        "# number_of_filters, filter_size, convstride, convpadding, activation, max_pool_size, maxpoolstrides, maxpoolpadding.\n",
        "conv_layers = [[64,3,1,\"valid\",'relu',1,2,\"valid\"],[64,3,1,\"valid\",'relu',2,1,\"valid\"]]\n",
        "#number_of_units, activation function.\n",
        "dense_layers = [[128,'relu']]\n",
        "norm = 'norm'\n",
        "model_conv = Genreate_CNN_Arch(conv_layers,dense_layers,10)\n",
        "model_conv.summary()\n",
        "\n",
        "#data = data.shuffle(50000).batch(128)\n",
        "epochs = 50\n",
        "epsilon = 0.01\n",
        "train_adversarial_models(model_conv,epochs,data,epsilon,norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSTvkU_BBMxL",
        "outputId": "29eb05d7-b5ed-40b2-ab2b-d7de578102ed",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 4.6588 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 5.0829 - accuracy: 0.0469\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.8154 - accuracy: 0.0703\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2665 - accuracy: 0.0703\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5781 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3397 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.1102 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.2657 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.4554 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.7554 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.9071 - accuracy: 0.0391\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5318 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.4263 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 5.1723 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.8332 - accuracy: 0.0469\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.1045 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2373 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2713 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3115 - accuracy: 0.0938\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2100 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2103 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.9336 - accuracy: 0.0938\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3959 - accuracy: 0.0938\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5421 - accuracy: 0.0938\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2048 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.6792 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2948 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5416 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.7893 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2293 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3755 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.7622 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.8611 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.5472 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.4587 - accuracy: 0.1484\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3140 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5123 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.1677 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.9963 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3366 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.4655 - accuracy: 0.1172\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2317 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3434 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.4079 - accuracy: 0.0625\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.6890 - accuracy: 0.0625\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5666 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.1145 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.9341 - accuracy: 0.1406\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.1920 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.3668 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.7647 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.8161 - accuracy: 0.0703\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5878 - accuracy: 0.1172\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5223 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 5.0973 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.8692 - accuracy: 0.0703\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.8738 - accuracy: 0.0703\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.4593 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2357 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3467 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.1075 - accuracy: 0.1641\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.9933 - accuracy: 0.1172\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2086 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5690 - accuracy: 0.0781\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.6997 - accuracy: 0.1094\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.6387 - accuracy: 0.0625\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5610 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.1978 - accuracy: 0.1328\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2267 - accuracy: 0.1016\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.4782 - accuracy: 0.1562\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.9021 - accuracy: 0.1250\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3256 - accuracy: 0.0625\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.6136 - accuracy: 0.0625\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 3.9274 - accuracy: 0.1172\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.5087 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.9301 - accuracy: 0.0938\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.8795 - accuracy: 0.0859\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.3771 - accuracy: 0.1094\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 4.2835 - accuracy: 0.1875\n",
            "test_loss: 4.475504503974432 test_acc: 0.0981012658227848\n"
          ]
        }
      ],
      "source": [
        "test_data_b = test_data.shuffle(10000).batch(128)\n",
        "test_loss, test_acc = test_adv_Net(model_conv,test_data_b,epsilon)\n",
        "print(\"test_loss: {} test_acc: {}\".format(test_loss,test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADW1Rq1oxqFh",
        "outputId": "4bb765db-2d67-4e0b-d89f-d3909795dbd0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "original Loss : 2.8244805335998535 and Adversarial Loss: 457.0640869140625\n",
            "original Loss : 8564.529296875 and Adversarial Loss: 4852.7568359375\n",
            "original Loss : 2002.291259765625 and Adversarial Loss: 2316.85986328125\n",
            "original Loss : 614.5768432617188 and Adversarial Loss: 518.573486328125\n",
            "Epoch: 1\n",
            "original Loss : 802.4020385742188 and Adversarial Loss: 741.9290771484375\n",
            "original Loss : 634.9983520507812 and Adversarial Loss: 550.6116333007812\n",
            "original Loss : 607.681396484375 and Adversarial Loss: 515.923095703125\n",
            "original Loss : 298.56170654296875 and Adversarial Loss: 221.6471710205078\n",
            "Epoch: 2\n",
            "original Loss : 208.97019958496094 and Adversarial Loss: 204.01318359375\n",
            "original Loss : 347.4029846191406 and Adversarial Loss: 232.67127990722656\n",
            "original Loss : 172.39254760742188 and Adversarial Loss: 184.875732421875\n",
            "original Loss : 162.51226806640625 and Adversarial Loss: 190.42062377929688\n",
            "Epoch: 3\n",
            "original Loss : 177.50302124023438 and Adversarial Loss: 329.7176513671875\n",
            "original Loss : 100.93913269042969 and Adversarial Loss: 129.59423828125\n",
            "original Loss : 130.6827392578125 and Adversarial Loss: 181.197021484375\n",
            "original Loss : 89.47501373291016 and Adversarial Loss: 75.22456359863281\n",
            "Epoch: 4\n",
            "original Loss : 104.89733123779297 and Adversarial Loss: 213.38540649414062\n",
            "original Loss : 65.77783966064453 and Adversarial Loss: 57.5145149230957\n",
            "original Loss : 108.90311431884766 and Adversarial Loss: 101.2249526977539\n",
            "original Loss : 1058.470947265625 and Adversarial Loss: 950.7363891601562\n",
            "Epoch: 5\n",
            "original Loss : 182.6568145751953 and Adversarial Loss: 271.29083251953125\n",
            "original Loss : 99.2610092163086 and Adversarial Loss: 91.53508758544922\n",
            "original Loss : 72.26822662353516 and Adversarial Loss: 49.53746795654297\n",
            "original Loss : 28.028430938720703 and Adversarial Loss: 28.846206665039062\n",
            "Epoch: 6\n",
            "original Loss : 38.982826232910156 and Adversarial Loss: 36.7472038269043\n",
            "original Loss : 29.413148880004883 and Adversarial Loss: 29.77967071533203\n",
            "original Loss : 15.61021900177002 and Adversarial Loss: 17.35171890258789\n",
            "original Loss : 21.843238830566406 and Adversarial Loss: 13.66116714477539\n",
            "Epoch: 7\n",
            "original Loss : 14.041446685791016 and Adversarial Loss: 12.564330101013184\n",
            "original Loss : 26.021581649780273 and Adversarial Loss: 32.48078536987305\n",
            "original Loss : 16.497848510742188 and Adversarial Loss: 15.405571937561035\n",
            "original Loss : 11.427702903747559 and Adversarial Loss: 11.613845825195312\n",
            "Epoch: 8\n",
            "original Loss : 14.410914421081543 and Adversarial Loss: 9.472963333129883\n",
            "original Loss : 10.877537727355957 and Adversarial Loss: 10.047239303588867\n",
            "original Loss : 14.937692642211914 and Adversarial Loss: 10.374002456665039\n",
            "original Loss : 15.575848579406738 and Adversarial Loss: 11.683052062988281\n",
            "Epoch: 9\n",
            "original Loss : 8.207450866699219 and Adversarial Loss: 7.961977481842041\n",
            "original Loss : 7.373190402984619 and Adversarial Loss: 7.669306755065918\n",
            "original Loss : 7.486830711364746 and Adversarial Loss: 7.795951843261719\n",
            "original Loss : 5.101744651794434 and Adversarial Loss: 6.619640827178955\n",
            "Epoch: 10\n",
            "original Loss : 7.613951683044434 and Adversarial Loss: 6.094754219055176\n",
            "original Loss : 6.310842990875244 and Adversarial Loss: 4.743657112121582\n",
            "original Loss : 6.209922790527344 and Adversarial Loss: 5.271275520324707\n",
            "original Loss : 7.780407905578613 and Adversarial Loss: 7.875250816345215\n",
            "Epoch: 11\n",
            "original Loss : 114520.1640625 and Adversarial Loss: 158771.703125\n",
            "original Loss : 1365.683837890625 and Adversarial Loss: 1195.821533203125\n",
            "original Loss : 443.876953125 and Adversarial Loss: 469.462890625\n",
            "original Loss : 327.2856750488281 and Adversarial Loss: 408.78289794921875\n",
            "Epoch: 12\n",
            "original Loss : 271.40069580078125 and Adversarial Loss: 212.27781677246094\n",
            "original Loss : 314.677734375 and Adversarial Loss: 255.2794189453125\n",
            "original Loss : 140.27426147460938 and Adversarial Loss: 127.50181579589844\n",
            "original Loss : 186.24171447753906 and Adversarial Loss: 176.46124267578125\n",
            "Epoch: 13\n",
            "original Loss : 149.568359375 and Adversarial Loss: 127.64688110351562\n",
            "original Loss : 77.86518859863281 and Adversarial Loss: 67.73062133789062\n",
            "original Loss : 73.93233489990234 and Adversarial Loss: 62.525089263916016\n",
            "original Loss : 107.44557189941406 and Adversarial Loss: 78.60594177246094\n",
            "Epoch: 14\n",
            "original Loss : 95.56356811523438 and Adversarial Loss: 66.96585083007812\n",
            "original Loss : 42.997894287109375 and Adversarial Loss: 35.577537536621094\n",
            "original Loss : 52.76344299316406 and Adversarial Loss: 50.99205780029297\n",
            "original Loss : 55.396400451660156 and Adversarial Loss: 55.35612487792969\n",
            "Epoch: 15\n",
            "original Loss : 56.930809020996094 and Adversarial Loss: 46.732421875\n",
            "original Loss : 55.214019775390625 and Adversarial Loss: 43.555320739746094\n",
            "original Loss : 52.82913589477539 and Adversarial Loss: 47.59864807128906\n",
            "original Loss : 20.802148818969727 and Adversarial Loss: 18.71845245361328\n",
            "Epoch: 16\n",
            "original Loss : 34.08162307739258 and Adversarial Loss: 32.34314727783203\n",
            "original Loss : 30.36911392211914 and Adversarial Loss: 23.11605453491211\n",
            "original Loss : 34.21877670288086 and Adversarial Loss: 25.555082321166992\n",
            "original Loss : 16.251035690307617 and Adversarial Loss: 14.86581039428711\n",
            "Epoch: 17\n",
            "original Loss : 17.42974090576172 and Adversarial Loss: 20.013347625732422\n",
            "original Loss : 17.810794830322266 and Adversarial Loss: 18.672761917114258\n",
            "original Loss : 6953.36328125 and Adversarial Loss: 5946.8681640625\n",
            "original Loss : 390.1867370605469 and Adversarial Loss: 350.5152282714844\n",
            "Epoch: 18\n",
            "original Loss : 205.89883422851562 and Adversarial Loss: 214.49658203125\n",
            "original Loss : 165.83517456054688 and Adversarial Loss: 142.96682739257812\n",
            "original Loss : 152.7298583984375 and Adversarial Loss: 115.61689758300781\n",
            "original Loss : 141.38475036621094 and Adversarial Loss: 123.34530639648438\n",
            "Epoch: 19\n",
            "original Loss : 88.0119400024414 and Adversarial Loss: 85.73128509521484\n",
            "original Loss : 117.15324401855469 and Adversarial Loss: 98.4053955078125\n",
            "original Loss : 61.881710052490234 and Adversarial Loss: 49.57049560546875\n",
            "original Loss : 65.96351623535156 and Adversarial Loss: 48.478553771972656\n",
            "Epoch: 20\n",
            "original Loss : 52.60594177246094 and Adversarial Loss: 51.04210662841797\n",
            "original Loss : 40.15142059326172 and Adversarial Loss: 42.974212646484375\n",
            "original Loss : 41.89634704589844 and Adversarial Loss: 47.231712341308594\n",
            "original Loss : 35.470497131347656 and Adversarial Loss: 32.13385772705078\n",
            "Epoch: 21\n",
            "original Loss : 40.276878356933594 and Adversarial Loss: 36.62294006347656\n",
            "original Loss : 47.50822448730469 and Adversarial Loss: 48.38069152832031\n",
            "original Loss : 34.099220275878906 and Adversarial Loss: 33.905967712402344\n",
            "original Loss : 36.10972595214844 and Adversarial Loss: 33.33946228027344\n",
            "Epoch: 22\n",
            "original Loss : 22.544933319091797 and Adversarial Loss: 20.422359466552734\n",
            "original Loss : 19.89807891845703 and Adversarial Loss: 19.740068435668945\n",
            "original Loss : 25.290428161621094 and Adversarial Loss: 21.298503875732422\n",
            "original Loss : 17.659259796142578 and Adversarial Loss: 16.795791625976562\n",
            "Epoch: 23\n",
            "original Loss : 16.46027374267578 and Adversarial Loss: 13.826738357543945\n",
            "original Loss : 19.967111587524414 and Adversarial Loss: 15.70252799987793\n",
            "original Loss : 10.479209899902344 and Adversarial Loss: 9.239945411682129\n",
            "original Loss : 12.547651290893555 and Adversarial Loss: 11.18263053894043\n",
            "Epoch: 24\n",
            "original Loss : 12.27080249786377 and Adversarial Loss: 10.779657363891602\n",
            "original Loss : 7.214034080505371 and Adversarial Loss: 6.576617240905762\n",
            "original Loss : 660120.9375 and Adversarial Loss: 1036716.25\n",
            "original Loss : 686.3697509765625 and Adversarial Loss: 598.0458374023438\n",
            "Epoch: 25\n",
            "original Loss : 361.5606384277344 and Adversarial Loss: 377.1864013671875\n",
            "original Loss : 222.25747680664062 and Adversarial Loss: 218.87039184570312\n",
            "original Loss : 217.20286560058594 and Adversarial Loss: 188.96768188476562\n",
            "original Loss : 121.58179473876953 and Adversarial Loss: 120.49151611328125\n",
            "Epoch: 26\n",
            "original Loss : 170.63877868652344 and Adversarial Loss: 154.47256469726562\n",
            "original Loss : 149.90757751464844 and Adversarial Loss: 148.94920349121094\n",
            "original Loss : 102.72662353515625 and Adversarial Loss: 101.9911880493164\n",
            "original Loss : 101.16412353515625 and Adversarial Loss: 99.3165283203125\n",
            "Epoch: 27\n",
            "original Loss : 105.97653198242188 and Adversarial Loss: 94.36691284179688\n",
            "original Loss : 61.27083969116211 and Adversarial Loss: 64.59806060791016\n",
            "original Loss : 66.31403350830078 and Adversarial Loss: 55.92508316040039\n",
            "original Loss : 69.18074035644531 and Adversarial Loss: 67.27873992919922\n",
            "Epoch: 28\n",
            "original Loss : 71.95675659179688 and Adversarial Loss: 54.061668395996094\n",
            "original Loss : 75.25281524658203 and Adversarial Loss: 53.716060638427734\n",
            "original Loss : 61.00238800048828 and Adversarial Loss: 55.1395263671875\n",
            "original Loss : 39.585968017578125 and Adversarial Loss: 37.865333557128906\n",
            "Epoch: 29\n",
            "original Loss : 44.7310791015625 and Adversarial Loss: 45.63283157348633\n",
            "original Loss : 31.562896728515625 and Adversarial Loss: 28.643049240112305\n",
            "original Loss : 35.815391540527344 and Adversarial Loss: 28.05469512939453\n",
            "original Loss : 27.972618103027344 and Adversarial Loss: 25.08847427368164\n",
            "Epoch: 30\n",
            "original Loss : 25.04667091369629 and Adversarial Loss: 21.68535041809082\n",
            "original Loss : 14.174510955810547 and Adversarial Loss: 12.2332124710083\n",
            "original Loss : 3604.801025390625 and Adversarial Loss: 3765.9013671875\n",
            "original Loss : 662.6192016601562 and Adversarial Loss: 728.760986328125\n",
            "Epoch: 31\n",
            "original Loss : 526.2658081054688 and Adversarial Loss: 472.0653076171875\n",
            "original Loss : 244.23439025878906 and Adversarial Loss: 249.40115356445312\n",
            "original Loss : 204.5917205810547 and Adversarial Loss: 172.986328125\n",
            "original Loss : 228.31170654296875 and Adversarial Loss: 220.36936950683594\n",
            "Epoch: 32\n",
            "original Loss : 205.54380798339844 and Adversarial Loss: 220.3824462890625\n",
            "original Loss : 130.26438903808594 and Adversarial Loss: 111.49922180175781\n",
            "original Loss : 134.5738525390625 and Adversarial Loss: 135.7323455810547\n",
            "original Loss : 134.197998046875 and Adversarial Loss: 118.6013412475586\n",
            "Epoch: 33\n",
            "original Loss : 102.51405334472656 and Adversarial Loss: 104.20406341552734\n",
            "original Loss : 74.63195037841797 and Adversarial Loss: 49.93489456176758\n",
            "original Loss : 73.8153076171875 and Adversarial Loss: 66.1993179321289\n",
            "original Loss : 81.02680969238281 and Adversarial Loss: 71.19804382324219\n",
            "Epoch: 34\n",
            "original Loss : 89.57671356201172 and Adversarial Loss: 78.82534790039062\n",
            "original Loss : 44.40179443359375 and Adversarial Loss: 44.025390625\n",
            "original Loss : 47.3857536315918 and Adversarial Loss: 53.43751525878906\n",
            "original Loss : 52.26538848876953 and Adversarial Loss: 37.00946807861328\n",
            "Epoch: 35\n",
            "original Loss : 35.256988525390625 and Adversarial Loss: 35.22674560546875\n",
            "original Loss : 46.12450408935547 and Adversarial Loss: 36.97673034667969\n",
            "original Loss : 29.743885040283203 and Adversarial Loss: 27.465869903564453\n",
            "original Loss : 37.40081787109375 and Adversarial Loss: 34.67913055419922\n",
            "Epoch: 36\n",
            "original Loss : 28.07501220703125 and Adversarial Loss: 25.787031173706055\n",
            "original Loss : 30.0246524810791 and Adversarial Loss: 28.003070831298828\n",
            "original Loss : 20.713485717773438 and Adversarial Loss: 20.9156494140625\n",
            "original Loss : 22.181974411010742 and Adversarial Loss: 21.15066146850586\n",
            "Epoch: 37\n",
            "original Loss : 3383.399169921875 and Adversarial Loss: 6177.6904296875\n",
            "original Loss : 4528.12060546875 and Adversarial Loss: 3624.366455078125\n",
            "original Loss : 1108.8206787109375 and Adversarial Loss: 1069.15087890625\n",
            "original Loss : 602.8836669921875 and Adversarial Loss: 548.6627197265625\n",
            "Epoch: 38\n",
            "original Loss : 435.964599609375 and Adversarial Loss: 542.9906616210938\n",
            "original Loss : 561.163818359375 and Adversarial Loss: 914.6989135742188\n",
            "original Loss : 321.5814208984375 and Adversarial Loss: 324.8397216796875\n",
            "original Loss : 329.78448486328125 and Adversarial Loss: 316.0273742675781\n",
            "Epoch: 39\n",
            "original Loss : 236.72384643554688 and Adversarial Loss: 199.282470703125\n",
            "original Loss : 302.8753662109375 and Adversarial Loss: 241.93331909179688\n",
            "original Loss : 243.50315856933594 and Adversarial Loss: 172.79713439941406\n",
            "original Loss : 351.7569274902344 and Adversarial Loss: 345.746826171875\n",
            "Epoch: 40\n",
            "original Loss : 329.3215026855469 and Adversarial Loss: 262.9122009277344\n",
            "original Loss : 220.4449920654297 and Adversarial Loss: 286.87762451171875\n",
            "original Loss : 162.32069396972656 and Adversarial Loss: 148.42469787597656\n",
            "original Loss : 135.0579376220703 and Adversarial Loss: 127.48478698730469\n",
            "Epoch: 41\n",
            "original Loss : 107.677490234375 and Adversarial Loss: 86.58674621582031\n",
            "original Loss : 138.3041534423828 and Adversarial Loss: 119.82807159423828\n",
            "original Loss : 92.13368225097656 and Adversarial Loss: 83.47708892822266\n",
            "original Loss : 97.44273376464844 and Adversarial Loss: 91.85330200195312\n",
            "Epoch: 42\n",
            "original Loss : 136.18968200683594 and Adversarial Loss: 103.23693084716797\n",
            "original Loss : 102.05360412597656 and Adversarial Loss: 87.62613677978516\n",
            "original Loss : 57.72540283203125 and Adversarial Loss: 46.221923828125\n",
            "original Loss : 103.59219360351562 and Adversarial Loss: 67.82854461669922\n",
            "Epoch: 43\n",
            "original Loss : 61.7391471862793 and Adversarial Loss: 57.832584381103516\n",
            "original Loss : 46.88898468017578 and Adversarial Loss: 39.536048889160156\n",
            "original Loss : 44.977630615234375 and Adversarial Loss: 46.0421028137207\n",
            "original Loss : 57.278465270996094 and Adversarial Loss: 50.79258728027344\n",
            "Epoch: 44\n",
            "original Loss : 37.967559814453125 and Adversarial Loss: 39.247596740722656\n",
            "original Loss : 40.521263122558594 and Adversarial Loss: 33.17250442504883\n",
            "original Loss : 36.591514587402344 and Adversarial Loss: 30.667160034179688\n",
            "original Loss : 8354621.0 and Adversarial Loss: 3594469.5\n",
            "Epoch: 45\n",
            "original Loss : 1306.00634765625 and Adversarial Loss: 1619.0452880859375\n",
            "original Loss : 872.7357788085938 and Adversarial Loss: 1023.3023681640625\n",
            "original Loss : 570.6119384765625 and Adversarial Loss: 449.48681640625\n",
            "original Loss : 390.6080017089844 and Adversarial Loss: 252.53570556640625\n",
            "Epoch: 46\n",
            "original Loss : 302.8874816894531 and Adversarial Loss: 298.5689392089844\n",
            "original Loss : 400.55126953125 and Adversarial Loss: 331.9258117675781\n",
            "original Loss : 262.7074890136719 and Adversarial Loss: 283.3653869628906\n",
            "original Loss : 255.99148559570312 and Adversarial Loss: 175.9354705810547\n",
            "Epoch: 47\n",
            "original Loss : 123.73258972167969 and Adversarial Loss: 176.50137329101562\n",
            "original Loss : 210.1676025390625 and Adversarial Loss: 246.1821746826172\n",
            "original Loss : 157.28419494628906 and Adversarial Loss: 129.68560791015625\n",
            "original Loss : 136.83995056152344 and Adversarial Loss: 159.88369750976562\n",
            "Epoch: 48\n",
            "original Loss : 105.44002532958984 and Adversarial Loss: 102.02275085449219\n",
            "original Loss : 99.10938262939453 and Adversarial Loss: 100.81159210205078\n",
            "original Loss : 105.00456237792969 and Adversarial Loss: 93.5485610961914\n",
            "original Loss : 89.24118041992188 and Adversarial Loss: 73.96260070800781\n",
            "Epoch: 49\n",
            "original Loss : 103.31696319580078 and Adversarial Loss: 91.77140808105469\n",
            "original Loss : 75.291015625 and Adversarial Loss: 74.58929443359375\n",
            "original Loss : 66.56448364257812 and Adversarial Loss: 64.874267578125\n",
            "original Loss : 61.74665832519531 and Adversarial Loss: 45.83482360839844\n"
          ]
        }
      ],
      "source": [
        "seq_model = get_model([512,256,256,128,128],num_classes)\n",
        "norm = 'norm'\n",
        "train_adversarial_models(seq_model,epochs,data,epsilon,norm)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment_9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
