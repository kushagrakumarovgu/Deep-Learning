{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL3m4BVMQFvJ"
      },
      "source": [
        "Assignment 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ch5mOSF5zAh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation,Dense, Flatten, MaxPooling2D, Dropout, Conv2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDT6Ddzu53qe",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Number of GPUs Available: \",len(physical_devices))\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUCTTg_j6BYi",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Load CIFAR Data set.\n",
        "cifar10 = tf.keras.datasets.cifar10 # tf.keras.datasets.cifar10.load_data()\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(train_images[0].shape)\n",
        "#show the first image.\n",
        "plt.imshow(train_images[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEhO2p2i6FdV",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, train_labels.reshape(-1,).astype(np.int32)))\n",
        "data = data.shuffle(buffer_size=50000).batch(128).repeat()\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, test_labels.reshape(-1,).astype(np.int32))).batch(10000)\n",
        "\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3Ndcd-86HCD",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def Genreate_CNN_Arch(conv_layers,dense_layers,num_classes,lastlayeractivation='softmax'):\n",
        "  model = Sequential()\n",
        "  for idx in range(len(conv_layers)):\n",
        "    layer = conv_layers[idx]\n",
        "    if idx == 0:\n",
        "      model.add(Conv2D(layer[0],(layer[1],layer[1]),strides=(layer[2],layer[2]),padding=layer[3],activation=layer[4],input_shape=(32,32,3))) # input_shape=(32,32,3)\n",
        "    else:\n",
        "      model.add(Conv2D(layer[0],(layer[1],layer[1]),strides=(layer[2],layer[2]),padding=layer[3],activation=layer[4]))\n",
        "    if (len(layer) > 5 ): # Maxpooling \n",
        "      model.add(MaxPooling2D(pool_size=(layer[5],layer[5]),strides=(layer[6],layer[6]),padding=layer[7]))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Add Denselayer\n",
        "  for idx in range(len(dense_layers)):\n",
        "    layer = dense_layers[idx]\n",
        "    #print(\"layer: \",layer)\n",
        "    model.add(Dense(units=layer[0],activation=layer[1]))\n",
        "\n",
        "  #output layer.\n",
        "  #print(\"lastlayeractivation: \",lastlayeractivation)\n",
        "  model.add(Dense(num_classes,activation=lastlayeractivation ))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2BzhNaj6jU-",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def train_models(model,data,train_steps,parameters,optimizer,loss_func):\n",
        "  for step ,(img_batch,lbl_batch) in enumerate(data):\n",
        "    #print(\"step: \",step)\n",
        "    if step > train_steps:\n",
        "      break\n",
        "  \n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(img_batch)\n",
        "      xent = loss_func(lbl_batch, logits)\n",
        "\n",
        "    grads = tape.gradient(xent,parameters)\n",
        "\n",
        "    optimizer.apply_gradients(zip(grads,parameters))\n",
        "\n",
        "    if not step % 100:\n",
        "      predict = tf.argmax(logits,axis=1,output_type=tf.int32)\n",
        "      accuracy = tf.reduce_mean(tf.cast(tf.equal(predict,lbl_batch),tf.float32))\n",
        "      print(\"Loss: {} Accuracy: {}\".format(xent,accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lnCeeTW4YOz",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def get_test_accuracy(model,test_data):\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  for img_batch, lbl_batch in test_data:\n",
        "    test_accuracy(lbl_batch,model(img_batch))\n",
        "\n",
        "  print(\"Test Accuracy: \",test_accuracy.result())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyV8s8Qc6fAP",
        "outputId": "6bcb276b-515e-43f2-f53f-8833e42f72bd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 15, 15, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 6, 6, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 3, 3, 64)          4160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1000)              257000    \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 1,310,890\n",
            "Trainable params: 1,310,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Loss: 2.302449941635132 Accuracy: 0.1171875\n",
            "Loss: 2.214139938354492 Accuracy: 0.2109375\n",
            "Loss: 2.153449058532715 Accuracy: 0.2578125\n",
            "Loss: 2.1032161712646484 Accuracy: 0.34375\n",
            "Loss: 2.0431132316589355 Accuracy: 0.4140625\n",
            "Loss: 2.0810327529907227 Accuracy: 0.3828125\n",
            "Loss: 1.998665452003479 Accuracy: 0.453125\n",
            "Loss: 2.0282998085021973 Accuracy: 0.4140625\n",
            "Loss: 2.024502992630005 Accuracy: 0.4140625\n",
            "Loss: 2.0903170108795166 Accuracy: 0.3671875\n",
            "Loss: 2.017660617828369 Accuracy: 0.4296875\n",
            "Loss: 2.083132266998291 Accuracy: 0.3828125\n",
            "Loss: 2.0188283920288086 Accuracy: 0.46875\n",
            "Loss: 2.0897316932678223 Accuracy: 0.3515625\n",
            "Loss: 1.9985554218292236 Accuracy: 0.4453125\n",
            "Loss: 2.021787166595459 Accuracy: 0.421875\n",
            "Loss: 1.9682197570800781 Accuracy: 0.5078125\n",
            "Loss: 1.9118157625198364 Accuracy: 0.5390625\n",
            "Loss: 2.001154899597168 Accuracy: 0.46875\n",
            "Loss: 1.9047468900680542 Accuracy: 0.5703125\n",
            "Loss: 2.044778347015381 Accuracy: 0.4140625\n",
            "Loss: 1.9858524799346924 Accuracy: 0.46875\n",
            "Loss: 1.9433166980743408 Accuracy: 0.5\n",
            "Loss: 1.9649014472961426 Accuracy: 0.5\n",
            "Loss: 2.0241785049438477 Accuracy: 0.4453125\n",
            "Loss: 1.9244918823242188 Accuracy: 0.5390625\n",
            "Loss: 1.9290821552276611 Accuracy: 0.5078125\n",
            "Loss: 1.897885799407959 Accuracy: 0.5703125\n",
            "Loss: 1.923384189605713 Accuracy: 0.53125\n",
            "Loss: 2.0049734115600586 Accuracy: 0.4609375\n",
            "Loss: 1.9599642753601074 Accuracy: 0.5\n",
            "Loss: 1.9592546224594116 Accuracy: 0.484375\n",
            "Loss: 1.8792608976364136 Accuracy: 0.5546875\n",
            "Loss: 1.9797773361206055 Accuracy: 0.46875\n",
            "Loss: 1.9460339546203613 Accuracy: 0.515625\n",
            "Loss: 1.9891480207443237 Accuracy: 0.4609375\n",
            "Loss: 1.8847637176513672 Accuracy: 0.578125\n",
            "Loss: 1.9330099821090698 Accuracy: 0.53125\n",
            "Loss: 2.011249303817749 Accuracy: 0.4375\n",
            "Loss: 1.9094445705413818 Accuracy: 0.546875\n",
            "Loss: 1.9751873016357422 Accuracy: 0.4921875\n",
            "Loss: 1.970936894416809 Accuracy: 0.4765625\n",
            "Loss: 1.9298558235168457 Accuracy: 0.53125\n",
            "Loss: 1.9650853872299194 Accuracy: 0.512499988079071\n",
            "Loss: 1.8715993165969849 Accuracy: 0.5859375\n",
            "Loss: 1.9355008602142334 Accuracy: 0.53125\n",
            "Loss: 1.9317879676818848 Accuracy: 0.5078125\n",
            "Loss: 1.9092566967010498 Accuracy: 0.5390625\n",
            "Loss: 1.8268043994903564 Accuracy: 0.6484375\n",
            "Loss: 1.8502283096313477 Accuracy: 0.609375\n",
            "Loss: 1.8794994354248047 Accuracy: 0.5703125\n",
            "Loss: 1.9147688150405884 Accuracy: 0.53125\n",
            "Loss: 1.9162390232086182 Accuracy: 0.546875\n",
            "Loss: 1.9146069288253784 Accuracy: 0.5390625\n",
            "Loss: 1.9327728748321533 Accuracy: 0.53125\n",
            "Loss: 1.9444594383239746 Accuracy: 0.5234375\n",
            "Loss: 1.912445068359375 Accuracy: 0.5546875\n",
            "Loss: 1.9025516510009766 Accuracy: 0.5546875\n",
            "Loss: 1.8688485622406006 Accuracy: 0.59375\n",
            "Loss: 1.8439877033233643 Accuracy: 0.609375\n",
            "Loss: 1.8263962268829346 Accuracy: 0.625\n",
            "Loss: 1.919321894645691 Accuracy: 0.5390625\n",
            "Loss: 1.8727741241455078 Accuracy: 0.5703125\n",
            "Loss: 1.8801745176315308 Accuracy: 0.5703125\n",
            "Loss: 1.9065687656402588 Accuracy: 0.546875\n",
            "Loss: 1.8620669841766357 Accuracy: 0.609375\n",
            "Loss: 1.8833112716674805 Accuracy: 0.5859375\n",
            "Loss: 1.8710671663284302 Accuracy: 0.5859375\n",
            "Loss: 1.8394583463668823 Accuracy: 0.625\n",
            "Loss: 1.8174335956573486 Accuracy: 0.6328125\n",
            "Loss: 1.8823342323303223 Accuracy: 0.5859375\n",
            "Loss: 1.8923951387405396 Accuracy: 0.5703125\n",
            "Loss: 1.8893091678619385 Accuracy: 0.5703125\n",
            "Loss: 1.8318965435028076 Accuracy: 0.625\n",
            "Loss: 1.8596246242523193 Accuracy: 0.609375\n",
            "Loss: 1.8583095073699951 Accuracy: 0.6015625\n",
            "Loss: 1.8594965934753418 Accuracy: 0.6015625\n",
            "Loss: 1.865847110748291 Accuracy: 0.6015625\n",
            "Loss: 1.8291300535202026 Accuracy: 0.625\n",
            "Loss: 1.7852060794830322 Accuracy: 0.6796875\n",
            "Loss: 1.7927477359771729 Accuracy: 0.65625\n",
            "Loss: 1.8817166090011597 Accuracy: 0.5703125\n",
            "Loss: 1.9087276458740234 Accuracy: 0.5390625\n",
            "Loss: 1.924281120300293 Accuracy: 0.5390625\n",
            "Loss: 1.7622559070587158 Accuracy: 0.7109375\n",
            "Loss: 1.8982704877853394 Accuracy: 0.5625\n",
            "Loss: 1.790778636932373 Accuracy: 0.6953125\n",
            "Loss: 1.8183767795562744 Accuracy: 0.640625\n",
            "Loss: 1.8405680656433105 Accuracy: 0.625\n",
            "Loss: 1.851396083831787 Accuracy: 0.6171875\n",
            "Loss: 1.8668773174285889 Accuracy: 0.609375\n",
            "Loss: 1.877469778060913 Accuracy: 0.5703125\n",
            "Loss: 1.8076441287994385 Accuracy: 0.65625\n",
            "Loss: 1.834826946258545 Accuracy: 0.6171875\n",
            "Loss: 1.8468482494354248 Accuracy: 0.6171875\n",
            "Loss: 1.8611469268798828 Accuracy: 0.59375\n",
            "Loss: 1.8808640241622925 Accuracy: 0.578125\n",
            "Loss: 1.8190600872039795 Accuracy: 0.6484375\n",
            "Loss: 1.8142805099487305 Accuracy: 0.65625\n",
            "Loss: 1.8492684364318848 Accuracy: 0.6015625\n",
            "Loss: 1.8382656574249268 Accuracy: 0.625\n",
            "Loss: 1.8570340871810913 Accuracy: 0.609375\n",
            "Loss: 1.8784492015838623 Accuracy: 0.578125\n",
            "Loss: 1.837009310722351 Accuracy: 0.6171875\n",
            "Loss: 1.83454430103302 Accuracy: 0.6328125\n",
            "Loss: 1.8412007093429565 Accuracy: 0.609375\n",
            "Loss: 1.8805937767028809 Accuracy: 0.5703125\n",
            "Loss: 1.9434101581573486 Accuracy: 0.515625\n",
            "Loss: 1.8731807470321655 Accuracy: 0.5859375\n",
            "Loss: 1.8546861410140991 Accuracy: 0.609375\n",
            "Loss: 1.8666963577270508 Accuracy: 0.5859375\n",
            "Loss: 1.9241764545440674 Accuracy: 0.5234375\n",
            "Loss: 1.8679639101028442 Accuracy: 0.6015625\n",
            "Loss: 1.8471581935882568 Accuracy: 0.6171875\n",
            "Loss: 1.8695918321609497 Accuracy: 0.6015625\n",
            "Loss: 1.8247904777526855 Accuracy: 0.6328125\n",
            "Loss: 1.8300361633300781 Accuracy: 0.6328125\n",
            "Loss: 1.8369684219360352 Accuracy: 0.6171875\n",
            "Loss: 1.8283605575561523 Accuracy: 0.6328125\n",
            "Loss: 1.8106396198272705 Accuracy: 0.6484375\n",
            "Loss: 1.8714165687561035 Accuracy: 0.5859375\n",
            "Loss: 1.7885823249816895 Accuracy: 0.671875\n",
            "Loss: 1.843506097793579 Accuracy: 0.625\n",
            "Loss: 1.8514013290405273 Accuracy: 0.609375\n",
            "Loss: 1.8360499143600464 Accuracy: 0.6328125\n",
            "Loss: 1.8269309997558594 Accuracy: 0.640625\n",
            "Loss: 1.7925193309783936 Accuracy: 0.6640625\n",
            "Loss: 1.8833192586898804 Accuracy: 0.5703125\n",
            "Loss: 1.8077694177627563 Accuracy: 0.6484375\n",
            "Loss: 1.8085684776306152 Accuracy: 0.6484375\n",
            "Loss: 1.8892544507980347 Accuracy: 0.5625\n",
            "Loss: 1.7880033254623413 Accuracy: 0.671875\n",
            "Loss: 1.8743994235992432 Accuracy: 0.5859375\n",
            "Loss: 1.886763334274292 Accuracy: 0.5703125\n",
            "Loss: 1.7868194580078125 Accuracy: 0.6796875\n",
            "Loss: 1.8466397523880005 Accuracy: 0.6171875\n",
            "Loss: 1.856726050376892 Accuracy: 0.6015625\n",
            "Loss: 1.810845971107483 Accuracy: 0.6484375\n",
            "Loss: 1.7733848094940186 Accuracy: 0.6875\n",
            "Loss: 1.7951184511184692 Accuracy: 0.671875\n",
            "Loss: 1.8466390371322632 Accuracy: 0.609375\n",
            "Loss: 1.768532633781433 Accuracy: 0.6875\n",
            "Loss: 1.8536714315414429 Accuracy: 0.6171875\n",
            "Loss: 1.8197526931762695 Accuracy: 0.6484375\n",
            "Loss: 1.8885077238082886 Accuracy: 0.5703125\n",
            "Loss: 1.7481597661972046 Accuracy: 0.703125\n",
            "Loss: 1.8351778984069824 Accuracy: 0.625\n",
            "Loss: 1.8175593614578247 Accuracy: 0.640625\n",
            "Loss: 1.7455055713653564 Accuracy: 0.71875\n",
            "Loss: 1.8244681358337402 Accuracy: 0.640625\n",
            "Loss: 1.8254207372665405 Accuracy: 0.6328125\n",
            "Loss: 1.8692591190338135 Accuracy: 0.5859375\n",
            "Loss: 1.8562037944793701 Accuracy: 0.6015625\n",
            "Loss: 1.9293291568756104 Accuracy: 0.5234375\n",
            "Loss: 1.790201187133789 Accuracy: 0.6640625\n",
            "Loss: 1.9134842157363892 Accuracy: 0.546875\n",
            "Loss: 1.824183464050293 Accuracy: 0.640625\n",
            "Loss: 1.7703120708465576 Accuracy: 0.6875\n",
            "Loss: 1.8207035064697266 Accuracy: 0.640625\n",
            "Loss: 1.8010656833648682 Accuracy: 0.6640625\n",
            "Loss: 1.8625155687332153 Accuracy: 0.59375\n",
            "Loss: 1.861666202545166 Accuracy: 0.6015625\n",
            "Loss: 1.7678627967834473 Accuracy: 0.6953125\n",
            "Loss: 1.8648381233215332 Accuracy: 0.59375\n",
            "Loss: 1.869425654411316 Accuracy: 0.5859375\n",
            "Loss: 1.8240822553634644 Accuracy: 0.6328125\n",
            "Loss: 1.9127326011657715 Accuracy: 0.5390625\n",
            "Loss: 1.8394217491149902 Accuracy: 0.6171875\n",
            "Loss: 1.81472647190094 Accuracy: 0.65625\n",
            "Loss: 1.7472460269927979 Accuracy: 0.7109375\n",
            "Loss: 1.851614236831665 Accuracy: 0.609375\n",
            "Loss: 1.7738232612609863 Accuracy: 0.6875\n",
            "Loss: 1.843291997909546 Accuracy: 0.6171875\n",
            "Loss: 1.8375905752182007 Accuracy: 0.6171875\n",
            "Loss: 1.7967958450317383 Accuracy: 0.6640625\n",
            "Loss: 1.830812692642212 Accuracy: 0.625\n",
            "Loss: 1.8659331798553467 Accuracy: 0.59375\n",
            "Loss: 1.853226900100708 Accuracy: 0.609375\n",
            "Loss: 1.794677972793579 Accuracy: 0.6640625\n",
            "Loss: 1.832709789276123 Accuracy: 0.625\n",
            "Loss: 1.8173227310180664 Accuracy: 0.640625\n",
            "Loss: 1.7733972072601318 Accuracy: 0.6796875\n",
            "Loss: 1.7920588254928589 Accuracy: 0.6640625\n",
            "Loss: 1.8033051490783691 Accuracy: 0.65625\n",
            "Loss: 1.7954702377319336 Accuracy: 0.65625\n",
            "Loss: 1.8247065544128418 Accuracy: 0.640625\n",
            "Loss: 1.8367540836334229 Accuracy: 0.6171875\n",
            "Loss: 1.8174338340759277 Accuracy: 0.640625\n",
            "Loss: 1.7755730152130127 Accuracy: 0.6875\n",
            "Loss: 1.7674506902694702 Accuracy: 0.6953125\n",
            "Loss: 1.8274731636047363 Accuracy: 0.625\n",
            "Loss: 1.8158693313598633 Accuracy: 0.6484375\n",
            "Loss: 1.7932319641113281 Accuracy: 0.6640625\n",
            "Loss: 1.7731544971466064 Accuracy: 0.6796875\n",
            "Loss: 1.8296552896499634 Accuracy: 0.625\n",
            "Loss: 1.8039393424987793 Accuracy: 0.65625\n",
            "Loss: 1.738539218902588 Accuracy: 0.7109375\n",
            "Loss: 1.8380264043807983 Accuracy: 0.6171875\n",
            "Loss: 1.7385387420654297 Accuracy: 0.71875\n",
            "Loss: 1.7778178453445435 Accuracy: 0.6796875\n",
            "Loss: 1.843318223953247 Accuracy: 0.609375\n",
            "Test Accuracy:  tf.Tensor(0.5679, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "train_steps = 20000\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "loss_func = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# number_of_filters, filter_size, convstride, convpadding, activation, max_pool_size, maxpoolstrides, maxpoolpadding.\n",
        "conv_layers = [[64,3,2,\"valid\",'relu',1,2,\"valid\"],[64,3,1,\"valid\",'relu',2,1,\"valid\"],[64,1,2,\"valid\",'relu',2,1,\"valid\"]]\n",
        "#number_of_units, activation function.\n",
        "dense_layers = [[1000,'relu'],[1000,'relu']]\n",
        "\n",
        "model = Genreate_CNN_Arch(conv_layers,dense_layers,10)\n",
        "parameters = model.trainable_variables\n",
        "model.summary()\n",
        "train_models(model,data,train_steps,parameters,optimizer,loss_func)\n",
        "get_test_accuracy(model,test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0G6ke946mew"
      },
      "source": [
        "Architecture2: Filter size = 1 * 1 , 2 conv layers with maxpooling, Dense layer = 100 and last layer activation as relu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeoYAPn2BvmZ",
        "outputId": "5a3cab48-fef6-4845-d73e-5857aa219de5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_35 (Conv2D)           (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 16, 16, 64)        4160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 14400)             0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1000)              14401000  \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1000)              1001000   \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 15,416,426\n",
            "Trainable params: 15,416,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Loss: 2.3026182651519775 Accuracy: 0.1015625\n",
            "Loss: 2.110424041748047 Accuracy: 0.3671875\n",
            "Loss: 2.141417980194092 Accuracy: 0.3046875\n",
            "Loss: 2.052079200744629 Accuracy: 0.3984375\n",
            "Loss: 2.039438247680664 Accuracy: 0.421875\n",
            "Loss: 2.0148942470550537 Accuracy: 0.4453125\n",
            "Loss: 2.0041794776916504 Accuracy: 0.4453125\n",
            "Loss: 2.0087437629699707 Accuracy: 0.46875\n",
            "Loss: 2.027566909790039 Accuracy: 0.4375\n",
            "Loss: 2.018784999847412 Accuracy: 0.4375\n",
            "Loss: 1.87798011302948 Accuracy: 0.5859375\n",
            "Loss: 1.891745686531067 Accuracy: 0.5546875\n",
            "Loss: 1.974294900894165 Accuracy: 0.484375\n",
            "Loss: 1.9334583282470703 Accuracy: 0.515625\n",
            "Loss: 1.9546470642089844 Accuracy: 0.5\n",
            "Loss: 1.8718397617340088 Accuracy: 0.6015625\n",
            "Loss: 1.9836981296539307 Accuracy: 0.46875\n",
            "Loss: 1.8314720392227173 Accuracy: 0.640625\n",
            "Loss: 1.9542665481567383 Accuracy: 0.5078125\n",
            "Loss: 1.9154913425445557 Accuracy: 0.546875\n",
            "Loss: 1.9060859680175781 Accuracy: 0.546875\n",
            "Test Accuracy:  tf.Tensor(0.5231, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "loss_func = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# number_of_filters, filter_size, convstride, convpadding, activation, max_pool_size, maxpoolstrides, maxpoolpadding.\n",
        "conv_layers = [[64,1,1,\"valid\",'relu',1,2,\"valid\"],[64,1,1,\"valid\",'relu',2,1,\"valid\"]]\n",
        "#number_of_units, activation function.\n",
        "dense_layers = [[1000,'relu'],[1000,'relu']]\n",
        "\n",
        "model = Genreate_CNN_Arch(conv_layers,dense_layers,10)\n",
        "parameters = model.trainable_variables\n",
        "model.summary()\n",
        "train_models(model,data,train_steps,parameters,optimizer,loss_func)\n",
        "get_test_accuracy(model,test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbyVVEGX-Ir0"
      },
      "source": [
        "Architecture 3 : filter size = image size ( 28 * 28 ) for both conv layers. It will lead to failing of model generation since output will very small for next layer to apply the filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "Z4WC2RZO-h5U",
        "outputId": "b0060adc-2dba-4481-dac3-f7fb5e508d8e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1811\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 28 from 3 for '{{node conv2d_38/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](max_pooling2d_35/MaxPool, conv2d_38/Conv2D/ReadVariableOp)' with input shapes: [?,3,3,64], [28,28,64,64].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3f29fc38f3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdense_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenreate_CNN_Arch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdense_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#parameter initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-eeb61a5015e7>\u001b[0m in \u001b[0;36mGenreate_CNN_Arch\u001b[0;34m(conv_layers, dense_layers, num_classes, lastlayeractivation)\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# input_shape=(32,32,3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Maxpooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2590\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2592\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2593\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2594\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    977\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    980\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    591\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3483\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3484\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3485\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3486\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1975\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1813\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 28 from 3 for '{{node conv2d_38/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](max_pooling2d_35/MaxPool, conv2d_38/Conv2D/ReadVariableOp)' with input shapes: [?,3,3,64], [28,28,64,64]."
          ]
        }
      ],
      "source": [
        "train_steps = 2000\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "loss_func = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# number_of_filters, filter_size, convstride, convpadding, activation, max_pool_size, maxpoolstrides, maxpoolpadding.\n",
        "conv_layers = [[64,28,1,\"valid\",'relu',1,2,\"valid\"],[64,28,1,\"valid\",'relu',2,1,\"valid\"]]\n",
        "#number_of_units, activation function.\n",
        "dense_layers = [[1000,'relu']]\n",
        "\n",
        "model = Genreate_CNN_Arch(conv_layers,dense_layers,10)\n",
        "#parameter initialization\n",
        "parameters = model.trainable_variables\n",
        "model.summary()\n",
        "train_models_new(model,data_mf,train_steps,parameters,optimizer,loss_func)\n",
        "get_test_accuracy(model,test_data_mf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUKBYzumWNfl",
        "outputId": "ce30f11b-6607-402a-868a-2f2f85df05d7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_39 (Conv2D)           (None, 31, 31, 16)        208       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 16, 16, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 15, 15, 32)        2080      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_12 (Flatten)         (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 64)                401472    \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 404,410\n",
            "Trainable params: 404,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Loss: 2.3033413887023926 Accuracy: 0.1171875\n",
            "Loss: 2.1679790019989014 Accuracy: 0.2734375\n",
            "Loss: 2.0418899059295654 Accuracy: 0.4140625\n",
            "Loss: 2.112607955932617 Accuracy: 0.3359375\n",
            "Loss: 2.0293045043945312 Accuracy: 0.4296875\n",
            "Loss: 2.0263075828552246 Accuracy: 0.421875\n",
            "Loss: 2.129568576812744 Accuracy: 0.328125\n",
            "Loss: 1.9741690158843994 Accuracy: 0.4765625\n",
            "Loss: 2.0338704586029053 Accuracy: 0.421875\n",
            "Loss: 1.948521375656128 Accuracy: 0.5078125\n",
            "Loss: 2.0190505981445312 Accuracy: 0.4296875\n",
            "Loss: 2.065340042114258 Accuracy: 0.390625\n",
            "Loss: 1.9856927394866943 Accuracy: 0.4765625\n",
            "Loss: 2.0221264362335205 Accuracy: 0.4375\n",
            "Loss: 2.0193140506744385 Accuracy: 0.4375\n",
            "Loss: 2.0413460731506348 Accuracy: 0.421875\n",
            "Loss: 2.1185436248779297 Accuracy: 0.34375\n",
            "Loss: 2.142754077911377 Accuracy: 0.3203125\n",
            "Loss: 2.0319342613220215 Accuracy: 0.4375\n",
            "Loss: 2.0135135650634766 Accuracy: 0.453125\n",
            "Loss: 2.0020649433135986 Accuracy: 0.4609375\n",
            "Loss: 2.0041344165802 Accuracy: 0.4609375\n",
            "Loss: 2.0519745349884033 Accuracy: 0.40625\n",
            "Loss: 2.0198235511779785 Accuracy: 0.4375\n",
            "Loss: 1.9817101955413818 Accuracy: 0.484375\n",
            "Loss: 2.0986685752868652 Accuracy: 0.359375\n",
            "Loss: 2.0511868000030518 Accuracy: 0.40625\n",
            "Loss: 2.077083110809326 Accuracy: 0.3828125\n",
            "Loss: 2.065307140350342 Accuracy: 0.3984375\n",
            "Loss: 2.0831942558288574 Accuracy: 0.375\n",
            "Loss: 1.9784562587738037 Accuracy: 0.484375\n",
            "Loss: 2.211259126663208 Accuracy: 0.25\n",
            "Loss: 2.1467270851135254 Accuracy: 0.3125\n",
            "Loss: 2.2267961502075195 Accuracy: 0.234375\n",
            "Loss: 2.1562085151672363 Accuracy: 0.3046875\n",
            "Loss: 2.1090497970581055 Accuracy: 0.3515625\n",
            "Loss: 2.105401039123535 Accuracy: 0.359375\n",
            "Loss: 2.016057252883911 Accuracy: 0.4453125\n",
            "Loss: 2.101869821548462 Accuracy: 0.359375\n",
            "Loss: 2.015833854675293 Accuracy: 0.4453125\n",
            "Loss: 2.1485023498535156 Accuracy: 0.3125\n",
            "Loss: 2.195467710494995 Accuracy: 0.265625\n",
            "Loss: 2.209226131439209 Accuracy: 0.25\n",
            "Loss: 2.047733783721924 Accuracy: 0.4124999940395355\n",
            "Loss: 2.0250983238220215 Accuracy: 0.4375\n",
            "Loss: 2.2345876693725586 Accuracy: 0.2265625\n",
            "Loss: 2.0859265327453613 Accuracy: 0.375\n",
            "Loss: 2.250225067138672 Accuracy: 0.2109375\n",
            "Loss: 2.3830251693725586 Accuracy: 0.078125\n",
            "Loss: 2.3439626693725586 Accuracy: 0.1171875\n",
            "Loss: 2.3361501693725586 Accuracy: 0.125\n",
            "Loss: 2.2502126693725586 Accuracy: 0.2109375\n",
            "Loss: 2.109708309173584 Accuracy: 0.3515625\n",
            "Loss: 2.1642820835113525 Accuracy: 0.296875\n",
            "Loss: 2.0838441848754883 Accuracy: 0.375\n",
            "Loss: 2.086174488067627 Accuracy: 0.375\n",
            "Loss: 2.0859670639038086 Accuracy: 0.375\n",
            "Loss: 2.047092914581299 Accuracy: 0.4140625\n",
            "Loss: 2.065258502960205 Accuracy: 0.3984375\n",
            "Loss: 2.2345876693725586 Accuracy: 0.2265625\n",
            "Loss: 2.196037530899048 Accuracy: 0.265625\n",
            "Loss: 2.1483235359191895 Accuracy: 0.3125\n",
            "Loss: 2.140831232070923 Accuracy: 0.3203125\n",
            "Loss: 2.195707321166992 Accuracy: 0.265625\n",
            "Loss: 1.992400050163269 Accuracy: 0.46875\n",
            "Loss: 2.0778305530548096 Accuracy: 0.3828125\n",
            "Loss: 2.1877126693725586 Accuracy: 0.2734375\n",
            "Loss: 2.1638851165771484 Accuracy: 0.296875\n",
            "Loss: 2.2111501693725586 Accuracy: 0.25\n",
            "Loss: 2.164259433746338 Accuracy: 0.296875\n",
            "Loss: 2.172015428543091 Accuracy: 0.2890625\n",
            "Loss: 2.273562431335449 Accuracy: 0.1875\n",
            "Loss: 2.1408376693725586 Accuracy: 0.3203125\n",
            "Loss: 2.1095876693725586 Accuracy: 0.3515625\n",
            "Loss: 2.2866785526275635 Accuracy: 0.171875\n",
            "Loss: 2.1135733127593994 Accuracy: 0.34375\n",
            "Loss: 2.0236501693725586 Accuracy: 0.4375\n",
            "Loss: 2.1408376693725586 Accuracy: 0.3203125\n",
            "Loss: 2.1330251693725586 Accuracy: 0.328125\n",
            "Loss: 2.0861501693725586 Accuracy: 0.375\n",
            "Loss: 2.2424001693725586 Accuracy: 0.21875\n",
            "Loss: 2.2111501693725586 Accuracy: 0.25\n",
            "Loss: 2.3361501693725586 Accuracy: 0.125\n",
            "Loss: 2.2814626693725586 Accuracy: 0.1796875\n",
            "Loss: 2.2970657348632812 Accuracy: 0.1640625\n",
            "Loss: 2.2267751693725586 Accuracy: 0.234375\n",
            "Loss: 2.3361501693725586 Accuracy: 0.125\n",
            "Loss: 2.2179853916168213 Accuracy: 0.2421875\n",
            "Loss: 2.1877126693725586 Accuracy: 0.2734375\n",
            "Loss: 2.2970876693725586 Accuracy: 0.1640625\n",
            "Loss: 2.3517751693725586 Accuracy: 0.109375\n",
            "Loss: 2.3595876693725586 Accuracy: 0.1015625\n",
            "Loss: 2.3674001693725586 Accuracy: 0.09375\n",
            "Loss: 2.3361501693725586 Accuracy: 0.125\n",
            "Loss: 2.3908376693725586 Accuracy: 0.0703125\n",
            "Loss: 2.3205251693725586 Accuracy: 0.140625\n",
            "Loss: 2.3752126693725586 Accuracy: 0.0859375\n",
            "Loss: 2.3361501693725586 Accuracy: 0.125\n",
            "Loss: 2.3752126693725586 Accuracy: 0.0859375\n",
            "Loss: 2.3674001693725586 Accuracy: 0.09375\n",
            "Loss: 2.359325885772705 Accuracy: 0.1015625\n",
            "Test Accuracy:  tf.Tensor(0.1013, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "train_steps = 10000\n",
        "optimizer = tf.keras.optimizers.Adam(0.01)\n",
        "loss_func = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# number_of_filters, filter_size, convstride, convpadding, activation, max_pool_size, maxpoolstrides, maxpoolpadding.\n",
        "conv_layers = [[16,2,1,\"valid\",'relu',1,2,\"valid\"],[32,2,1,\"valid\",'relu',2,1,\"valid\"]]\n",
        "#number_of_units, activation function.\n",
        "dense_layers = [[64,'relu']]\n",
        "\n",
        "model = Genreate_CNN_Arch(conv_layers,dense_layers,10)\n",
        "parameters = model.trainable_variables\n",
        "model.summary()\n",
        "train_models(model,data,train_steps,parameters,optimizer,loss_func)\n",
        "get_test_accuracy(model,test_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment_3_CIFAR.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
