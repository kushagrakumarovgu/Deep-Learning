{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du67mA__CQ_w"
      },
      "source": [
        "Assignment 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TWhuyVQ7t081",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFb6czA3YfNy",
        "outputId": "df68554f-d09d-412e-e5f7-ba7cbd69d38b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Oct  8 2020, 12:12:24) \n",
            "[GCC 8.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErVoPRfCuN5d",
        "outputId": "cf0362d3-73f4-4e7c-fae5-c54385683106",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hin_sentence:  आपका * स्वागत है।  & %\n",
            "<start> May I borrow this book ? <end>\n",
            "<start> आपका स्वागत है। <end>\n"
          ]
        }
      ],
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "\n",
        "  #w = unicode_to_ascii(w.lower().strip()) # No impact on output. Do we need this ....\n",
        "  \n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  #print(w)\n",
        "  hindialpha = \"\"\n",
        "  for char in range(2304,2432):\n",
        "    hindialpha += \"\\\\u0\" + str(hex(char)[2:])\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  #w = re.sub(r\"[^a-zA-Z?.!,¿।]+\" + hindialpha , \" \", w)\n",
        "\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,\\u0900\\u0901\\u0902\\u0903\\u0904\\u0905\\u0906\\u0907\\u0908\\u0909\\u090a\\u090b\\u090c\\u090d\\u090e\\u090f\\u0910\\u0911\\u0912\\u0913\\u0914\\u0915\\u0916\\u0917\\u0918\\u0919\\u091a\\u091b\\u091c\\u091d\\u091e\\u091f\\u0920\\u0921\\u0922\\u0923\\u0924\\u0925\\u0926\\u0927\\u0928\\u0929\\u092a\\u092b\\u092c\\u092d\\u092e\\u092f\\u0930\\u0931\\u0932\\u0933\\u0934\\u0935\\u0936\\u0937\\u0938\\u0939\\u093a\\u093b\\u093c\\u093d\\u093e\\u093f\\u0940\\u0941\\u0942\\u0943\\u0944\\u0945\\u0946\\u0947\\u0948\\u0949\\u094a\\u094b\\u094c\\u094d\\u094e\\u094f\\u0950\\u0951\\u0952\\u0953\\u0954\\u0955\\u0956\\u0957\\u0958\\u0959\\u095a\\u095b\\u095c\\u095d\\u095e\\u095f\\u0960\\u0961\\u0962\\u0963\\u0964\\u0965\\u0966\\u0967\\u0968\\u0969\\u096a\\u096b\\u096c\\u096d\\u096e\\u096f\\u0970\\u0971\\u0972\\u0973\\u0974\\u0975\\u0976\\u0977\\u0978\\u0979\\u097a\\u097b\\u097c\\u097d\\u097e\\u097f]+\", \" \", w)\n",
        "\n",
        "  #w = re.sub(r\"[^a-zA-Z?.|\\W\\d_?.!|]+\",\" \",w)\n",
        "\n",
        "  #print(w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w\n",
        "\n",
        "en_sentence = u\"May I borrow this book? *^%\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "hin_sentence = u\"आपका * स्वागत है।  & %\"\n",
        "print(\"hin_sentence: \",hin_sentence)\n",
        "print(preprocess_sentence(en_sentence))\n",
        "# print(preprocess_sentence(sp_sentence)) # .encode('utf-8')\n",
        "print(preprocess_sentence(hin_sentence)) # .encode('utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6qtkDjKt-Y4",
        "outputId": "29cdff88-5029-41a0-d758-e6d7d3b8cd5a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<start> When I was a kid , touching bugs didn t bother me a bit . Now I can hardly stand looking at pictures of them . <end>\n",
            "<start> जब मैं बच्चा था , मुझे कीड़ों को छूने से कोई परेशानी नहीं होती थी , पर अब मैं उनकी तस्वीरें देखना भी बर्दाश्त नहीं कर सकता। <end>\n"
          ]
        }
      ],
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:-1]]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)\n",
        "\n",
        "en, hin = create_dataset('hin.txt', None)\n",
        "print(en[-1])\n",
        "print(hin[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWr76tMvuk53",
        "outputId": "8da7a3ac-628e-49fb-cc61-2629b4fcc35b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_tensor: [[   1  780   74 ...    0    0    0]\n",
            " [   1 1487   74 ...    0    0    0]\n",
            " [   1 1488  781 ...    0    0    0]\n",
            " ...\n",
            " [   1 3053  778 ...    0    0    0]\n",
            " [   1  146   64 ...    0    0    0]\n",
            " [   1  143    7 ...   27  158    2]]\n",
            "input_tensor[0]: [  1 780  74   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0]\n",
            "input_tensor shape: (2923, 29)\n",
            "target_tensor: [[   1 1282   64 ...    0    0    0]\n",
            " [   1   96   64 ...    0    0    0]\n",
            " [   1  561    3 ...    0    0    0]\n",
            " ...\n",
            " [   1 2363   10 ...    0    0    0]\n",
            " [   1   80   16 ...    0    0    0]\n",
            " [   1   67    5 ...  149    3    2]]\n",
            "target_tensor[0]: [   1 1282   64    2    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "target_tensor shape: (2923, 28)\n",
            "inp_lang: <keras_preprocessing.text.Tokenizer object at 0x7f59db997320>\n",
            "targ_lang: <keras_preprocessing.text.Tokenizer object at 0x7f59db997780>\n",
            "2338 2338 585 585\n"
          ]
        }
      ],
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  \n",
        "  # Updates internal vocabulary based on a list of texts.\n",
        "  # In the case where texts contains lists, we assume each entry of the lists to be a token.\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  #print(\"lang_tokenizer.fit_on_texts(lang): {}\".format(lang_tokenizer.fit_on_texts(lang)))  # Returns None\n",
        "  \n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  \n",
        "  # print(\"lang_tokenizer: {}\".format(lang_tokenizer))\n",
        "  # print(\"tensor: {}\".format(tensor))\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  # print(\"targ_lang: {}\".format(targ_lang))\n",
        "  # print(\"inp_lang: {}\".format(inp_lang))\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  # print(\"input_tensor: {}\".format(input_tensor))\n",
        "  # print(\"inp_lang_tokenizer: {}\".format(inp_lang_tokenizer))\n",
        "  # print(\"target_tensor: {}\".format(target_tensor))\n",
        "  # print(\"targ_lang_tokenizer: {}\".format(targ_lang_tokenizer))\n",
        "  # input()\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n",
        "\n",
        "\n",
        "# Try experimenting with the size of that dataset\n",
        "num_examples =  2923 #En30000tire Data set  #\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(\"hin.txt\", num_examples) # hin.txt\n",
        "\n",
        "print(\"input_tensor: {}\".format(input_tensor))\n",
        "print(\"input_tensor[0]: {}\".format(input_tensor[0]))\n",
        "print(\"input_tensor shape: {}\".format(input_tensor.shape))\n",
        "print(\"target_tensor: {}\".format(target_tensor))\n",
        "print(\"target_tensor[0]: {}\".format(target_tensor[0]))\n",
        "print(\"target_tensor shape: {}\".format(target_tensor.shape))\n",
        "print(\"inp_lang: {}\".format(inp_lang))\n",
        "print(\"targ_lang: {}\".format(targ_lang))\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJZ2uzOwu4v4",
        "outputId": "3bd0a9ab-a58a-4616-b654-2d3384393ae1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "8 ----> वह\n",
            "10 ----> मुझे\n",
            "106 ----> भारत\n",
            "13 ----> के\n",
            "134 ----> बारे\n",
            "5 ----> में\n",
            "2521 ----> कहानियाँ\n",
            "2522 ----> सुनाया\n",
            "94 ----> करता\n",
            "23 ----> था।\n",
            "2 ----> <end>\n",
            " 1282 ----> मतलब\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "11 ----> he\n",
            "253 ----> used\n",
            "6 ----> to\n",
            "142 ----> tell\n",
            "17 ----> me\n",
            "1933 ----> stories\n",
            "79 ----> about\n",
            "86 ----> india\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            " 1282 ----> wow\n",
            "index_word_dict_len: 2367\n",
            " 2368 ----> UNKNOWN\n",
            "{1: '<start>', 2: '<end>', 3: '.', 4: 'the', 5: 'i', 6: 'to', 7: 'you', 8: '?', 9: 'a', 10: 'is', 11: 'he', 12: 'of', 13: 't', 14: 'in', 15: 'it', 16: 'my', 17: 'me', 18: 'have', 19: 'this', 20: 'she', 21: 'do', 22: 'that', 23: 'was', 24: ',', 25: 's', 26: 'for', 27: 'are', 28: 'what', 29: 'we', 30: 'his', 31: 'your', 32: 'don', 33: 'can', 34: 'will', 35: 'on', 36: 'at', 37: 'him', 38: 'not', 39: 'her', 40: 'go', 41: 'like', 42: 'tom', 43: 'with', 44: 'be', 45: 'm', 46: 'how', 47: 'and', 48: 'know', 49: 'has', 50: 'there', 51: 'all', 52: 'up', 53: 'they', 54: 'very', 55: 'time', 56: 'come', 57: 'as', 58: 'had', 59: 'want', 60: 'from', 61: 'please', 62: 'did', 63: 'here', 64: '!', 65: 'by', 66: 'out', 67: 'when', 68: 'get', 69: 'll', 70: 'am', 71: 'an', 72: 'going', 73: 'no', 74: 'father', 75: 'been', 76: 'one', 77: 'book', 78: 'take', 79: 'about', 80: 'if', 81: 'where', 82: 'would', 83: 'day', 84: 'were', 85: 'money', 86: 'india', 87: 'but', 88: 'us', 89: 'let', 90: 'now', 91: 'make', 92: 'today', 93: 'long', 94: 'two', 95: 'didn', 96: 'help', 97: 'who', 98: 'good', 99: 'live', 100: 'see', 101: 'tomorrow', 102: 'must', 103: 'back', 104: 'man', 105: 'our', 106: 'home', 107: 'car', 108: 're', 109: 'should', 110: 'so', 111: 'work', 112: 'these', 113: 'english', 114: 'yesterday', 115: 'never', 116: 'room', 117: 'think', 118: 've', 119: 'house', 120: 'many', 121: 'too', 122: 'every', 123: 'made', 124: 'last', 125: 'much', 126: 'may', 127: 'went', 128: 'old', 129: 'nothing', 130: 'mother', 131: 'than', 132: 'off', 133: 'again', 134: 'dog', 135: 'give', 136: 'could', 137: 'any', 138: 'more', 139: 'people', 140: 'door', 141: 'some', 142: 'tell', 143: 'mary', 144: 'speak', 145: 'always', 146: 'got', 147: 'well', 148: 'down', 149: 'them', 150: 'children', 151: 'turn', 152: 'night', 153: 'train', 154: 'say', 155: 'why', 156: 'leave', 157: 'call', 158: 'lot', 159: 'put', 160: 'school', 161: 'before', 162: 'happy', 163: 'doctor', 164: 'isn', 165: 'teacher', 166: 'into', 167: 'or', 168: 'new', 169: 'read', 170: 'job', 171: 'water', 172: 'way', 173: 'their', 174: 'away', 175: 'tired', 176: 'left', 177: 'everyone', 178: 'open', 179: 'problem', 180: 'right', 181: 'believe', 182: 'true', 183: 'use', 184: 'next', 185: 'soon', 186: 'ten', 187: 'keep', 188: 'because', 189: 'world', 190: 'answer', 191: 'once', 192: 'drive', 193: 'year', 194: 'hard', 195: 'saw', 196: 'really', 197: 'd', 198: 'few', 199: 'three', 200: 'times', 201: 'seen', 202: 'letter', 203: 'won', 204: 'both', 205: 'wrong', 206: 'big', 207: 'birthday', 208: 'feel', 209: 'watch', 210: 'cut', 211: 'met', 212: 'does', 213: 'books', 214: 'doing', 215: 'little', 216: 'tea', 217: 'couldn', 218: 'afraid', 219: 'without', 220: 'looking', 221: 'said', 222: 'morning', 223: 'lost', 224: 'came', 225: 'understand', 226: 'yet', 227: 'play', 228: 'need', 229: 'girl', 230: 'while', 231: 'years', 232: 'other', 233: 'such', 234: 'japan', 235: 'something', 236: 'love', 237: 'try', 238: 'bed', 239: 'around', 240: 'likes', 241: 'after', 242: 'told', 243: 'talking', 244: 'friends', 245: 'bought', 246: 'tried', 247: 'wanted', 248: 'mind', 249: 'gave', 250: 'asked', 251: 'clock', 252: 'doesn', 253: 'used', 254: 'six', 255: 'able', 256: 'cannot', 257: 'month', 258: 'took', 259: 'alone', 260: 'coming', 261: 'buy', 262: 'stay', 263: 'study', 264: 'early', 265: 'running', 266: 'first', 267: 'meet', 268: 'bad', 269: 'already', 270: 'news', 271: 'ask', 272: 'sister', 273: 'caught', 274: 'just', 275: 'easy', 276: 'looked', 277: 'shoes', 278: 'river', 279: 'comes', 280: 'o', 281: 'own', 282: 'better', 283: 'ever', 284: 'between', 285: 'medicine', 286: 'usually', 287: 'brother', 288: 'smoking', 289: 'days', 290: 'fun', 291: 'broke', 292: 'cold', 293: 'knows', 294: 'boy', 295: 'drink', 296: 'fish', 297: 'dinner', 298: 'person', 299: 'friend', 300: 'eyes', 301: 'abroad', 302: 'married', 303: 'small', 304: 'felt', 305: 'city', 306: 'box', 307: 'health', 308: 'week', 309: 'walk', 310: 'happened', 311: 'station', 312: 'hair', 313: 'coffee', 314: 'difficult', 315: 'enough', 316: 'tv', 317: 'accident', 318: 'wants', 319: 'sit', 320: 'nobody', 321: 'things', 322: 'busy', 323: 'town', 324: 'stop', 325: 'mine', 326: 'name', 327: 'questions', 328: 'reading', 329: 'life', 330: 'poor', 331: 'died', 332: 'another', 333: 'ran', 334: 'party', 335: 'five', 336: 'found', 337: 'almost', 338: 'question', 339: 'mistakes', 340: 'wait', 341: 'die', 342: 'baby', 343: 'food', 344: 'eight', 345: 'afternoon', 346: 'london', 347: 'watching', 348: 'idea', 349: 'hours', 350: 'parents', 351: 'possible', 352: 'saying', 353: 'forgot', 354: 'fly', 355: 'done', 356: 'fire', 357: 'swim', 358: 'flowers', 359: 'hot', 360: 'music', 361: 'look', 362: 'ill', 363: 'heard', 364: 'noise', 365: 'power', 366: 'nice', 367: 'hurry', 368: 'story', 369: 'talk', 370: 'sure', 371: 'later', 372: 'kept', 373: 'write', 374: 'language', 375: 'hand', 376: 'became', 377: 'each', 378: 'bus', 379: 'anyone', 380: 'king', 381: 'beautiful', 382: 'someone', 383: 'large', 384: 'police', 385: 'america', 386: 'others', 387: 'desk', 388: 'sorry', 389: 'bicycle', 390: 'eat', 391: 'care', 392: 'rain', 393: 'slowly', 394: 'instead', 395: 'written', 396: 'weather', 397: 'kind', 398: 'behind', 399: 'since', 400: 'difference', 401: 'birds', 402: 'excuse', 403: 'move', 404: 'sick', 405: 'bring', 406: 'free', 407: 'son', 408: 'clean', 409: 'phone', 410: 'only', 411: 'ready', 412: 'boys', 413: 'anything', 414: 'getting', 415: 'along', 416: 'sleep', 417: 'works', 418: 'address', 419: 'born', 420: 'yours', 421: 'family', 422: 'which', 423: 'everybody', 424: 'called', 425: 'lives', 426: 'rich', 427: 'yourself', 428: 'waiting', 429: 'fever', 430: 'rumor', 431: 'size', 432: 'visit', 433: 'wherever', 434: 'thing', 435: 'often', 436: 'forget', 437: 'country', 438: 'playing', 439: 'wish', 440: 'outside', 441: 'makes', 442: 'tennis', 443: 'shouldn', 444: 'homework', 445: 'wife', 446: 'minutes', 447: 'learn', 448: 'window', 449: 'standing', 450: 'picture', 451: 'class', 452: 'best', 453: 'interesting', 454: 'raining', 455: 'french', 456: 'spoken', 457: 'clothes', 458: 'telephone', 459: 'capital', 460: 'wouldn', 461: 'find', 462: 'hear', 463: 'village', 464: 'child', 465: 'longer', 466: 'through', 467: 'whether', 468: 'pay', 469: 'hungry', 470: 'smiled', 471: 'dogs', 472: 'summer', 473: 'bag', 474: 'wash', 475: 'run', 476: 'guitar', 477: 'black', 478: 'crying', 479: 'talks', 480: 'began', 481: 'cried', 482: 'haven', 483: 'hands', 484: 'blue', 485: 'against', 486: 'war', 487: 'matter', 488: 'closed', 489: 'those', 490: 'still', 491: 'television', 492: 'looks', 493: 'seems', 494: 'taking', 495: 'baseball', 496: 'working', 497: 'plan', 498: 'eating', 499: 'apple', 500: 'sunday', 501: 'quickly', 502: 'dress', 503: 'disappointed', 504: 'eggs', 505: 'reap', 506: 'sow', 507: 'lose', 508: 'quit', 509: 'business', 510: 'begins', 511: 'anymore', 512: 'easily', 513: 'decided', 514: 'sky', 515: 'fell', 516: 'studying', 517: 'late', 518: 'sugar', 519: 'rains', 520: 'then', 521: 'air', 522: 'apples', 523: 'larger', 524: 'might', 525: 'interested', 526: 'thank', 527: 'changing', 528: 'suddenly', 529: 'europe', 530: 'cup', 531: 'number', 532: 'office', 533: 'set', 534: 'grandmother', 535: 'hobby', 536: 'population', 537: 'ship', 538: 'across', 539: 'surprised', 540: 'anxious', 541: 'men', 542: 'plane', 543: 'china', 544: 'finish', 545: 'making', 546: 'heat', 547: 'whoever', 548: 'strange', 549: 'being', 550: 'mountain', 551: 'hospital', 552: 'advice', 553: 'finished', 554: 'bit', 555: 'machine', 556: 'known', 557: 'necessary', 558: 'different', 559: 'arrested', 560: 'england', 561: 'jump', 562: 'laughed', 563: 'sing', 564: 'stood', 565: 'strong', 566: 'cake', 567: 'attend', 568: 'fat', 569: 'history', 570: 'god', 571: 'over', 572: 'cooked', 573: 'beauty', 574: 'age', 575: 'remember', 576: 'april', 577: 'key', 578: 'whose', 579: 'bank', 580: 'sight', 581: 'truth', 582: 'earth', 583: 'hope', 584: 'mistake', 585: 'worked', 586: 'dark', 587: 'snow', 588: 'started', 589: 'expensive', 590: 'thief', 591: 'taxi', 592: 'shirt', 593: 'clear', 594: 'airport', 595: 'angry', 596: 'agree', 597: 'red', 598: 'broken', 599: 'return', 600: 'secret', 601: 'policeman', 602: 'swimming', 603: 'close', 604: 'lake', 605: 'game', 606: 'knew', 607: 'learned', 608: 'japanese', 609: 'empty', 610: 'woman', 611: 'prefer', 612: 'myself', 613: 'nine', 614: 'rather', 615: 'light', 616: 'memory', 617: 'milk', 618: 'abandoned', 619: 'tends', 620: 'present', 621: 'chair', 622: 'show', 623: 'hasn', 624: 'face', 625: 'four', 626: 'table', 627: 'garden', 628: 'stand', 629: 'explain', 630: 'bath', 631: 'harder', 632: 'least', 633: 'death', 634: 'cars', 635: 'rest', 636: 'dollars', 637: 'shade', 638: 'cats', 639: 'movie', 640: 'aren', 641: 'believes', 642: 'arrived', 643: 'dead', 644: 'hardly', 645: 'brought', 646: 'famous', 647: 'great', 648: 'head', 649: 'promise', 650: 'canada', 651: 'france', 652: 'dream', 653: 'speaking', 654: 'meeting', 655: 'africa', 656: 'become', 657: 'result', 658: 'happen', 659: 'most', 660: 'australia', 661: 'future', 662: 'students', 663: 'sisters', 664: 'college', 665: 'bigger', 666: 'having', 667: 'paris', 668: 'trouble', 669: 'pictures', 670: 'older', 671: 'leaving', 672: 'stayed', 673: 'languages', 674: 'doubt', 675: 'covered', 676: 'ordered', 677: 'whole', 678: 'together', 679: 'street', 680: 'uncle', 681: 'amateur', 682: 'cricket', 683: 'player', 684: 'bridge', 685: 'supposed', 686: 'cost', 687: 'government', 688: 'pass', 689: 'responsible', 690: 'bored', 691: 'wonderful', 692: 'follow', 693: 'shout', 694: 'promised', 695: 'cat', 696: 'map', 697: 'feet', 698: 'waited', 699: 'hat', 700: 'husband', 701: 'cook', 702: 'anybody', 703: 'kites', 704: 'fault', 705: 'carefully', 706: 'teach', 707: 'join', 708: 'rice', 709: 'legs', 710: 'speaks', 711: 'near', 712: 'thirsty', 713: 'bird', 714: 'walking', 715: 'turned', 716: 'listen', 717: 'student', 718: 'stolen', 719: 'radio', 720: 'yes', 721: 'simple', 722: 'admit', 723: 'women', 724: 'sort', 725: 'tall', 726: 'suitcase', 727: 'crow', 728: 'entered', 729: 'continued', 730: 'win', 731: 'wine', 732: 'pulled', 733: 'trees', 734: 'tax', 735: 'jog', 736: 'worry', 737: 'success', 738: 'succeed', 739: 'expect', 740: 'meant', 741: 'joke', 742: 'glasses', 743: 'eleven', 744: 'shut', 745: 'goes', 746: 'accepted', 747: 'offer', 748: 'horse', 749: 'daughter', 750: 'correct', 751: 'ahead', 752: 'eye', 753: 'ball', 754: 'lived', 755: 'animal', 756: 'fast', 757: 'foot', 758: 'wake', 759: 'thinking', 760: 'absent', 761: 'shall', 762: 'piano', 763: 'heart', 764: 'showed', 765: 'oil', 766: 'smooth', 767: 'arrive', 768: 'plenty', 769: 'bother', 770: 'glass', 771: 'park', 772: 'arrogant', 773: 'accused', 774: 'sent', 775: 'important', 776: 'brothers', 777: 'under', 778: 'thirty', 779: 'cancer', 780: 'novel', 781: 'half', 782: 'forest', 783: 'team', 784: 'rooms', 785: 'road', 786: 'tokyo', 787: 'satisfied', 788: 'neighbors', 789: 'plays', 790: 'burning', 791: 'sleeping', 792: 'account', 793: 'sold', 794: 'travel', 795: 'towel', 796: 'add', 797: 'herself', 798: 'reason', 799: 'cry', 800: 'twenty', 801: 'protect', 802: 'favorite', 803: 'smoke', 804: 'officer', 805: 'whatever', 806: 'opinions', 807: 'miles', 808: 'following', 809: 'items', 810: 'place', 811: 'feed', 812: 'word', 813: 'order', 814: 'bread', 815: 'somewhere', 816: 'explained', 817: 'rule', 818: 'osaka', 819: 'waste', 820: 'voice', 821: 'allowed', 822: 'saved', 823: 'danger', 824: 'store', 825: 'brush', 826: 'teeth', 827: 'meals', 828: 'words', 829: 'tickets', 830: 'speech', 831: 'advise', 832: 'pleased', 833: 'allow', 834: 'pain', 835: 'italy', 836: 'tree', 837: 'worse', 838: 'fact', 839: 'butter', 840: 'advantage', 841: 'monday', 842: 'movies', 843: 'trip', 844: 'traffic', 845: 'mail', 846: 'pieces', 847: 'favor', 848: 'flying', 849: 'kite', 850: 'dangerous', 851: 'due', 852: 'illness', 853: 'interpret', 854: 'poem', 855: 'pick', 856: 'borrow', 857: 'subject', 858: 'lie', 859: 'helped', 860: 'tonight', 861: 'sun', 862: 'wedding', 863: 'fresh', 864: 'promote', 865: 'buried', 866: 'lying', 867: 'until', 868: 'dictionary', 869: 'trust', 870: 'rules', 871: 'killed', 872: 'ashamed', 873: 'wrote', 874: 'temples', 875: 'fifty', 876: 'end', 877: 'extent', 878: 'wind', 879: 'leaves', 880: 'computer', 881: 'short', 882: 'prize', 883: 'message', 884: 'point', 885: 'delhi', 886: 'speed', 887: 'breakfast', 888: 'case', 889: 'living', 890: 'depends', 891: 'teaching', 892: 'destroyed', 893: 'catch', 894: 'according', 895: 'front', 896: 'company', 897: 'advised', 898: 'far', 899: 'its', 900: 'passed', 901: 'weeks', 902: 'lights', 903: 'workers', 904: 'museum', 905: 'library', 906: 'answers', 907: 'test', 908: 'ought', 909: 'till', 910: 'couple', 911: 'except', 912: 'largest', 913: 'feeling', 914: 'spent', 915: 'teresa', 916: 'hello', 917: 'cheers', 918: 'ok', 919: 'perfect', 920: 'welcome', 921: 'fine', 922: 'math', 923: 'shot', 924: 'touch', 925: 'atheist', 926: 'congratulations', 927: 'miss', 928: 'reads', 929: 'arabic', 930: 'rude', 931: 'lucky', 932: 'cafe', 933: 'fair', 934: 'lack', 935: 'choose', 936: 'top', 937: 'oranges', 938: 'sign', 939: 'betrayed', 940: 'build', 941: 'nests', 942: 'headache', 943: 'loved', 944: 'happiness', 945: 'throw', 946: 'breathed', 947: 'deeply', 948: 'cousin', 949: 'toes', 950: 'pretty', 951: 'guy', 952: 'enjoyed', 953: 'kids', 954: 'vase', 955: 'pen', 956: 'gym', 957: 'state', 958: 'taste', 959: 'eaten', 960: 'ticket', 961: 'green', 962: 'forgive', 963: 'pencil', 964: 'sea', 965: 'lunch', 966: 'noon', 967: 'consciousness', 968: 'decision', 969: 'wore', 970: 'haunted', 971: 'sheets', 972: 'burst', 973: 'feels', 974: 'silk', 975: 'beer', 976: 'hens', 977: 'bell', 978: 'climbed', 979: 'stairs', 980: 'sharp', 981: 'race', 982: 'boston', 983: 'start', 984: 'swollen', 985: 'hated', 986: 'stubborn', 987: 'nearby', 988: 'missed', 989: 'shouted', 990: 'exciting', 991: 'elevator', 992: 'song', 993: 'earns', 994: 'knocked', 995: 'robbed', 996: 'physics', 997: 'wonder', 998: 'stomach', 999: 'york', 1000: 'wears', 1001: 'glad', 1002: 'lion', 1003: 'chairs', 1004: 'passport', 1005: 'soccer', 1006: 'complaining', 1007: 'dozen', 1008: 'dressed', 1009: 'white', 1010: 'whichever', 1011: 'applies', 1012: 'wood', 1013: 'cheese', 1014: 'fond', 1015: 'gun', 1016: 'murder', 1017: 'seat', 1018: 'further', 1019: 'cups', 1020: 'iron', 1021: 'gold', 1022: 'healthy', 1023: 'successful', 1024: 'gathered', 1025: 'amount', 1026: 'trusted', 1027: 'import', 1028: 'part', 1029: 'fairies', 1030: 'moment', 1031: 'taught', 1032: 'walked', 1033: 'witnessed', 1034: 'steal', 1035: 'lately', 1036: 'manager', 1037: 'stopped', 1038: 'hates', 1039: 'bags', 1040: 'missing', 1041: 'plants', 1042: 'prisoner', 1043: 'independence', 1044: 'pond', 1045: 'coal', 1046: 'personally', 1047: 'koala', 1048: 'visited', 1049: 'kyoto', 1050: 'says', 1051: 'pencils', 1052: 'cover', 1053: 'sat', 1054: 'mouse', 1055: 'alive', 1056: 'same', 1057: 'hit', 1058: 'mud', 1059: 'season', 1060: 'celebrated', 1061: 'chose', 1062: 'pride', 1063: 'western', 1064: 'german', 1065: 'treats', 1066: 'august', 1067: 'accompanied', 1068: 'useful', 1069: 'spanish', 1070: 'mexico', 1071: 'yen', 1072: 'loves', 1073: 'answered', 1074: 'else', 1075: 'low', 1076: 'hundred', 1077: 'real', 1078: 'diamond', 1079: 'wall', 1080: 'roses', 1081: 'degree', 1082: 'followed', 1083: 'deer', 1084: 'tracks', 1085: 'science', 1086: 'farm', 1087: 'young', 1088: 'grown', 1089: 'rome', 1090: 'monkey', 1091: 'increasing', 1092: 'send', 1093: 'taken', 1094: 'rotten', 1095: 'spread', 1096: 'youth', 1097: 'jam', 1098: 'jobs', 1099: 'thought', 1100: 'patient', 1101: 'bound', 1102: 'contains', 1103: 'undone', 1104: 'absence', 1105: 'meal', 1106: 'distance', 1107: 'roof', 1108: 'dust', 1109: 'itself', 1110: 'crash', 1111: 'shop', 1112: 'someday', 1113: 'juice', 1114: 'supper', 1115: 'listened', 1116: 'struck', 1117: 'even', 1118: 'everything', 1119: 'vegetables', 1120: 'graveyard', 1121: 'supermarket', 1122: 'rainy', 1123: 'vain', 1124: 'sinking', 1125: 'high', 1126: 'cross', 1127: 'newspapers', 1128: 'dance', 1129: 'count', 1130: 'stingy', 1131: 'paper', 1132: 'single', 1133: 'lazy', 1134: 'boss', 1135: 'consists', 1136: 'past', 1137: 'reproached', 1138: 'starts', 1139: 'rang', 1140: 'scolded', 1141: 'worst', 1142: 'rid', 1143: 'habit', 1144: 'gets', 1145: 'nerves', 1146: 'hid', 1147: 'among', 1148: 'realized', 1149: 'program', 1150: 'smile', 1151: 'arrogance', 1152: 'fortune', 1153: 'proved', 1154: 'laid', 1155: 'prevented', 1156: 'murders', 1157: 'willing', 1158: 'observe', 1159: 'limit', 1160: 'market', 1161: 'tolerate', 1162: 'statement', 1163: 'art', 1164: 'friday', 1165: 'learning', 1166: 'foreign', 1167: 'nowadays', 1168: 'overseas', 1169: 'insecure', 1170: 'animals', 1171: 'asleep', 1172: 'pocket', 1173: 'jungle', 1174: 'storm', 1175: 'proud', 1176: 'themselves', 1177: 'chance', 1178: 'sudden', 1179: 'toilet', 1180: 'pet', 1181: 'spend', 1182: 'dreamed', 1183: 'twice', 1184: 'vary', 1185: 'stars', 1186: 'law', 1187: 'scattered', 1188: 'talked', 1189: 'less', 1190: 'answering', 1191: 'corner', 1192: 'sentences', 1193: 'opportunity', 1194: 'current', 1195: 'income', 1196: 'fit', 1197: 'wearing', 1198: 'inside', 1199: 'occurred', 1200: 'regret', 1201: 'imitate', 1202: 'education', 1203: 'ride', 1204: 'staying', 1205: 'months', 1206: 'fall', 1207: 'received', 1208: 'sometimes', 1209: 'hesitation', 1210: 'convinced', 1211: 'doll', 1212: 'gentleman', 1213: 'absolute', 1214: 'shows', 1215: 'common', 1216: 'environment', 1217: 'club', 1218: 'examination', 1219: 'reduce', 1220: 'invited', 1221: 'confident', 1222: 'writing', 1223: 'letters', 1224: 'recognize', 1225: 'video', 1226: 'caused', 1227: 'earthquake', 1228: 'failed', 1229: 'jumped', 1230: 'locked', 1231: 'countries', 1232: 'conditioner', 1233: 'situation', 1234: 'himself', 1235: 'precious', 1236: 'injured', 1237: 'during', 1238: 'stole', 1239: 'disappointment', 1240: 'respected', 1241: 'tears', 1242: 'impossible', 1243: 'opinion', 1244: 'certain', 1245: 'noticed', 1246: 'misunderstanding', 1247: 'fight', 1248: 'companies', 1249: 'products', 1250: 'instant', 1251: 'ago', 1252: 'lots', 1253: 'gained', 1254: 'thousands', 1255: 'taiwan', 1256: 'strike', 1257: 'president', 1258: 'quality', 1259: 'bothered', 1260: 'seventeen', 1261: 'sad', 1262: 'strawberries', 1263: 'cities', 1264: 'gut', 1265: 'regard', 1266: 'names', 1267: 'careful', 1268: 'backs', 1269: 'selfish', 1270: 'thinks', 1271: 'feelings', 1272: 'committee', 1273: 'exam', 1274: 'investigate', 1275: 'reach', 1276: 'takes', 1277: 'safety', 1278: 'affected', 1279: 'realize', 1280: 'value', 1281: 'calcutta', 1282: 'wow', 1283: 'awesome', 1284: 'goodbye', 1285: 'full', 1286: 'fantastic', 1287: 'fainted', 1288: 'fear', 1289: 'definitely', 1290: 'burns', 1291: 'yawned', 1292: 'lied', 1293: 'easter', 1294: 'snowing', 1295: 'unbelievable', 1296: 'dies', 1297: 'bloom', 1298: 'donuts', 1299: 'quick', 1300: 'aloud', 1301: 'bent', 1302: 'holidays', 1303: 'beard', 1304: 'actor', 1305: 'needs', 1306: 'idol', 1307: 'kidding', 1308: 'guys', 1309: 'absurd', 1310: 'nauseous', 1311: 'assaulted', 1312: 'startled', 1313: 'climb', 1314: 'potatoes', 1315: 'faces', 1316: 'responded', 1317: 'shopping', 1318: 'bar', 1319: 'deceive', 1320: 'screamed', 1321: 'employs', 1322: 'maid', 1323: 'studied', 1324: 'traitor', 1325: 'sleepy', 1326: 'truly', 1327: 'starting', 1328: 'rotates', 1329: 'invite', 1330: 'beach', 1331: 'pie', 1332: 'stones', 1333: 'gone', 1334: 'nuts', 1335: 'handle', 1336: 'toyota', 1337: 'frozen', 1338: 'leaped', 1339: 'joy', 1340: 'happily', 1341: 'annoys', 1342: 'batter', 1343: 'flew', 1344: 'vanished', 1345: 'skating', 1346: 'pumpkin', 1347: 'begin', 1348: 'wheel', 1349: 'lonely', 1350: 'singing', 1351: 'hate', 1352: 'risks', 1353: 'marry', 1354: 'ink', 1355: 'tiger', 1356: 'skies', 1357: 'sweating', 1358: 'winter', 1359: 'saver', 1360: 'envied', 1361: 'lent', 1362: 'stranger', 1363: 'counting', 1364: 'vomiting', 1365: 'stomachache', 1366: 'problems', 1367: 'finger', 1368: 'allergic', 1369: 'ringing', 1370: 'charge', 1371: 'boring', 1372: 'victory', 1373: 'windy', 1374: 'lincoln', 1375: 'specialty', 1376: 'ablaze', 1377: 'damp', 1378: 'pipe', 1379: 'hers', 1380: 'zoo', 1381: 'contain', 1382: 'prove', 1383: 'camera', 1384: 'lay', 1385: 'rung', 1386: 'deals', 1387: 'furniture', 1388: 'shooter', 1389: 'sixty', 1390: 'sang', 1391: 'dear', 1392: 'grateful', 1393: 'dove', 1394: 'servant', 1395: 'liked', 1396: 'biology', 1397: 'korea', 1398: 'tiny', 1399: 'toy', 1400: 'deep', 1401: 'disturbing', 1402: 'rested', 1403: 'nonsense', 1404: 'fox', 1405: 'wild', 1406: 'color', 1407: 'temper', 1408: 'slap', 1409: 'salary', 1410: 'daughters', 1411: 'tore', 1412: 'apart', 1413: 'understands', 1414: 'pity', 1415: 'cage', 1416: 'seem', 1417: 'wasn', 1418: 'fired', 1419: 'bloody', 1420: 'growling', 1421: 'gentle', 1422: 'wealthy', 1423: 'prattles', 1424: 'weird', 1425: 'gate', 1426: 'knife', 1427: 'sooner', 1428: 'thin', 1429: 'tame', 1430: 'engine', 1431: 'temperature', 1432: 'stuttering', 1433: 'tuesday', 1434: 'spoil', 1435: 'alcohol', 1436: 'sand', 1437: 'catches', 1438: 'colds', 1439: 'smelling', 1440: 'soup', 1441: 'theft', 1442: 'throwing', 1443: 'dentist', 1444: 'drinking', 1445: 'concern', 1446: 'example', 1447: 'debts', 1448: 'flames', 1449: 'adopted', 1450: 'orphan', 1451: 'note', 1452: 'plus', 1453: 'round', 1454: 'nationality', 1455: 'pours', 1456: 'travels', 1457: 'ambulance', 1458: 'envelope', 1459: 'leveled', 1460: 'dissatisfied', 1461: 'kilo', 1462: 'beg', 1463: 'differ', 1464: 'jacket', 1465: 'subway', 1466: 'condition', 1467: 'knocking', 1468: 'coughing', 1469: 'refund', 1470: 'page', 1471: 'introduce', 1472: 'quiet', 1473: 'obstinate', 1474: 'refused', 1475: 'notice', 1476: 'pulse', 1477: 'committed', 1478: 'includes', 1479: 'narrow', 1480: 'lacks', 1481: 'courage', 1482: 'line', 1483: 'b', 1484: 'sale', 1485: 'arrest', 1486: 'hammered', 1487: 'hesitated', 1488: 'sentenced', 1489: 'quota', 1490: 'bowls', 1491: 'hunger', 1492: 'drove', 1493: 'farther', 1494: 'glimpse', 1495: 'fixed', 1496: 'facebook', 1497: 'barber', 1498: 'terribly', 1499: 'smog', 1500: 'causes', 1501: 'snakes', 1502: 'poisonous', 1503: 'enemy', 1504: 'haze', 1505: 'enveloped', 1506: 'abused', 1507: 'released', 1508: 'families', 1509: 'painted', 1510: 'appeared', 1511: 'appointment', 1512: 'fail', 1513: 'watering', 1514: 'greeks', 1515: 'engaged', 1516: 'occasionally', 1517: 'worthless', 1518: 'honesty', 1519: 'policy', 1520: 'actually', 1521: 'usual', 1522: 'decline', 1523: 'john', 1524: 'june', 1525: 'bum', 1526: 'aunt', 1527: 'arms', 1528: 'bride', 1529: 'tastes', 1530: 'bitter', 1531: 'clung', 1532: 'paint', 1533: 'dried', 1534: 'drinkable', 1535: 'monsoon', 1536: 'greek', 1537: 'captain', 1538: 'figured', 1539: 'hurt', 1540: 'soft', 1541: 'drinks', 1542: 'breathe', 1543: 'digging', 1544: 'grave', 1545: 'prefers', 1546: 'repeated', 1547: 'slave', 1548: 'st', 1549: 'cleaned', 1550: 'cycling', 1551: 'crossing', 1552: 'insert', 1553: 'metal', 1554: 'million', 1555: 'sheer', 1556: 'expenses', 1557: 'spa', 1558: 'jeans', 1559: 'shrank', 1560: 'players', 1561: 'also', 1562: 'offered', 1563: 'declined', 1564: 'invitation', 1565: 'dialed', 1566: 'purse', 1567: 'bun', 1568: 'soldiers', 1569: 'silent', 1570: 'socks', 1571: 'houses', 1572: 'burned', 1573: 'smelled', 1574: 'tobacco', 1575: 'teachers', 1576: 'ourselves', 1577: 'south', 1578: 'terminal', 1579: 'tidy', 1580: 'chinese', 1581: 'underlined', 1582: 'lean', 1583: 'football', 1584: 'changed', 1585: 'schools', 1586: 'eats', 1587: 'cafeteria', 1588: 'ear', 1589: 'shirts', 1590: 'washed', 1591: 'wishes', 1592: 'smell', 1593: 'forever', 1594: 'bottles', 1595: 'informed', 1596: 'mentioned', 1597: 'dozens', 1598: 'catching', 1599: 'appears', 1600: 'honest', 1601: 'fate', 1602: 'arguing', 1603: 'collecting', 1604: 'coins', 1605: 'notebook', 1606: 'beating', 1607: 'bush', 1608: 'widely', 1609: 'begun', 1610: 'decay', 1611: 'pole', 1612: 'cliff', 1613: 'vertical', 1614: 'crushed', 1615: 'enemies', 1616: 'sail', 1617: 'bombay', 1618: 'resolved', 1619: 'rodica', 1620: 'fifth', 1621: 'island', 1622: 'concealed', 1623: 'accustomed', 1624: 'costly', 1625: 'purchases', 1626: 'toward', 1627: 'within', 1628: 'disturbed', 1629: 'bear', 1630: 'sundays', 1631: 'reasonable', 1632: 'basketball', 1633: 'escaped', 1634: 'dreams', 1635: 'seicho', 1636: 'matsumoto', 1637: 'withered', 1638: 'governed', 1639: 'finland', 1640: 'consider', 1641: 'intelligent', 1642: 'solve', 1643: 'mile', 1644: 'ours', 1645: 'slow', 1646: 'dad', 1647: 'shaving', 1648: 'bathroom', 1649: 'cheaper', 1650: 'fighting', 1651: 'settle', 1652: 'attention', 1653: 'walks', 1654: 'behavior', 1655: 'odd', 1656: 'bone', 1657: 'keys', 1658: 'wallet', 1659: 'motioned', 1660: 'folder', 1661: 'worrying', 1662: 'doable', 1663: 'politics', 1664: 'louder', 1665: 'remove', 1666: 'tries', 1667: 'pack', 1668: 'appearing', 1669: 'warned', 1670: 'string', 1671: 'occurs', 1672: 'frequently', 1673: 'raised', 1674: 'cloud', 1675: 'barking', 1676: 'moves', 1677: 'investigation', 1678: 'hunting', 1679: 'lions', 1680: 'carried', 1681: 'leather', 1682: 'goods', 1683: 'towels', 1684: 'church', 1685: 'sixteenth', 1686: 'graduated', 1687: 'forced', 1688: 'peace', 1689: 'author', 1690: 'dine', 1691: 'owe', 1692: 'apology', 1693: 'owner', 1694: 'solved', 1695: 'exports', 1696: 'wool', 1697: 'peasant', 1698: 'bet', 1699: 'stuff', 1700: 'heavily', 1701: 'properly', 1702: 'perhaps', 1703: 'pounds', 1704: 'gazed', 1705: 'apartment', 1706: 'discussing', 1707: 'strict', 1708: 'princess', 1709: 'crows', 1710: 'unless', 1711: 'ocean', 1712: 'hurried', 1713: 'boat', 1714: 'baggage', 1715: 'blame', 1716: 'wipe', 1717: 'conform', 1718: 'similar', 1719: 'rope', 1720: 'thrown', 1721: 'plans', 1722: 'detail', 1723: 'pressed', 1724: 'prompt', 1725: 'reply', 1726: 'bullet', 1727: 'weighed', 1728: 'stone', 1729: 'grandfather', 1730: 'housework', 1731: 'sin', 1732: 'anywhere', 1733: 'asking', 1734: 'visiting', 1735: 'oh', 1736: 'gas', 1737: 'billion', 1738: 'quite', 1739: 'accidental', 1740: 'pardon', 1741: 'raise', 1742: 'funds', 1743: 'gladly', 1744: 'proposal', 1745: 'younger', 1746: 'remained', 1747: 'stamps', 1748: 'stripped', 1749: 'conference', 1750: 'aware', 1751: 'shooting', 1752: 'several', 1753: 'flat', 1754: 'planted', 1755: 'cave', 1756: 'tie', 1757: 'suit', 1758: 'hotel', 1759: 'beatles', 1760: 'chat', 1761: 'squirrel', 1762: 'branches', 1763: 'fallen', 1764: 'coincidentally', 1765: 'elephants', 1766: 'asia', 1767: 'neither', 1768: 'sadness', 1769: 'pigeons', 1770: 'experiment', 1771: 'cash', 1772: 'fool', 1773: 'ability', 1774: 'ignore', 1775: 'neat', 1776: 'piece', 1777: 'prided', 1778: 'accompany', 1779: 'fewer', 1780: 'harm', 1781: 'exemplary', 1782: 'performance', 1783: 'p', 1784: 'exactly', 1785: 'parallel', 1786: 'besides', 1787: 'worth', 1788: 'shared', 1789: 'profit', 1790: 'elephant', 1791: 'dislike', 1792: 'bern', 1793: 'switzerland', 1794: 'classmates', 1795: 'comfort', 1796: 'faults', 1797: 'reverse', 1798: 'neighborhood', 1799: 'sense', 1800: 'rebellion', 1801: 'faster', 1802: 'rescued', 1803: 'sandwiches', 1804: 'remain', 1805: 'naughty', 1806: 'haste', 1807: 'repair', 1808: 'group', 1809: 'actress', 1810: 'dishes', 1811: 'germany', 1812: 'wings', 1813: 'golf', 1814: 'cleared', 1815: 'ghosts', 1816: 'preparing', 1817: 'planting', 1818: 'profession', 1819: 'cradle', 1820: 'holding', 1821: 'hole', 1822: 'deprived', 1823: 'mystery', 1824: 'remains', 1825: 'unsolved', 1826: 'discussed', 1827: 'clever', 1828: 'newspaper', 1829: 'matters', 1830: 'land', 1831: 'moon', 1832: 'eager', 1833: 'wooden', 1834: 'buildings', 1835: 'opening', 1836: 'loyalty', 1837: 'century', 1838: 'laugh', 1839: 'extend', 1840: 'helps', 1841: 'russian', 1842: 'sentence', 1843: 'seemed', 1844: 'ignorance', 1845: 'stuck', 1846: 'oxford', 1847: 'university', 1848: 'cemetery', 1849: 'jogging', 1850: 'innocent', 1851: 'complains', 1852: 'daytime', 1853: 'ninth', 1854: 'completely', 1855: 'unfounded', 1856: 'approached', 1857: 'equal', 1858: 'hour', 1859: 'match', 1860: 'brown', 1861: 'stabbed', 1862: 'agreement', 1863: 'managed', 1864: 'genuine', 1865: 'thick', 1866: 'mist', 1867: 'countryside', 1868: 'quitting', 1869: 'buddhism', 1870: 'beginnings', 1871: 'classical', 1872: 'bones', 1873: 'leg', 1874: 'impatient', 1875: 'gently', 1876: 'shoulder', 1877: 'grows', 1878: 'wiped', 1879: 'sweat', 1880: 'forehead', 1881: 'follows', 1882: 'scale', 1883: 'amazed', 1884: 'scared', 1885: 'anchorage', 1886: 'ache', 1887: 'imagine', 1888: 'earlier', 1889: 'complained', 1890: 'rudeness', 1891: 'prepared', 1892: 'pretending', 1893: 'fifteen', 1894: 'dug', 1895: 'treasure', 1896: 'denied', 1897: 'type', 1898: 'attended', 1899: 'exhibited', 1900: 'remorse', 1901: 'crime', 1902: 'failure', 1903: 'board', 1904: 'childhood', 1905: 'mohan', 1906: 'acquainted', 1907: 'sofa', 1908: 'veracity', 1909: 'unicycle', 1910: 'umbrella', 1911: 'phrase', 1912: 'mom', 1913: 'keeps', 1914: 'peacefully', 1915: 'sickness', 1916: 'sound', 1917: 'beast', 1918: 'patrolling', 1919: 'trying', 1920: 'persuade', 1921: 'charged', 1922: 'directions', 1923: 'cloth', 1924: 'silky', 1925: 'driven', 1926: 'electricity', 1927: 'unused', 1928: 'pink', 1929: 'remote', 1930: 'control', 1931: 'embezzled', 1932: 'employees', 1933: 'stories', 1934: 'cooking', 1935: 'fully', 1936: 'innocence', 1937: 'american', 1938: 'literature', 1939: 'obliged', 1940: 'youngster', 1941: 'pair', 1942: 'scissors', 1943: 'debt', 1944: 'drop', 1945: 'consented', 1946: 'suffers', 1947: 'headaches', 1948: 'miracle', 1949: 'save', 1950: 'reminds', 1951: 'pianist', 1952: 'scar', 1953: 'cheek', 1954: 'completed', 1955: 'smartest', 1956: 'proverb', 1957: 'turning', 1958: 'volume', 1959: 'nerve', 1960: 'results', 1961: 'excellent', 1962: 'cure', 1963: 'mood', 1964: 'cows', 1965: 'sacred', 1966: 'hardships', 1967: 'price', 1968: 'wares', 1969: 'poet', 1970: 'destined', 1971: 'adding', 1972: 'salt', 1973: 'concert', 1974: 'pronounce', 1975: 'angels', 1976: 'addicted', 1977: 'chocolate', 1978: 'ice', 1979: 'cream', 1980: 'straight', 1981: 'matches', 1982: 'everywhere', 1983: 'forward', 1984: 'named', 1985: 'rainbow', 1986: 'burglar', 1987: 'satisfying', 1988: 'spoiled', 1989: 'prison', 1990: 'calm', 1991: 'film', 1992: 'punished', 1993: 'break', 1994: 'spit', 1995: 'identify', 1996: 'recognized', 1997: 'defeated', 1998: 'opponent', 1999: 'election', 2000: 'expectations', 2001: 'release', 2002: 'prisoners', 2003: 'rely', 2004: 'watched', 2005: 'beginning', 2006: 'materials', 2007: 'acquaintance', 2008: 'woods', 2009: 'strangers', 2010: 'heavy', 2011: 'bakery', 2012: 'cute', 2013: 'lady', 2014: 'granddaughter', 2015: 'calls', 2016: 'drastic', 2017: 'measures', 2018: 'penalty', 2019: 'continent', 2020: 'cured', 2021: 'discovered', 2022: 'brave', 2023: 'act', 2024: 'pickpocketing', 2025: 'breath', 2026: 'operate', 2027: 'electrical', 2028: 'engineer', 2029: 'erase', 2030: 'wondering', 2031: 'definite', 2032: 'carelessness', 2033: 'qutub', 2034: 'minar', 2035: 'fort', 2036: 'farmer', 2037: 'toudaiji', 2038: 'spending', 2039: 'hokkaido', 2040: 'blanket', 2041: 'growing', 2042: 'poorer', 2043: 'obvious', 2044: 'main', 2045: 'object', 2046: 'climate', 2047: 'congratulate', 2048: 'engagement', 2049: 'possession', 2050: 'respect', 2051: 'vocabulary', 2052: 'amend', 2053: 'constitution', 2054: 'holiday', 2055: 'hold', 2056: 'carries', 2057: 'seeds', 2058: 'distances', 2059: 'clouds', 2060: 'furnished', 2061: 'originally', 2062: 'journey', 2063: 'investigated', 2064: 'angles', 2065: 'photocopier', 2066: 'requires', 2067: 'madman', 2068: 'accountable', 2069: 'actions', 2070: 'rubber', 2071: 'bounces', 2072: 'elastic', 2073: 'british', 2074: 'citizen', 2075: 'becoming', 2076: 'artist', 2077: 'closing', 2078: 'spends', 2079: 'entirely', 2080: 'heap', 2081: 'theater', 2082: 'woke', 2083: 'middle', 2084: 'reforming', 2085: 'male', 2086: 'peacock', 2087: 'colorful', 2088: 'tail', 2089: 'feathers', 2090: 'leading', 2091: 'cursed', 2092: 'finding', 2093: 'waking', 2094: 'opposite', 2095: 'seats', 2096: 'occur', 2097: 'windows', 2098: 'copyrighted', 2099: 'sources', 2100: 'balance', 2101: 'allowances', 2102: 'oppose', 2103: 'whom', 2104: 'pouring', 2105: 'lift', 2106: 'mt', 2107: 'everest', 2108: 'highest', 2109: 'peak', 2110: 'poured', 2111: 'washing', 2112: 'enter', 2113: 'classroom', 2114: 'careless', 2115: 'driving', 2116: 'factory', 2117: 'cease', 2118: 'operations', 2119: 'alarm', 2120: 'throughout', 2121: 'observed', 2122: 'eventually', 2123: 'fined', 2124: 'illegal', 2125: 'parking', 2126: 'distinguish', 2127: 'granted', 2128: 'wins', 2129: 'receive', 2130: 'gives', 2131: 'innumerable', 2132: 'contact', 2133: 'alphabet', 2134: 'hang', 2135: 'given', 2136: 'advertise', 2137: 'biggest', 2138: 'source', 2139: 'inspiration', 2140: 'hesitate', 2141: 'drug', 2142: 'smuggler', 2143: 'side', 2144: 'fortunate', 2145: 'loving', 2146: 'presents', 2147: 'switch', 2148: 'member', 2149: 'commit', 2150: 'suicide', 2151: 'upon', 2152: 'weekend', 2153: 'waist', 2154: 'britain', 2155: 'located', 2156: 'towns', 2157: 'grapes', 2158: 'sour', 2159: 'booted', 2160: 'foreigners', 2161: 'customers', 2162: 'independent', 2163: 'softer', 2164: 'report', 2165: 'resting', 2166: 'elected', 2167: 'frankly', 2168: 'reminded', 2169: 'parcel', 2170: 'translate', 2171: 'phrases', 2172: 'ease', 2173: 'searching', 2174: 'exist', 2175: 'immediately', 2176: 'private', 2177: 'acquaintances', 2178: 'reform', 2179: 'laws', 2180: 'above', 2181: 'sixth', 2182: 'floor', 2183: 'superior', 2184: 'popular', 2185: 'exchange', 2186: 'sweater', 2187: 'u', 2188: 'contracted', 2189: 'malaria', 2190: 'property', 2191: 'slept', 2192: 'thames', 2193: 'distributed', 2194: 'returning', 2195: 'weren', 2196: 'swear', 2197: 'decide', 2198: 'freedom', 2199: 'objected', 2200: 'removing', 2201: 'chatting', 2202: 'seventh', 2203: 'noisy', 2204: 'encouraged', 2205: 'fulfill', 2206: 'ambitions', 2207: 'constantly', 2208: 'forgetting', 2209: 'seldom', 2210: 'theory', 2211: 'comprehend', 2212: 'surprise', 2213: 'emergency', 2214: 'polluted', 2215: 'atmosphere', 2216: 'reached', 2217: 'international', 2218: 'trade', 2219: 'vital', 2220: 'economies', 2221: 'richest', 2222: 'bat', 2223: 'balls', 2224: 'protection', 2225: 'kindness', 2226: 'dropped', 2227: 'photograph', 2228: 'developed', 2229: 'arrange', 2230: 'motorbike', 2231: 'helmet', 2232: 'dirty', 2233: 'repairing', 2234: 'industry', 2235: 'majority', 2236: 'voted', 2237: 'bill', 2238: 'aids', 2239: 'horrifyingly', 2240: 'parts', 2241: 'shower', 2242: 'drenched', 2243: 'skin', 2244: 'lakes', 2245: 'biwa', 2246: 'beforehand', 2247: 'maybe', 2248: 'unhappy', 2249: 'intend', 2250: 'kill', 2251: 'huge', 2252: 'snake', 2253: 'murdered', 2254: 'entrance', 2255: 'communicate', 2256: 'patience', 2257: 'succeeded', 2258: 'chain', 2259: 'bite', 2260: 'ventured', 2261: 'swallow', 2262: 'tablets', 2263: 'taj', 2264: 'mahal', 2265: 'seven', 2266: 'wonders', 2267: 'voyage', 2268: 'obtained', 2269: 'yield', 2270: 'percent', 2271: 'investment', 2272: 'pollute', 2273: 'conduct', 2274: 'columbus', 2275: 'argued', 2276: 'west', 2277: 'awake', 2278: 'introduced', 2279: 'barely', 2280: 'afford', 2281: 'essential', 2282: 'command', 2283: 'mumbai', 2284: 'indian', 2285: 'maharashtra', 2286: 'fishing', 2287: 'intends', 2288: 'devote', 2289: 'curing', 2290: 'wear', 2291: 'greatest', 2292: 'economic', 2293: 'powers', 2294: 'fifteenth', 2295: 'mobile', 2296: 'calculation', 2297: 'although', 2298: 'twins', 2299: 'interests', 2300: 'paid', 2301: 'dues', 2302: 'deliberately', 2303: 'ignored', 2304: 'seeing', 2305: 'authorities', 2306: 'hiding', 2307: 'facts', 2308: 'public', 2309: 'opened', 2310: 'smelt', 2311: 'imitation', 2312: 'diamonds', 2313: 'blowing', 2314: 'horn', 2315: 'demanded', 2316: 'copies', 2317: 'sheep', 2318: 'field', 2319: 'higher', 2320: 'wars', 2321: 'fisherman', 2322: 'exaggerated', 2323: 'corruption', 2324: 'sticking', 2325: 'cleaning', 2326: 'prepare', 2327: 'resembles', 2328: 'appearance', 2329: 'character', 2330: 'incident', 2331: 'electric', 2332: 'seeking', 2333: 'staring', 2334: 'ceiling', 2335: 'handful', 2336: 'peanuts', 2337: 'firm', 2338: 'bankruptcy', 2339: 'access', 2340: 'acknowledgement', 2341: 'services', 2342: 'twin', 2343: 'girls', 2344: 'alike', 2345: 'practice', 2346: 'laying', 2347: 'thieves', 2348: 'drawers', 2349: 'search', 2350: 'driver', 2351: 'license', 2352: 'eighteen', 2353: 'catholic', 2354: 'nun', 2355: 'george', 2356: 'washington', 2357: 'unites', 2358: 'states', 2359: 'view', 2360: 'daily', 2361: 'passengers', 2362: 'nearest', 2363: 'democracy', 2364: 'form', 2365: 'kid', 2366: 'touching', 2367: 'bugs', 2368: 'UNKNOWN'}\n"
          ]
        }
      ],
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "\n",
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "idx = 1282\n",
        "print(\" %d ----> %s\" % (idx,inp_lang.index_word[1282]))\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])\n",
        "print(\" %d ----> %s\" % (idx,targ_lang.index_word[1282]))\n",
        "\n",
        "\n",
        "index_word_dict_len = len(targ_lang.index_word)\n",
        "print(\"index_word_dict_len: {}\".format(index_word_dict_len))\n",
        "targ_lang.index_word[len(targ_lang.index_word) + 1] = 'UNKNOWN'\n",
        "idx = len(targ_lang.index_word)\n",
        "print(\" %d ----> %s\" % (idx,targ_lang.index_word[idx]))\n",
        "targ_lang.word_index['UNKNOWN'] = idx\n",
        "\n",
        "print(targ_lang.index_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7G3PMiDvCwu",
        "outputId": "3c165770-6984-4ad4-f0ce-2c1f758dc944",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vocab_inp_size: 3061\n",
            "vocab_tar_size: 2369\n",
            "input word to index mapping: {'<start>': 1, '<end>': 2, 'है।': 3, '?': 4, 'में': 5, 'नहीं': 6, 'मैं': 7, 'वह': 8, 'से': 9, 'मुझे': 10, 'क्या': 11, 'है': 12, 'के': 13, 'को': 14, 'की': 15, 'हैं।': 16, 'हो': 17, 'बहुत': 18, 'का': 19, 'एक': 20, 'उसने': 21, 'पर': 22, 'था।': 23, 'यह': 24, 'हूँ।': 25, 'तुम': 26, 'कर': 27, 'लिए': 28, 'कि': 29, 'मेरे': 30, ',': 31, 'हैं': 32, 'और': 33, 'अपने': 34, 'उसे': 35, 'भी': 36, 'इस': 37, 'ने': 38, 'टॉम': 39, 'मेरी': 40, 'मैंने': 41, 'रहा': 42, 'करने': 43, 'पास': 44, 'तो': 45, 'हम': 46, 'अपनी': 47, 'गया।': 48, 'ही': 49, 'कल': 50, 'काम': 51, 'था': 52, 'करना': 53, 'आप': 54, 'कोई': 55, 'साथ': 56, 'तुम्हें': 57, 'तुम्हारे': 58, 'उसकी': 59, 'उसके': 60, 'घर': 61, 'गया': 62, 'थी।': 63, 'मेरा': 64, 'बात': 65, 'पता': 66, 'सकते': 67, 'उस': 68, 'समय': 69, 'रही': 70, 'कुछ': 71, 'अभी': 72, 'यहाँ': 73, '!': 74, 'हूँ': 75, 'आज': 76, 'तक': 77, 'सकता': 78, 'लगता': 79, 'किया।': 80, 'उसको': 81, 'चाहिए।': 82, 'बजे': 83, 'तुम्हे': 84, 'अच्छा': 85, 'मत': 86, 'रहे': 87, 'कभी': 88, 'पसंद': 89, 'किताब': 90, 'थे।': 91, 'मुझसे': 92, 'आ': 93, 'करता': 94, 'दिया।': 95, 'हुई': 96, '।': 97, 'करते': 98, 'होता': 99, 'दो': 100, 'वे': 101, 'जाने': 102, 'किसी': 103, 'मदद': 104, 'हुआ': 105, 'भारत': 106, 'जो': 107, 'अपना': 108, 'पैसे': 109, 'गाड़ी': 110, 'होगा।': 111, 'हो।': 112, 'उससे': 113, 'न': 114, 'ज़्यादा': 115, 'आपको': 116, 'कहाँ': 117, 'हुए': 118, 'उसका': 119, 'जाना': 120, 'कम': 121, 'साल': 122, 'किया': 123, 'पहले': 124, 'होती': 125, 'चाहता': 126, 'सारे': 127, 'गए': 128, 'तुम्हारी': 129, 'सब': 130, 'जा': 131, 'बार': 132, 'बाहर': 133, 'बारे': 134, 'आदमी': 135, 'अंग्रेज़ी': 136, 'दिन': 137, 'देर': 138, 'गई।': 139, 'रात': 140, 'जाता': 141, 'दिया': 142, 'जब': 143, 'हमारे': 144, 'खाना': 145, 'अगर': 146, 'हमने': 147, 'बड़ा': 148, 'अब': 149, 'वापस': 150, 'फ़ोन': 151, 'वहाँ': 152, 'बंद': 153, 'ये': 154, 'करो।': 155, 'जवाब': 156, 'कैसे': 157, 'सकता।': 158, 'जल्दी': 159, 'कितने': 160, 'दी।': 161, 'तुमसे': 162, 'चला': 163, 'लोग': 164, 'तुमने': 165, 'तरह': 166, 'छोड़': 167, 'हमेशा': 168, 'तीन': 169, 'गए।': 170, 'आता': 171, 'करती': 172, 'थे': 173, 'हर': 174, 'हमे': 175, 'दस': 176, 'क्यों': 177, 'उन्होंने': 178, 'स्कूल': 179, 'पापा': 180, 'बारिश': 181, 'लोगों': 182, 'सबसे': 183, 'ठीक': 184, 'खुश': 185, 'चल': 186, 'देखा': 187, 'डॉक्टर': 188, 'खतम': 189, 'कमरे': 190, 'मौसम': 191, 'देखा।': 192, 'मुश्किल': 193, 'माँ': 194, 'बच्चे': 195, 'कहा': 196, 'पानी': 197, 'पिता': 198, 'अच्छी': 199, 'चाहते': 200, 'दो।': 201, 'कुत्ता': 202, 'सभी': 203, 'गई': 204, 'शुरू': 205, 'हमारी': 206, 'सारी': 207, 'ट्रेन': 208, 'होने': 209, 'कोशिश': 210, 'अच्छे': 211, 'थी': 212, 'दोस्त': 213, 'रहता': 214, 'नौकरी': 215, 'भाई': 216, 'जल्द': 217, 'लिया।': 218, 'थोड़ा': 219, 'थोड़ी': 220, 'चाहिए': 221, 'चिट्ठी': 222, 'ले': 223, 'आपकी': 224, 'वाला': 225, 'फिरसे': 226, 'बस': 227, 'तुम्हारा': 228, 'टीवी': 229, 'बाद': 230, 'कब': 231, 'मन': 232, 'लड़की': 233, 'सच': 234, 'जाती': 235, 'देना': 236, 'बिना': 237, 'या': 238, 'सुबह': 239, 'चुका': 240, 'थक': 241, 'साफ़': 242, 'जन्मदिन': 243, 'ज़रूरत': 244, 'यकीन': 245, 'पढ़': 246, 'रोज़': 247, 'नहीं।': 248, 'हमें': 249, 'जानता': 250, 'बड़े': 251, 'ऐसा': 252, 'जाएगा।': 253, 'लिया': 254, 'करनी': 255, 'देख': 256, 'वाले': 257, 'छः': 258, 'करी।': 259, 'लगा': 260, 'माफ़': 261, 'प्यार': 262, 'दोनो': 263, 'शहर': 264, 'आवाज़': 265, 'नाम': 266, 'पीछे': 267, 'पूरी': 268, 'किताबें': 269, 'दरवाज़े': 270, 'इतना': 271, 'चाय': 272, 'इन': 273, 'कितनी': 274, 'जापान': 275, 'खाने': 276, 'वजह': 277, 'बच्चों': 278, 'सही': 279, 'आने': 280, 'समझ': 281, 'सोच': 282, 'मुझपर': 283, 'चीज़': 284, 'इनसान': 285, 'विदेश': 286, 'हाथ': 287, 'पिताजी': 288, 'हुआ।': 289, 'शादी': 290, 'टीचर': 291, 'ना': 292, 'कपड़े': 293, 'पिछले': 294, 'हफ़्ते': 295, 'दे': 296, 'नदी': 297, 'पाँच': 298, 'दूसरे': 299, 'आदत': 300, 'मेज़': 301, 'आमतौर': 302, 'सिगरेट': 303, 'महीने': 304, 'कौन': 305, 'लगी': 306, 'कैसा': 307, 'ग़लत': 308, 'कृपया': 309, 'उम्र': 310, 'तैयार': 311, 'लड़के': 312, 'मिलने': 313, 'इंतेज़ार': 314, 'इस्तेमाल': 315, 'चलाना': 316, 'खो': 317, 'मिलना': 318, 'होगा': 319, 'दोपहर': 320, 'आसान': 321, 'मिला।': 322, 'उनकी': 323, 'काफ़ी': 324, 'कमरा': 325, 'आपके': 326, 'होते': 327, 'अकेले': 328, 'धीरे': 329, 'फ़ायदा': 330, 'उनके': 331, 'अंदर': 332, 'जाओ।': 333, 'भूल': 334, 'आग': 335, 'आपसे': 336, 'आया।': 337, 'लग': 338, 'हुई।': 339, 'करो': 340, 'जानते': 341, 'रहते': 342, 'बताया': 343, 'जैसा': 344, 'कितना': 345, 'गर्मी': 346, 'बहन': 347, 'भरोसा': 348, 'सेव': 349, 'जूते': 350, 'जहाँ': 351, 'सवाल': 352, 'पीना': 353, 'मर': 354, 'आठ': 355, 'दिनों': 356, 'देने': 357, 'क्योंकि': 358, 'कहना': 359, 'दुनिया': 360, 'अगले': 361, 'गाँव': 362, 'आपका': 363, 'चलो': 364, 'कीजिए।': 365, 'कुत्ते': 366, 'आया': 367, 'पैसों': 368, 'आराम': 369, 'पढ़ाई': 370, 'मज़ाक': 371, 'याद': 372, 'खुशी': 373, 'बन': 374, 'विश्वास': 375, 'उन': 376, 'पड़ी।': 377, 'देखना': 378, 'आए': 379, 'जाकर': 380, 'घड़ी': 381, 'पुलिस': 382, 'होंगे।': 383, 'पार्टी': 384, 'स्टेशन': 385, 'परेशान': 386, 'बाल': 387, 'कॉफ़ी': 388, 'लगभग': 389, 'अक्सर': 390, 'मिल': 391, 'सकती।': 392, 'उन्हें': 393, 'खबर': 394, 'दवाई': 395, 'सो': 396, 'समस्या': 397, 'मम्मी': 398, 'लंदन': 399, 'साईकल': 400, 'फ़र्क': 401, 'लगती': 402, 'सलाह': 403, 'बता': 404, 'निकल': 405, 'वैसा': 406, 'तैरना': 407, 'करूँगा।': 408, 'वादा': 409, 'बीमार': 410, 'मौत': 411, 'दरवाज़ा': 412, 'संगीत': 413, 'फिर': 414, 'कहानी': 415, 'शायद': 416, 'करी': 417, 'मुलाकात': 418, 'ग़लती': 419, 'चालू': 420, 'ली।': 421, 'जितना': 422, 'लम्बा': 423, 'कीजिएगा': 424, 'लेना': 425, 'पेड़': 426, 'जान': 427, 'ख़याल': 428, 'हवा': 429, 'सकते।': 430, 'मैरी': 431, 'पड़ेगी।': 432, 'रखना': 433, 'ऐसी': 434, 'तेज़': 435, 'अजीब': 436, 'राजा': 437, 'डर': 438, 'छोटी': 439, 'पुराने': 440, 'ढूँढ': 441, 'सैर': 442, 'चाह्ता': 443, 'तस्वीर': 444, 'नई': 445, 'सका।': 446, 'बीच': 447, 'अचानक': 448, 'मानो': 449, 'दूर': 450, 'लिखी': 451, 'जैसे': 452, 'होगी।': 453, 'बर्दाश्त': 454, 'अलग': 455, 'भूख': 456, 'तू': 457, 'देखने': 458, 'इसे': 459, 'मछलियाँ': 460, 'हमारा': 461, 'बिस्तर': 462, 'पैर': 463, 'पतंग': 464, 'ध्यान': 465, 'शोर': 466, 'खराब': 467, 'दर्द': 468, 'विद्यार्थी': 469, 'चोरी': 470, 'आँखें': 471, 'आएगा।': 472, 'सकती': 473, 'पैदा': 474, 'परिवार': 475, 'चुके': 476, 'आती': 477, 'करके': 478, 'बुरी': 479, 'जाए।': 480, 'आसमान': 481, 'डब्बे': 482, 'लगाकर': 483, 'बुखार': 484, 'काट': 485, 'बज': 486, 'दीजिए।': 487, 'रंग': 488, 'अफ़वाह': 489, 'नाप': 490, 'ज़िन्दगी': 491, 'जानवर': 492, 'भाग': 493, 'खाली': 494, 'बोल': 495, 'आसानी': 496, 'खेलना': 497, 'काश': 498, 'चीनी': 499, 'टेनिस': 500, 'दोनों': 501, 'होमवर्क': 502, 'जंगल': 503, 'अध्यापक': 504, 'रहने': 505, 'पीने': 506, 'किस': 507, 'जाते': 508, 'खिड़की': 509, 'दुर्घटना': 510, 'सफ़र': 511, 'पूरे': 512, 'इसके': 513, 'बजाय': 514, 'सड़क': 515, 'बोली': 516, 'बड़ी': 517, 'भाषा': 518, 'राजधानी': 519, 'रहना': 520, 'इतने': 521, 'ज़िम्मेदार': 522, 'पढ़ने': 523, 'अंतर': 524, 'बच्चा': 525, 'मशीन': 526, 'खड़ा': 527, 'लगते': 528, 'आओ।': 529, 'लो।': 530, 'फूल': 531, 'खरीदना': 532, 'आऊँगा।': 533, 'गरम': 534, 'ज़रूरी': 535, 'आई': 536, 'सुनाई': 537, 'गिटार': 538, 'बिजली': 539, 'बारी': 540, 'रहें': 541, 'सच्चाई': 542, 'जंग': 543, 'रहती': 544, 'किसने': 545, 'वही': 546, 'सा': 547, 'i': 548, 'छोटा': 549, 'सुंदर': 550, 'चोर': 551, 'सवालों': 552, 'दिखने': 553, 'अमीर': 554, 'बेसबॉल': 555, 'आओगे': 556, 'पढ़ना': 557, 'बना': 558, 'कामयाब': 559, 'सहमत': 560, 'पीठ': 561, 'मिला': 562, 'फ़ैसला': 563, 'रविवार': 564, 'निराश': 565, 'चुकी': 566, 'अफ़सर': 567, 'गरीब': 568, 'विज्ञान': 569, 'आगे': 570, 'लम्बी': 571, 'कहीं': 572, 'झील': 573, 'पूरा': 574, 'चहिए।': 575, 'औरत': 576, 'जाऊँगा।': 577, 'साढ़े': 578, 'बजाना': 579, 'वाली': 580, 'ग़लतियाँ': 581, 'देश': 582, 'उसपर': 583, 'इससे': 584, 'सामने': 585, 'खड़े': 586, 'लगाया।': 587, 'जी': 588, 'बीमारी': 589, 'मिनट': 590, 'कीमत': 591, 'आना': 592, 'सीखना': 593, 'डॉलर': 594, 'उठा': 595, 'दिलचस्पी': 596, 'फ़िल्म': 597, 'रूप': 598, 'क्लास': 599, 'दिलचस्प': 600, 'रुक': 601, 'आखिरकार': 602, 'बोलना': 603, 'खिलाड़ी': 604, 'नम्बर': 605, 'सौ': 606, 'मना': 607, 'असली': 608, 'चाहती': 609, 'सुनकर': 610, 'जाएगी।': 611, 'शौक': 612, 'जहाज़': 613, 'करोगे': 614, 'हूं।': 615, 'विषय': 616, 'जितनी': 617, 'चीन': 618, 'स्वास्थ्य': 619, 'कई': 620, 'पहाड़': 621, 'लिख': 622, 'पाया।': 623, 'रह': 624, 'देखभाल': 625, 'छोटे': 626, 'पा': 627, 'पहचान': 628, 'तब': 629, 'मज़े': 630, 'पेट': 631, 'भर': 632, 'चलें': 633, 'मत।': 634, 'ली': 635, 'कैसी': 636, 'पता।': 637, 'बरफ़': 638, 'गिर': 639, 'मुफ़्त': 640, 'नीचे': 641, 'उड़': 642, 'लड़का': 643, 'कमी': 644, 'इतिहास': 645, 'रहूँगा।': 646, 'भगवान': 647, 'करता।': 648, 'बस्ता': 649, 'पहनी': 650, 'बक': 651, 'ऊपर': 652, 'आस': 653, 'पड़ोस': 654, 'बूढ़ा': 655, 'अप्रैल': 656, 'चाबी': 657, 'लगा।': 658, 'बैंक': 659, 'उम्मीद': 660, 'मिलेंगे।': 661, 'चली': 662, 'कौनसा': 663, 'महसूस': 664, 'खरीदी।': 665, 'जीत': 666, 'चाहूँगा।': 667, 'रही।': 668, 'पड़ेगा।': 669, 'चिंता': 670, 'की।': 671, 'होना': 672, 'योजना': 673, 'खा': 674, 'मछली': 675, 'खुला': 676, 'ग्यारह': 677, 'लाल': 678, 'ड्रेस': 679, 'ओर': 680, 'राज़': 681, 'अंडे': 682, 'प्रस्ताव': 683, 'स्वीकार': 684, 'सारा': 685, 'आता।': 686, 'नफ़रत': 687, 'खेल': 688, 'आएगा': 689, 'भला': 690, 'गाना': 691, 'डाला।': 692, 'सात': 693, 'खुद': 694, 'नौ': 695, 'बत्ती': 696, 'पहुँच': 697, 'दूध': 698, 'मेहनत': 699, 'तरफ़': 700, 'सके': 701, 'दूँगा।': 702, 'कुरसी': 703, 'आई।': 704, 'डब्बा': 705, 'खोल': 706, 'संतुष्ट': 707, 'कप': 708, 'सोने': 709, 'सेहत': 710, 'पत्नी': 711, 'कहा।': 712, 'लेने': 713, 'इनकार': 714, 'मुझ': 715, 'कठिन': 716, 'बुराई': 717, 'अटैची': 718, 'रो': 719, 'पसंदीता': 720, 'बदलने': 721, 'भूलना।': 722, 'खाते': 723, 'छोड़ने': 724, 'राय': 725, 'मील': 726, 'बिलकुल': 727, 'मे': 728, 'शब्द': 729, 'हिसाब': 730, 'घंटे': 731, 'कनाडा': 732, 'यूरोप': 733, 'नियम': 734, 'पार': 735, 'सपना': 736, 'नगर': 737, 'होतीं': 738, 'दुकान': 739, 'हमसे': 740, 'आते': 741, 'टिकटें': 742, 'अमेरिका': 743, 'अफ़्रीका': 744, 'बेटे': 745, 'पकड़': 746, 'हद': 747, 'इसलिए': 748, 'रवाना': 749, 'इरादा': 750, 'जाऊँगी।': 751, 'लिखा': 752, 'बेहतर': 753, 'बहनें': 754, 'आजकल': 755, 'ढूँढने': 756, 'विमान': 757, 'कॉलेज': 758, 'विश्व': 759, 'सुन': 760, 'पहली': 761, 'ऐसे': 762, 'सामान': 763, 'केवल': 764, 'पैरिस': 765, 'ख़रीद': 766, 'दोस्तों': 767, 'लायक': 768, 'मुताबिक': 769, 'जिससे': 770, 'क्रिकेट': 771, 'शौकिया': 772, 'कर्मचारियों': 773, 'बनाने': 774, 'ब्रिज': 775, 'अम्रीका': 776, 'देते': 777, 'सरकार': 778, 'परीक्षा': 779, 'वाह': 780, '.': 781, 'जाओ': 782, 'हार': 783, 'करना।': 784, 'पंछी': 785, 'लेकिन': 786, 'अकेला': 787, 'बोर': 788, 'ठंड': 789, 'गाते': 790, 'बैठिए।': 791, 'मुस्कुराया।': 792, 'नया': 793, 'केक': 794, 'झूठ': 795, 'मुबारक': 796, 'समझता': 797, 'मान': 798, 'चीजों': 799, 'व्यस्थ': 800, 'बिल्ली': 801, 'सकतीं': 802, 'नक्शा': 803, 'गोली': 804, 'नए': 805, 'हों': 806, 'धोओ।': 807, 'पागल': 808, 'टोपी': 809, 'पति': 810, 'उल्टी': 811, 'नसीब': 812, 'काला': 813, 'सिखा': 814, 'चावल': 815, 'मूँह': 816, 'लम्बे': 817, 'कौनसी': 818, 'नींद': 819, 'नीली': 820, 'शादीशुदा': 821, 'बताओ।': 822, 'रेडियो': 823, 'वो': 824, 'महंगी': 825, 'रेलगाड़ी': 826, 'कौआ': 827, 'तोड़': 828, 'बनाया': 829, 'कह': 830, 'पुरानी': 831, 'बताने': 832, 'शराब': 833, 'लिखना': 834, 'कमीज़': 835, 'टैक्स': 836, 'पेनसिल': 837, 'जॉगिंग': 838, 'समुंदर': 839, 'कामयाबी': 840, 'गुस्सा': 841, 'उधार': 842, 'प्रतीक्षा': 843, 'ज़ुकाम': 844, 'बारह': 845, 'पहने': 846, 'भूत': 847, 'लगतीं': 848, 'तेज़ी': 849, 'रख': 850, 'व्यापार': 851, 'थोड़े': 852, 'हमको': 853, 'उनका': 854, 'छलाँग': 855, 'इसको': 856, 'जाऊं': 857, 'गेंद': 858, 'बैठ': 859, 'बताओ': 860, 'छूट': 861, 'लगाई।': 862, 'उनको': 863, 'जैसी': 864, 'गलत': 865, 'मजबूर': 866, 'बोलो।': 867, 'लेता': 868, 'खटखटाया।': 869, 'जापानी': 870, 'उठता': 871, 'ठंडा': 872, 'पियानो': 873, 'तेल': 874, 'उतना': 875, 'निर्णय': 876, 'फ़ुटबॉल': 877, 'इलज़ाम': 878, 'गिलास': 879, 'बजने': 880, 'लकड़ी': 881, 'चार': 882, 'कैंसर': 883, 'उपन्यास': 884, 'मुलाक़ात': 885, 'टैक्सी': 886, 'पढ़ा': 887, 'टोक्यो': 888, 'हाँ': 889, 'किनारे': 890, 'सज़ा': 891, 'दी': 892, 'गाड़ियाँ': 893, 'दिखाई': 894, 'होती।': 895, 'मुसीबत': 896, 'देखकर': 897, 'छाया': 898, 'धन्यवाद।': 899, 'बनी': 900, 'रोने': 901, 'पड़ा।': 902, 'बीस': 903, 'रक्षा': 904, 'करवाना': 905, 'जगह': 906, 'फूलों': 907, 'पड़ता।': 908, 'जरूरत': 909, 'समान': 910, 'सर': 911, 'चोट': 912, 'दोगे': 913, 'अगली': 914, 'फ़्रानसीसी': 915, 'बर्ताव': 916, 'ओसाका': 917, 'खूबसूरत': 918, 'बर्बादी': 919, 'धीमी': 920, 'बचा': 921, 'लिए।': 922, 'खेलने': 923, 'चाहेंगे': 924, 'दफ़्तर': 925, 'सुथरा': 926, 'भाषण': 927, 'नतीजे': 928, 'खेत': 929, 'नानी': 930, 'सीधे': 931, 'इटली': 932, 'अलावा': 933, 'जनसंख्या': 934, 'ऑस्ट्रेलिया': 935, 'छोड़ना': 936, 'सी': 937, 'चीज़ें': 938, 'मक्खन': 939, 'उठाया।': 940, 'सोमवार': 941, 'घंटों': 942, 'जाता।': 943, 'सपने': 944, 'डाक': 945, 'मानते': 946, 'उनसे': 947, 'सोते': 948, 'पत्र': 949, 'खड़ी': 950, 'तुमको': 951, 'बेचैन': 952, 'कविता': 953, 'निकालते': 954, 'व्यक्ति': 955, 'भोजन': 956, 'छत': 957, 'रहा।': 958, 'बातचीत': 959, 'कब्रिस्तान': 960, 'बाज़ार': 961, 'स्टॉप': 962, 'देता': 963, 'जल्दबाज़ी': 964, 'अखबार': 965, 'पालन': 966, 'उत्तर': 967, 'शर्म': 968, 'पचास': 969, 'तस्वीरें': 970, 'अस्पताल': 971, 'कम्प्यूटर': 972, 'इतनी': 973, 'संदेश': 974, 'दिल्ली': 975, 'चलती': 976, 'उठते': 977, 'वसीयत': 978, 'जानना': 979, 'हैरान': 980, 'जेब': 981, 'पकड़ा': 982, 'मौके': 983, 'बुलाया': 984, 'कम्पनी': 985, 'जाया': 986, 'पछतावा': 987, 'चाहे': 988, 'जाए': 989, 'देगी।': 990, 'कहने': 991, 'पाया': 992, 'राज़ी': 993, 'बत्तियाँ': 994, 'मिली।': 995, 'इलाज': 996, 'पहचानता': 997, 'म्युज़ियम': 998, 'इंग्लैंड': 999, 'थीं।': 1000, 'जिसे': 1001, 'दिख': 1002, 'रास्ते': 1003, 'पुस्तकालय': 1004, 'माता': 1005, 'सोचता': 1006, 'पड़ता': 1007, 'टेरेसा': 1008, 'समझे': 1009, 'मौज': 1010, 'बेहोश': 1011, 'शाबाश': 1012, 'किसको': 1013, 'किसे': 1014, 'मालूम': 1015, 'पीछा': 1016, 'तैर': 1017, 'ताकतवर': 1018, 'गणित': 1019, 'बोला।': 1020, 'जाना।': 1021, 'खोलो।': 1022, 'खोलिए।': 1023, 'आईए।': 1024, 'दोबारा': 1025, 'दाढ़ी': 1026, 'चुकीं': 1027, 'करेंगे।': 1028, 'आना।': 1029, 'भागते': 1030, 'अरबी': 1031, 'बदतमीज़': 1032, 'दौड़ने': 1033, 'कैफ़े': 1034, 'आसपास': 1035, 'हसीना': 1036, 'गलती': 1037, 'चिड़ियाँ': 1038, 'देखें।': 1039, 'चढ़': 1040, 'आओ': 1041, 'बैठो।': 1042, 'बोलता': 1043, 'लो': 1044, 'जानता।': 1045, 'बूढ़ी': 1046, 'मै': 1047, 'मिलकर': 1048, 'हस्ताक्षर': 1049, 'धोखा': 1050, 'चिड़िया': 1051, 'किसकी': 1052, 'पक्षी': 1053, 'घोसले': 1054, 'रहेंगे।': 1055, 'सिरदर्द': 1056, 'छोड़ो।': 1057, 'पत्थर': 1058, 'गहरी': 1059, 'साँस': 1060, 'रोया।': 1061, 'मानता': 1062, 'हूं': 1063, 'सुनी।': 1064, 'औरतों': 1065, 'प्यासा': 1066, 'रातभर': 1067, 'दिखता': 1068, 'महंगा': 1069, 'सच्ची': 1070, 'रहे।': 1071, 'गुलदान': 1072, 'कलम': 1073, 'जिमखाने': 1074, 'हालत': 1075, 'स्वाद': 1076, 'समझा': 1077, 'पूछना': 1078, 'टिकट': 1079, 'खींची।': 1080, 'हरे': 1081, 'हवाई': 1082, 'रहतीं': 1083, 'नाराज़': 1084, 'दीं।': 1085, 'बहाना': 1086, 'तुमपर': 1087, 'हल्का': 1088, 'लिपटा': 1089, 'रेशम': 1090, 'टूटी': 1091, 'पी': 1092, 'जाओगे': 1093, 'साबित': 1094, 'मोटी': 1095, 'घंटी': 1096, 'पैसा': 1097, 'निशाना': 1098, 'घोड़े': 1099, 'बरस': 1100, 'आभारी': 1101, 'बॉस्टन': 1102, 'दौड़': 1103, 'बेटी': 1104, 'समझो।': 1105, 'सूज': 1106, 'डालना': 1107, 'रखदो।': 1108, 'घुसाना': 1109, 'घुसा': 1110, 'मांगी।': 1111, 'ज़िद्दी': 1112, 'चलना': 1113, 'रोमांचक': 1114, 'लिफ़्ट': 1115, 'आएँगे': 1116, 'समझिए।': 1117, 'माँगो।': 1118, 'चुरा': 1119, 'भौतिक': 1120, 'दिलाया।': 1121, 'सोकर': 1122, 'अनुपस्थित': 1123, 'काले': 1124, 'पहनती': 1125, 'नर्म': 1126, 'दिल': 1127, 'मुड़कर': 1128, 'चाकू': 1129, 'करती।': 1130, 'शेर': 1131, 'पालतू': 1132, 'छूने': 1133, 'जाएँगे': 1134, 'याददाश्त': 1135, 'कुरसियाँ': 1136, 'पासपोर्ट': 1137, 'पार्क': 1138, 'लगाया': 1139, 'शिकायत': 1140, 'चाहूँगी।': 1141, 'दर्जन': 1142, 'सफ़ेद': 1143, 'हुएँ': 1144, 'लागु': 1145, 'कर्ज़': 1146, 'सुन्दर': 1147, 'मोड़ो।': 1148, 'जरूरी': 1149, 'छुट्टी': 1150, 'बगीचा': 1151, 'तीस': 1152, 'शौकीन': 1153, 'बंदूक': 1154, 'कत्ल': 1155, 'होता।': 1156, 'यहां': 1157, 'किलो': 1158, 'समझाउँगा।': 1159, 'लोहा': 1160, 'बाप': 1161, 'टीम': 1162, 'रास्ता': 1163, 'नही': 1164, 'आयात': 1165, 'कौनसे': 1166, 'पढ़ते': 1167, 'गिरफ़्तार': 1168, 'परियों': 1169, 'पड़ोसियों': 1170, 'डरता': 1171, 'जल': 1172, 'आँखों': 1173, 'खरीदी': 1174, 'खाता': 1175, 'हाल': 1176, 'बेच': 1177, 'मैनेजर': 1178, 'चाह्ती': 1179, 'मरने': 1180, 'तौलिया': 1181, 'चुकें': 1182, 'मिलते': 1183, 'पूछ': 1184, 'बीवी': 1185, 'दिखाई।': 1186, 'सांप': 1187, 'तोहफ़े': 1188, 'पाएगा।': 1189, 'छा': 1190, 'क़ैदी': 1191, 'रिहा': 1192, 'कारण': 1193, 'सरल': 1194, 'स्वतंत्रता': 1195, 'दुःखी': 1196, 'तालाब': 1197, 'होगी': 1198, 'कोयले': 1199, 'आकर': 1200, 'व्यक्तिगत': 1201, 'ग्रीक': 1202, 'माँगे।': 1203, 'सगाई': 1204, 'क्योटो': 1205, 'बेकार': 1206, 'मुकाबले': 1207, 'खरीदीं।': 1208, 'मर्ज़ी': 1209, 'आवश्यकता': 1210, 'खरीदने': 1211, 'ज़िन्दा': 1212, 'मज़ेदार': 1213, 'मुसलाधार': 1214, 'वर्षा': 1215, 'मशहूर': 1216, 'हँस': 1217, 'कीचड़': 1218, 'रखा': 1219, 'हँसे।': 1220, 'मनाया।': 1221, 'अभिमान': 1222, 'सुनते': 1223, 'हित': 1224, 'शोक': 1225, 'अच्छाई': 1226, 'फ़्रान्स': 1227, 'पश्चिमी': 1228, 'समझाया।': 1229, 'खेलता': 1230, 'जर्मन': 1231, 'अगस्त': 1232, 'चलने': 1233, 'सन': 1234, 'मेक्सिको': 1235, 'स्पैनिश': 1236, 'अरब': 1237, 'येन': 1238, 'सरासर': 1239, 'हिला': 1240, 'देखो': 1241, 'धूम्रपान': 1242, 'खतरे': 1243, 'शांति': 1244, 'रहो।': 1245, 'हीरा': 1246, 'दाँतों': 1247, 'शब्दों': 1248, 'दीवार': 1249, 'अंग्रेजी': 1250, 'गुलाब': 1251, 'बनने': 1252, 'बदबू': 1253, 'करतें': 1254, 'हिरण': 1255, 'बताया।': 1256, 'बहस': 1257, 'रोम': 1258, 'बंदर': 1259, 'आबादी': 1260, 'बढ़': 1261, 'उतर': 1262, 'घटना': 1263, 'चहिए': 1264, 'बैठा': 1265, 'करा': 1266, 'ब्रेड': 1267, 'तो।': 1268, 'विचार': 1269, 'नहीँ': 1270, 'नहाता': 1271, 'फँस': 1272, 'चूर': 1273, 'भविष्य': 1274, 'समझदार': 1275, 'चौंक': 1276, 'होनी': 1277, 'पूछने': 1278, 'कारोबार': 1279, 'पड़': 1280, 'खतरनाक': 1281, 'मतलब': 1282, 'वैसे': 1283, 'धन्यवाद': 1284, 'उतार': 1285, 'लेट': 1286, 'शानदार': 1287, 'धूल': 1288, 'सूरज': 1289, 'जारी': 1290, 'निकले।': 1291, 'नज़र': 1292, 'करेगी': 1293, 'रस': 1294, 'माँगनी': 1295, 'लेनी': 1296, 'सम्मान': 1297, 'ख़त्म': 1298, 'ताज़ी': 1299, 'सब्ज़ियाँ': 1300, 'बरी': 1301, 'किसान': 1302, 'लगाए': 1303, 'आशा': 1304, 'भारी': 1305, 'मुझको': 1306, 'बुरे': 1307, 'देखते': 1308, 'निकली।': 1309, 'हल्के': 1310, 'डूबते': 1311, 'ऊँचा': 1312, 'नियमों': 1313, 'चलतें': 1314, 'कंजूस': 1315, 'मारा': 1316, 'होकर': 1317, 'आलसी': 1318, 'कॉल': 1319, 'बुरा': 1320, 'बॉस': 1321, 'करवाया।': 1322, 'मंदिरों': 1323, 'बोलते': 1324, 'कष्ट': 1325, 'डाँट': 1326, 'जचती': 1327, 'तरीके': 1328, 'होगे': 1329, 'गप': 1330, 'देनी': 1331, 'उपयोग': 1332, 'कार्यक्रम': 1333, 'हाथी': 1334, 'दुख': 1335, 'छिपा': 1336, 'भाषाएँ': 1337, 'अक्खड़पन': 1338, 'बनना': 1339, 'तैरकर': 1340, 'नाज़': 1341, 'उड़ान': 1342, 'हुईं': 1343, 'सीखने': 1344, 'गति': 1345, 'नाश्ता': 1346, 'फ़िल्में': 1347, 'तोड़ी': 1348, 'पक्का': 1349, 'जीना': 1350, 'गलतियों': 1351, 'खाया।': 1352, 'जायदाद': 1353, 'लगता।': 1354, 'बयान': 1355, 'शक': 1356, 'सीखी': 1357, 'आर्ट': 1358, 'पंख': 1359, 'निर्भर': 1360, 'तैयारी': 1361, 'लेना।': 1362, 'पढ़ाना': 1363, 'तूफ़ान': 1364, 'नष्ट': 1365, 'प्रश्न': 1366, 'उन्हे': 1367, 'जानने': 1368, 'होंगीं': 1369, 'सालों': 1370, 'शतक': 1371, 'बच्चें': 1372, 'टॉयलेट': 1373, 'वाक्य': 1374, 'सोचा': 1375, 'जाओगे।': 1376, 'दादी': 1377, 'शिक़ायत': 1378, 'बेटा': 1379, 'सितारे': 1380, 'सलह': 1381, 'क़ानून': 1382, 'पत्तियों': 1383, 'पाए।': 1384, 'सुनने': 1385, 'रखा।': 1386, 'मिलेगा।': 1387, 'पड़ी': 1388, 'दिमाग़': 1389, 'मीटिंग': 1390, 'उलटी': 1391, 'नकल': 1392, 'शिक्षा': 1393, 'महीनों': 1394, 'सीख': 1395, 'शब्दकोश': 1396, 'बसीं।': 1397, 'पाल': 1398, 'पोस': 1399, 'हिचकिचाहट': 1400, 'आईएगा।': 1401, 'हफ़्तों': 1402, 'गुड़िया': 1403, 'बोलने': 1404, 'रहीं': 1405, 'एकदम': 1406, 'पर्यावरण': 1407, 'आम': 1408, 'कहावत': 1409, 'क्लब': 1410, 'न्योता': 1411, 'डाल': 1412, 'चिट्ठियाँ': 1413, 'वीडियो': 1414, 'पहलू': 1415, 'मिलती': 1416, 'हिरासत': 1417, 'समझने': 1418, 'भूकम्प': 1419, 'उतारे': 1420, 'लगादी।': 1421, 'अंत': 1422, 'भूलूँगा।': 1423, 'ख़रीदो': 1424, 'देशों': 1425, 'एसी': 1426, 'उठाने': 1427, 'ही।': 1428, 'कीमती': 1429, 'संपत्ति': 1430, 'विदेशी': 1431, 'चाह्ते': 1432, 'जाएगा': 1433, 'बातें': 1434, 'ऐक्सीडेंट': 1435, 'लापरवाही': 1436, 'चुराने': 1437, 'निराशा': 1438, 'इंग्लैड': 1439, 'रोकने': 1440, 'उठना': 1441, 'नामुमकिन': 1442, 'खर्च': 1443, 'बदल': 1444, 'टेस्ट': 1445, 'खिलाफ़': 1446, 'पर्वत': 1447, 'छोड़े': 1448, 'खोलते': 1449, 'ग़लतफ़ैमी': 1450, 'सम्पर्क': 1451, 'हस्पताल': 1452, 'पहुँचा': 1453, 'जिसके': 1454, 'उनपर': 1455, 'हज़ारों': 1456, 'आज़ादी': 1457, 'हड़ताल': 1458, 'परसों': 1459, 'भेजा': 1460, 'सत्रह': 1461, 'दुखी': 1462, 'खयाल': 1463, 'मिले': 1464, 'स्ट्रॉबेरी': 1465, 'विष्व': 1466, 'शहरों': 1467, 'जाएं।': 1468, 'हिफ़ाज़त': 1469, 'उतारने': 1470, 'मतलबी': 1471, 'बढ़ाने': 1472, 'समिति': 1473, 'तर': 1474, 'तहकीकात': 1475, 'राज्य': 1476, 'मातापिता': 1477, 'बाकी': 1478, 'हालांकि': 1479, 'जिसपर': 1480, 'जुड़वा': 1481, 'उनमें': 1482, 'लगेंगे।': 1483, 'पहचानते': 1484, 'मदर': 1485, 'कलकत्ता': 1486, 'बचाओ': 1487, 'उछलो': 1488, 'कूदो': 1489, 'छलांग': 1490, 'नमस्ते।': 1491, 'नमस्कार।': 1492, 'चियर्स': 1493, 'जीते।': 1494, 'बढ़िया': 1495, 'चले': 1496, 'ख़ुदा': 1497, 'हाफ़िज़।': 1498, 'उत्तम': 1499, 'स्वागत': 1500, 'स्वागतम्।': 1501, 'दूंगा।': 1502, 'उड़ते': 1503, 'ख़ूब': 1504, 'खेद': 1505, 'हँसा।': 1506, 'अकेली': 1507, 'दीवालिया': 1508, 'अद्भुत': 1509, 'निश्चित': 1510, 'हिलो': 1511, 'जलाती': 1512, 'भेजो।': 1513, 'अंगर': 1514, 'बार।': 1515, 'उबासी': 1516, 'चिल्लाओ': 1517, 'चिल्लाईए': 1518, 'आऊंगा।': 1519, 'एसटर': 1520, 'हिल': 1521, 'मालूम।': 1522, 'जाईये।': 1523, 'अविश्वसनीय': 1524, 'मोटे': 1525, 'पीकर': 1526, 'करदो।': 1527, 'खिलते': 1528, 'डॉनत': 1529, 'लेलूँगा।': 1530, 'दिखाओ।': 1531, 'ट्राए': 1532, 'पढ़ें।': 1533, 'पढ़के': 1534, 'सुनाओ।': 1535, 'झुकी।': 1536, 'सहायता': 1537, 'छूना': 1538, 'निकलो': 1539, 'नव': 1540, 'वर्ष': 1541, 'शुभकामनाएं': 1542, 'बधाईयाँ।': 1543, 'छुट्टियाँ': 1544, 'मंगलमय': 1545, 'अभिनेता': 1546, 'अनीश्वरवादी': 1547, 'चाल': 1548, 'जाने।': 1549, 'गर्मियाँ': 1550, 'आदर्श': 1551, 'बुलाएँगे।': 1552, 'थके': 1553, 'हारे': 1554, 'पे': 1555, 'आजाओ।': 1556, 'सको': 1557, 'बधाई': 1558, 'बनो।': 1559, 'मुस्कुराए।': 1560, 'इंतज़ार': 1561, 'पकाया।': 1562, 'हमला': 1563, 'रसोइया': 1564, 'बावर्ची': 1565, 'उड़ाएँ': 1566, 'रोना': 1567, 'बोलती': 1568, 'डरा': 1569, 'चुने।': 1570, 'आलूओं': 1571, 'काटो।': 1572, 'बनाओ।': 1573, 'मचाओ।': 1574, 'संत्रे': 1575, 'नारंगी': 1576, 'बस्ता।': 1577, 'प्यास': 1578, 'खरीदारी': 1579, 'शराबख़ाना': 1580, 'आँखे': 1581, 'बनातें': 1582, 'बनातीं': 1583, 'थें': 1584, 'धोका': 1585, 'चिल्लाए।': 1586, 'चिल्लाने': 1587, 'नौकरानी': 1588, 'रखता': 1589, 'पड़ा': 1590, 'देशद्रोही': 1591, 'जाचुका': 1592, 'रोई।': 1593, 'सिर': 1594, 'सुनता': 1595, 'दौड़ते': 1596, 'सच्चा': 1597, 'गईं': 1598, 'गाने': 1599, 'लगी।': 1600, 'पृथ्वी': 1601, 'घूमती': 1602, 'आमंत्रित': 1603, 'प्रयत्न': 1604, 'खुशखबर': 1605, 'ख़िलाफ़': 1606, 'युद्ध': 1607, 'विरोध': 1608, 'सुख': 1609, 'समुद्र': 1610, 'तट': 1611, 'कहां': 1612, 'पाय': 1613, 'बनाई': 1614, 'हाँ।': 1615, 'बिज़ी': 1616, 'सोये': 1617, 'फेंको।': 1618, 'तेरी': 1619, 'अकल': 1620, 'घास': 1621, 'चरने': 1622, 'करीं।': 1623, 'रोया': 1624, 'साधा': 1625, 'ज़रूर': 1626, 'चचेरा': 1627, 'ममेरा': 1628, '१९६०': 1629, '१९७९': 1630, 'देखता': 1631, 'गिरनी': 1632, 'गो': 1633, 'सूटकेस': 1634, 'मजेदार': 1635, 'संभालने': 1636, 'चलते': 1637, 'टोयोटा': 1638, 'पाँव': 1639, 'जम': 1640, 'उछल': 1641, 'चिढ़': 1642, 'बॅटर': 1643, 'आऊट': 1644, 'गायब': 1645, 'स्केटिंग': 1646, 'मज़ा': 1647, 'कद्दू': 1648, 'टेक्सी': 1649, 'बुलवाई।': 1650, 'प्रवेश': 1651, 'दाखिल': 1652, 'अकेलापन': 1653, 'थका': 1654, 'हारा': 1655, 'गाता': 1656, 'जोखिम': 1657, 'खाया': 1658, 'लाता': 1659, 'लाऊँगा।': 1660, 'खेलतें': 1661, 'स्याही': 1662, 'बाघ': 1663, 'जिसकी': 1664, 'पसीने': 1665, 'ज़बान': 1666, 'सम्भाल': 1667, 'भरना': 1668, 'अड्डा': 1669, 'सर्दी': 1670, 'क्षमा': 1671, 'बचाली।': 1672, 'प्रत्येक': 1673, 'जलन': 1674, 'अजनबी': 1675, 'आपत्ती': 1676, 'तकलीफ': 1677, 'खाती': 1678, 'ऊँगली': 1679, 'बेहोशी': 1680, 'तौर': 1681, 'समझकर': 1682, 'बोला': 1683, 'एलर्जी': 1684, 'चश्मा': 1685, 'चश्मे': 1686, 'उबाऊ': 1687, 'लेजाने': 1688, 'लिंकन': 1689, '१८६५': 1690, 'ख़ासियत': 1691, 'चादरें': 1692, 'गीलीं': 1693, 'पाइप': 1694, 'फट': 1695, 'मेरीं': 1696, 'ज़ू': 1697, 'बीतता': 1698, 'बियर': 1699, 'वार': 1700, 'इसमें': 1701, 'लौट': 1702, 'मोटा': 1703, 'कैमरा': 1704, 'मुर्गियाँ': 1705, 'देतीं': 1706, 'पुलिसवाला': 1707, 'सीड़ियों': 1708, 'फ़र्निचर': 1709, 'पैसेवाला': 1710, 'साठ': 1711, 'प्रतियोगिता': 1712, 'ढंग': 1713, 'डुबकी': 1714, 'नौकर': 1715, 'जीव': 1716, 'हड़बड़ी': 1717, 'कोरिया': 1718, 'मई': 1719, 'आँख': 1720, 'फेंकिए।': 1721, 'डालदो।': 1722, 'नन्हा': 1723, 'खिलौना': 1724, 'खरीद': 1725, 'लाई।': 1726, 'जी।': 1727, 'छोड़दी।': 1728, 'उड़ाया।': 1729, 'चिल्लाया।': 1730, 'बकवास': 1731, 'वैसी': 1732, 'भरनी।': 1733, 'बोओगे': 1734, 'काटोगे।': 1735, 'पाओ।': 1736, 'भला।': 1737, 'भरना।': 1738, 'लोमड़ी': 1739, 'जंगली': 1740, 'उड़ाओ।': 1741, 'थप्पड़': 1742, 'शुरु': 1743, 'जीतीं': 1744, 'कमा': 1745, 'बेटियाँ': 1746, 'सीखा।': 1747, 'फाड़': 1748, 'दया': 1749, 'पिंजरा': 1750, 'गस्सा': 1751, 'निकाला': 1752, 'ब्लडी': 1753, 'हवाईअड्डे': 1754, 'रखो': 1755, 'गुड़गुड़ा': 1756, 'न्यू': 1757, 'यॉर्क': 1758, 'छूटता': 1759, 'सफ़ाई': 1760, 'करूँ': 1761, 'जानती': 1762, 'पैसेवाली': 1763, 'पैसेवाले': 1764, 'दिखाया।': 1765, 'पकाया': 1766, 'पका': 1767, 'गेट': 1768, 'अच्छा।': 1769, 'प्रसन्न': 1770, 'पतली': 1771, 'इंजन': 1772, 'बैठते': 1773, 'तम्हे': 1774, 'खुलता': 1775, 'तापमान': 1776, 'हकला': 1777, 'रोकना': 1778, 'मंगलवार': 1779, 'देखतें': 1780, 'बूंद': 1781, 'पियो।': 1782, 'भूलना': 1783, 'ग्लास': 1784, 'रेत': 1785, 'पायी।': 1786, 'उठा।': 1787, 'सूप': 1788, 'सूँघ': 1789, 'घमण्डी': 1790, 'अहंकारी': 1791, 'अभिमानी': 1792, 'दंत': 1793, 'चिकित्सक': 1794, 'तोहफ़ा': 1795, 'बीयर': 1796, 'यही': 1797, 'टांगें': 1798, 'लम्बीं': 1799, 'लेआऊँ': 1800, 'खरीदे।': 1801, 'उदाहरण': 1802, 'कोईसा': 1803, 'अनाथ': 1804, 'गोद': 1805, 'आमने': 1806, 'हुए।': 1807, 'डरते': 1808, 'इसीलिए': 1809, 'नोट': 1810, 'भेजा।': 1811, 'गोल': 1812, 'वापिस': 1813, 'जीतेंगे।': 1814, 'डालते': 1815, 'किसलिए': 1816, 'राष्ट्रीयता': 1817, 'ज़बरदस्त': 1818, 'करदोगे': 1819, 'फैलती': 1820, 'बनता': 1821, 'चुनो।': 1822, 'ऐमब्यूलेंस': 1823, 'साथतानी': 1824, 'लिफ़ाफ़े': 1825, 'काटकर': 1826, 'मरा।': 1827, 'सुनेगा।': 1828, 'बैठिये।': 1829, 'आधा': 1830, 'किजिए': 1831, 'बगैर': 1832, 'सहन': 1833, 'जैकेट': 1834, 'मेट्रो': 1835, 'लेकर': 1836, 'पी।': 1837, 'खटखटाने': 1838, 'खाँसी': 1839, 'नहाने': 1840, 'पहला': 1841, 'पृष्ठ': 1842, 'सख्त': 1843, 'तेरा': 1844, 'बतादेना।': 1845, 'बसे।': 1846, 'ठहरिए।': 1847, 'चुप': 1848, 'रोते': 1849, 'करदिआ।': 1850, 'नब्ज़': 1851, 'मिले।': 1852, 'शामिल': 1853, 'पतला': 1854, 'जाएँगे।': 1855, 'बहादुरी': 1856, 'लाईन': 1857, 'लगकर': 1858, 'a': 1859, 'b': 1860, 'पाँचगुना': 1861, 'सस्ते': 1862, 'बिक': 1863, 'हिस्सा': 1864, 'पुलीस': 1865, 'अमरीका': 1866, 'ज़ोर': 1867, 'हिचकिचाया।': 1868, 'सबका': 1869, 'उड़ाता': 1870, 'बजाता': 1871, 'सिखाया।': 1872, 'चश्मदीद': 1873, 'गवाह': 1874, 'कोटे': 1875, 'पहुंच': 1876, 'कटोरियाँ': 1877, 'झलक': 1878, 'फ़ेसबुक': 1879, 'नाई': 1880, 'पल्ले': 1881, 'पड़ती।': 1882, 'लाती': 1883, 'छाँओं': 1884, 'जोड़ना': 1885, 'गर्म': 1886, 'चंद': 1887, 'दाहिना': 1888, 'बिल्लियों': 1889, 'दूसरों': 1890, 'ग़ायब': 1891, 'स्मॉग': 1892, 'पौधों': 1893, 'ज़हरीले': 1894, 'दुश्मन': 1895, 'धुंध': 1896, 'ताकत': 1897, 'दुरुपयोग': 1898, 'सेब': 1899, 'दिवस': 1900, 'रोक': 1901, 'बसे': 1902, 'पोत': 1903, 'टहलें।': 1904, 'नसीबवाला': 1905, 'बनाओगे': 1906, 'आपत्ति': 1907, 'तुरंत': 1908, 'मिलना।': 1909, 'अपौइंटमेंट': 1910, 'क्वाला': 1911, 'कहता': 1912, 'कभार': 1913, 'ईमानदारी': 1914, 'सर्वोत्तम': 1915, 'नीति': 1916, 'वास्तव': 1917, 'कहे': 1918, 'पेनसिलें': 1919, 'चलता': 1920, 'कहें': 1921, 'पढ़ूँ।': 1922, 'अस्वीकार': 1923, 'निम्नलिखित': 1924, 'वस्तुओं': 1925, 'जॉन': 1926, 'बैठा।': 1927, '४': 1928, 'जून': 1929, '१९७४': 1930, 'निकम्मा': 1931, 'बूढ़े': 1932, 'तलाश': 1933, 'चूहा': 1934, 'बुआ': 1935, 'लाईं।': 1936, 'खिलाना': 1937, 'लेटी': 1938, 'खेलती': 1939, 'रखना।': 1940, 'सुझाव': 1941, 'दुल्हन': 1942, 'मारा।': 1943, 'कड़वा': 1944, 'जूतों': 1945, 'पेंट': 1946, 'सूखा': 1947, 'बरसात': 1948, 'पिया': 1949, 'ऋतु': 1950, 'करदो': 1951, 'प्लीज़।': 1952, 'कप्तान': 1953, 'चुना।': 1954, 'निभाना': 1955, 'पहुँचाई।': 1956, 'औरडर': 1957, 'ब्रॅड': 1958, 'चौबीस': 1959, 'लाना।': 1960, 'उड़ना': 1961, 'कोक': 1962, 'सांस': 1963, 'पाता': 1964, 'क़ब्र': 1965, 'खोद': 1966, 'पढ़ी': 1967, 'ग़ुलाम': 1968, 'वहां': 1969, 'इक्कीस': 1970, 'रहेंगे': 1971, 'निकला': 1972, 'मेने': 1973, 'दिए।': 1974, 'सायकल': 1975, 'जन्म': 1976, '१९७७': 1977, 'उपयोगी': 1978, 'धातु': 1979, 'तकरीबन': 1980, 'होंगे': 1981, 'खर्चे': 1982, 'स्पा': 1983, 'जीन्स': 1984, 'पैंट': 1985, 'धुलाई': 1986, 'सिकुड़': 1987, 'बनाते': 1988, 'इच्छा': 1989, 'प्रकट': 1990, 'हल्की': 1991, 'आमंत्रण': 1992, 'पर्स': 1993, 'बालों': 1994, 'जूड़े': 1995, 'बाँधती': 1996, 'सिपाहियों': 1997, 'मोज़े': 1998, 'उतारिए।': 1999, 'जलकर': 2000, 'राख': 2001, 'साहब': 2002, 'दूरी': 2003, 'जापानियों': 2004, 'कालीं': 2005, 'तम्बाकू': 2006, 'महक': 2007, 'खुली': 2008, 'मकान': 2009, 'लेते': 2010, 'डालकर': 2011, 'पीते': 2012, 'पड़ोसी': 2013, 'दक्षिण': 2014, 'टर्मिनल': 2015, 'बैठना': 2016, 'ब्रश': 2017, 'रेखांकित': 2018, 'सुधारिए।': 2019, 'बचीं': 2020, 'झुँको।': 2021, 'आपने': 2022, 'खिल': 2023, 'बदला': 2024, 'जीने': 2025, 'कैनटीन': 2026, 'लन्च': 2027, 'कान': 2028, 'खींचा।': 2029, 'कमीज़ें': 2030, 'धुलवानीं': 2031, 'अभिलाषा': 2032, 'यादें': 2033, 'जीवित': 2034, 'रहेंगी।': 2035, 'बोतलें': 2036, 'ख़रीदीं।': 2037, 'पैरों': 2038, 'निशानों': 2039, 'करे।': 2040, 'दसियों': 2041, 'ईमानदार': 2042, 'मरना': 2043, 'भाग्य': 2044, 'रहो': 2045, 'ज़्यादातर': 2046, 'आएँ': 2047, 'बोलतीं': 2048, 'सिक्कों': 2049, 'इकट्ठा': 2050, 'कौपी': 2051, 'दिखाईए।': 2052, 'करें।': 2053, 'बोलो': 2054, 'घूमफिरकर': 2055, 'उगाई': 2056, 'इसका': 2057, 'सड़ने': 2058, 'खम्बे': 2059, 'भिड़': 2060, 'चट्टान': 2061, 'सीधी': 2062, 'घोड़ा': 2063, 'दुश्मनों': 2064, 'कुचल': 2065, 'चढ़ा।': 2066, 'बमबई': 2067, 'पटरी': 2068, 'त्याग': 2069, 'रोडिका': 2070, 'पाँचवी': 2071, 'बढ़ता': 2072, 'प्रेमपूर्वक': 2073, 'हादसा': 2074, 'खाएँगे': 2075, 'बुलाना': 2076, 'देखनी': 2077, 'तोड़ो।': 2078, 'द्वीप': 2079, 'आधे': 2080, 'सड़': 2081, 'छिपाई।': 2082, 'जवान': 2083, 'जवानी': 2084, 'न्यूयॉर्क': 2085, 'कबसे': 2086, 'किता': 2087, 'आएगी': 2088, 'युक्तियुक्त': 2089, 'ज्यादा': 2090, 'बास्': 2091, 'केटबॉल': 2092, 'देखता।': 2093, 'भागा।': 2094, 'सुलाना': 2095, 'ट्राफ़िक': 2096, 'जाम': 2097, 'ट्रैफ़िक': 2098, 'जैम': 2099, 'करुंगा।': 2100, 'करुंगी।': 2101, 'देखे': 2102, 'खिलाईएगा।': 2103, 'सेइचो': 2104, 'मात्सुमोतो': 2105, 'निधन': 2106, '१९९२': 2107, 'डरती': 2108, 'मिनटों': 2109, 'सोचा।': 2110, 'मुरझा': 2111, 'हुकूमत': 2112, 'रोगी': 2113, 'आखरी': 2114, 'भरी।': 2115, 'फ़िनलैंड': 2116, 'टूट': 2117, 'सुलझाना': 2118, 'चौड़ी': 2119, 'दीदी': 2120, 'अनहोनी': 2121, 'दल': 2122, 'मंदी': 2123, 'बाथरूम': 2124, 'सस्ता': 2125, 'आस्ट्रेलिया': 2126, 'लड़ने': 2127, 'झगड़ने': 2128, 'हल': 2129, 'उड़ाना': 2130, 'आखें': 2131, 'गोरे': 2132, 'कोआले': 2133, 'अर्थ': 2134, 'अँडे': 2135, 'चाबियों': 2136, 'बटुए': 2137, 'इशारा': 2138, 'फ़ोल्डर': 2139, 'दयालु': 2140, 'करलें।': 2141, 'राजनीति': 2142, 'छोड़ूँ': 2143, 'ऊँची': 2144, 'बोलिए।': 2145, 'पढ़ो।': 2146, 'आज़माती': 2147, 'पैक': 2148, 'आएगी।': 2149, 'चेतावनी': 2150, 'बैठी': 2151, 'उड़ाई।': 2152, 'उड़ा': 2153, 'भौंकता': 2154, 'धरती': 2155, 'परिक्रमा': 2156, 'जाँच': 2157, 'पड़ताल': 2158, 'शेरों': 2159, 'शिकार': 2160, 'जानें': 2161, 'लें': 2162, 'लीं।': 2163, 'पहुँचेगा।': 2164, 'चमड़े': 2165, 'उत्पाद': 2166, 'बेचती': 2167, 'पंद्राह': 2168, 'तौलिये': 2169, 'चर्च': 2170, 'सोलहवा': 2171, 'स्नातक': 2172, 'तत्पर': 2173, 'कीजिए': 2174, 'लेखक': 2175, 'आएंगे': 2176, 'लेलो।': 2177, 'माफ़ी': 2178, 'आइडिया': 2179, 'आदर': 2180, 'मालिक': 2181, 'निकाला।': 2182, 'ऊन': 2183, 'मात्रा': 2184, 'निर्यात': 2185, 'वैश्विक': 2186, 'समझते': 2187, 'दफ़नाया': 2188, 'उठाती': 2189, 'निभाओ।': 2190, 'बदले': 2191, 'पुस्तक': 2192, 'स्पष्ट': 2193, 'ख़राब': 2194, 'संभवतः': 2195, 'विख्यात': 2196, 'देदीजिए।': 2197, 'खरीदा।': 2198, 'घूरकर': 2199, 'उठकर': 2200, 'फ़्लैट': 2201, 'वक्त': 2202, 'बचाए।': 2203, 'ख़तरनाक': 2204, 'शब्दकोष': 2205, 'कहते': 2206, 'अटक': 2207, 'रुकी।': 2208, 'सख्ती': 2209, 'पेश': 2210, 'राजकुमारियों': 2211, 'व्यवहार': 2212, 'कूद': 2213, 'कूदो।': 2214, 'कौवे': 2215, 'नाव': 2216, 'तौलिए': 2217, 'पोंछो।': 2218, 'नाचना': 2219, 'चाहोगी': 2220, 'डान्स': 2221, 'रस्सी': 2222, 'फेंक': 2223, 'विस्तृत': 2224, 'समझाई।': 2225, 'कटवाता': 2226, 'पढ़ता': 2227, 'रखकर': 2228, 'तोला।': 2229, 'नाना': 2230, 'कहूँ।': 2231, 'कामकाज': 2232, 'नहा': 2233, 'प्रेम': 2234, 'जहां': 2235, 'माँगने': 2236, 'लगेगी।': 2237, 'दवाईयों': 2238, 'अरे': 2239, 'पेट्रोल': 2240, 'कक्षा': 2241, 'कीजिएगा।': 2242, 'जुटाने': 2243, 'लौटाए।': 2244, 'बेची': 2245, 'जातीं': 2246, 'उतारे।': 2247, 'सम्मेलन': 2248, 'समाप्त': 2249, 'गोलीबारी': 2250, 'बजा।': 2251, 'चोटी': 2252, 'चपटी': 2253, 'गुफ़ा': 2254, 'टाई': 2255, 'सूट': 2256, 'तरीका': 2257, 'होटल': 2258, 'ठहरे।': 2259, 'छूटते': 2260, 'लेंगे': 2261, 'बीटल्स': 2262, 'गा': 2263, 'मारने': 2264, 'झिलता': 2265, 'गिलहरी': 2266, 'डालियों': 2267, 'छुपी': 2268, 'पत्तियाँ': 2269, 'आईं।': 2270, 'इत्तेफ़ाक': 2271, 'एशिया': 2272, 'मैं।': 2273, 'मुस्कुराहट': 2274, 'प्रयोगों': 2275, 'कबूतरों': 2276, 'घंटो': 2277, 'झेला': 2278, 'मूर्ख': 2279, 'योग्यता': 2280, 'खुशकिसमत': 2281, 'सफ़ल': 2282, 'फ़ौरन': 2283, 'प्रथम': 2284, 'पुरस्कार': 2285, 'अनदेखा': 2286, 'रखो।': 2287, 'सुंदरता': 2288, 'मुर्गियों': 2289, 'दियें': 2290, 'कपड़ो': 2291, 'हानि': 2292, 'पहुँचाएगा।': 2293, 'अनुकरणीय': 2294, 'प्रदर्शन': 2295, 'बर्फ़': 2296, 'बिछी': 2297, 'हवाईजहाज़': 2298, 'फ़्रांस': 2299, 'महिलाये': 2300, 'क़त्ल': 2301, 'हत्याएँ': 2302, 'मुनाफ़े': 2303, 'बाँटा।': 2304, 'सीमा': 2305, 'सप्ताह': 2306, 'लगीं': 2307, 'लोगे': 2308, 'पढ़ो': 2309, 'रखनी': 2310, 'दरअसल': 2311, 'बर्न': 2312, 'स्विजरलैंड': 2313, 'सकतें': 2314, 'सुनी': 2315, 'डरो।': 2316, 'सहपाठियों': 2317, 'बनाना': 2318, 'बताए': 2319, 'उलटा': 2320, 'बनाए': 2321, 'रहता।': 2322, 'केस': 2323, 'छोड़ी।': 2324, 'विद्रोह': 2325, 'रोका।': 2326, 'भागता': 2327, 'बचाया।': 2328, 'पहुँचने': 2329, 'लगेगी': 2330, 'सैंडविच': 2331, 'बचे': 2332, 'नटखट': 2333, 'उतनी': 2334, 'सीढ़ियों': 2335, 'करवाई।': 2336, 'ग्रुप': 2337, 'संबंध': 2338, 'सुना': 2339, 'मश्हूर': 2340, 'अभिनेत्री': 2341, 'बर्तन': 2342, 'धोने': 2343, 'किताबों': 2344, 'जर्मनी': 2345, 'खरीदकर': 2346, 'मंगवाया': 2347, 'बजा': 2348, 'करूँगा': 2349, 'उड़कर': 2350, 'शनिवार': 2351, 'गौल्फ़': 2352, 'लगना': 2353, 'विदेषी': 2354, 'प्रेत': 2355, 'दूसरा': 2356, 'पूछा': 2357, 'डाँवाडोल': 2358, 'असुरक्षित': 2359, 'बगीचे': 2360, 'पेशा': 2361, 'पालनी': 2362, 'गड्ढा': 2363, 'फ़ुट': 2364, 'चौड़ा': 2365, 'ताक़त': 2366, 'छीन': 2367, 'रहस्य': 2368, 'तबाह': 2369, 'अकलमंद': 2370, 'बुलाई।': 2371, 'चाँद': 2372, 'उतरेगा।': 2373, 'लेनीं': 2374, 'इमारतों': 2375, 'वफ़ादारी': 2376, 'लिहाज': 2377, 'उठाना': 2378, 'गवा': 2379, 'फ़्रेंच': 2380, 'ख़तरे': 2381, 'पहुँचे।': 2382, 'सुनिए': 2383, 'ईश्वर': 2384, 'स्वयं': 2385, 'रूसी': 2386, 'अज्ञान': 2387, 'आशंका': 2388, 'जताई।': 2389, 'टूटे': 2390, 'टुकड़ों': 2391, 'जोड़ा।': 2392, 'करूँ।': 2393, 'खींज': 2394, 'ऑक्सफ़र्ड': 2395, 'विश्वविद्यालय': 2396, 'जानवरों': 2397, 'खर्चना': 2398, 'लौटकर': 2399, 'निर्दोष': 2400, 'ज़िंदा': 2401, 'कॉफ़ी।': 2402, 'दिखते': 2403, 'नौवे': 2404, 'बेबुनयाद': 2405, 'चूहे': 2406, 'बढ़ी।': 2407, 'मनुष्य': 2408, 'प्लान': 2409, 'भरेगा।': 2410, 'बिखेर': 2411, 'मंदिर': 2412, 'ब्राऊन': 2413, 'मारकर': 2414, 'हत्या': 2415, 'नाश्ते': 2416, 'पहनोगी': 2417, 'गहरा': 2418, 'कोहरा': 2419, 'बौद्ध': 2420, 'धर्म': 2421, 'पनीर': 2422, 'बनते': 2423, 'शास्त्रीय': 2424, 'ला': 2425, 'हड्डी': 2426, 'उसमें': 2427, 'बेसब्री': 2428, 'फटाफट': 2429, 'कंधे': 2430, 'माथे': 2431, 'पसीना': 2432, 'पोंछा।': 2433, 'वाक्यों': 2434, 'माईने': 2435, 'पैमाने': 2436, 'डालने': 2437, 'मौका': 2438, 'रफ़तार': 2439, 'दोगे।': 2440, 'आंकरेज': 2441, 'युरोप': 2442, 'कमाई': 2443, 'वर्तमान': 2444, 'आमदनी': 2445, 'सोचो': 2446, 'टाइम': 2447, 'असभ्यता': 2448, 'सोना': 2449, '१५': 2450, 'ख़ज़ाना': 2451, 'खोदा।': 2452, 'मार': 2453, 'बाएं': 2454, 'मुड़ो': 2455, 'चिंतित': 2456, 'प्रकार': 2457, 'ढूंढ': 2458, 'डिनर': 2459, 'किसके': 2460, 'टी': 2461, 'शर्ट': 2462, 'बच्ची': 2463, 'आयडिया': 2464, 'करें': 2465, 'एहसान': 2466, 'माँगा।': 2467, 'घरवालों': 2468, 'कमाता': 2469, 'जुर्म': 2470, 'चलाने': 2471, 'नाकामयाबी': 2472, 'ख़रीदीं': 2473, 'मोहन': 2474, 'परिचित': 2475, 'सोफ़ा': 2476, 'शक़': 2477, 'युनिसायकल': 2478, 'पिछली': 2479, 'छाते': 2480, 'द्वार': 2481, 'वाक्यांश': 2482, 'ढूँढो।': 2483, 'उड़ाने': 2484, 'चादर': 2485, 'बिछाई।': 2486, 'रखती': 2487, 'अंकल': 2488, 'मामा': 2489, 'चाचा': 2490, 'ताऊजी': 2491, 'बुलाया।': 2492, 'पालने': 2493, 'मुर्झाई': 2494, 'गिरते': 2495, 'लगे': 2496, 'वाईन': 2497, 'चखकर': 2498, 'खिलाने': 2499, 'पहरा': 2500, 'गुंजाईश': 2501, 'मनाने': 2502, 'दिशाओं': 2503, 'फैले': 2504, 'कपड़ा': 2505, 'रेशमी': 2506, 'गला': 2507, 'भागे': 2508, 'आए।': 2509, 'जिनका': 2510, 'पिंक': 2511, 'ऑर्डर': 2512, 'नीले': 2513, 'कोशीश': 2514, 'रिमोट': 2515, 'देंगे।': 2516, 'दफ़तर': 2517, 'गबन': 2518, 'निभता': 2519, 'हे': 2520, 'कहानियाँ': 2521, 'सुनाया': 2522, 'बेगुनाह': 2523, 'अम्रीकी': 2524, 'साहित्य': 2525, 'कैंचियों': 2526, 'पूछूँगा।': 2527, 'लगाऊँगा': 2528, 'दिवाई': 2529, 'चुकताऊँगा।': 2530, 'चमत्कार': 2531, 'दिलाती': 2532, 'महाशय': 2533, 'माने': 2534, 'पियानिस्ट': 2535, 'झूठी': 2536, 'गाल': 2537, 'निशान': 2538, 'भाषाओं': 2539, 'समानताएं': 2540, 'पर्याप्त': 2541, 'भाषाएं': 2542, 'कटाने': 2543, 'जुर्रत': 2544, 'इगज़ैम': 2545, 'रिज़ल्ट': 2546, 'मनोदशा': 2547, 'मुस्कान': 2548, 'गाय': 2549, 'पूज्य': 2550, 'घुसा।': 2551, 'सहने': 2552, 'पड़े': 2553, 'कीमतें': 2554, 'करनीं': 2555, 'पड़ीं।': 2556, 'महान': 2557, 'कवि': 2558, 'बल्कि': 2559, 'पांव': 2560, 'लतपत': 2561, 'नमक': 2562, 'कॉनसर्ट': 2563, 'मिलीं': 2564, 'निभाएगा।': 2565, 'फ़रिश्तों': 2566, 'चॉकलेट': 2567, 'आइसक्रीम': 2568, 'लत': 2569, 'ग़रीबी': 2570, 'यदि': 2571, 'ढल': 2572, 'रहिए।': 2573, 'सका': 2574, 'पूछते': 2575, 'छोड़नी': 2576, 'इन्द्रधनुष': 2577, 'लेलिया।': 2578, 'बिगड़े': 2579, 'जेल': 2580, 'शांत': 2581, 'देखी': 2582, 'खिसक': 2583, 'चित': 2584, 'पट': 2585, 'कानून': 2586, 'तोड़ोगे': 2587, 'मिलेगी।': 2588, 'सुशील': 2589, 'थूकेगा': 2590, 'पौधे': 2591, 'चुनाव': 2592, 'विरोधी': 2593, 'हरा': 2594, 'उम्मीदों': 2595, 'क़ैदियों': 2596, 'आदेश': 2597, 'तोह्फ़ा': 2598, 'पुकारते': 2599, 'सुना।': 2600, 'अच्छेपन': 2601, 'ख़रीदने': 2602, 'अजनबियों': 2603, 'ढूँढना': 2604, 'जागे': 2605, 'बेकरी': 2606, 'क्यूट': 2607, 'शुक्रवार': 2608, 'पोती': 2609, 'मुस्कुराई।': 2610, 'परिस्थिति': 2611, 'कठोर': 2612, 'कदम': 2613, 'हटा': 2614, 'ड्राईव': 2615, 'लेजाओगे': 2616, 'अंधेर': 2617, 'महाद्वीप': 2618, 'भेज': 2619, 'बहादुर': 2620, 'काटते': 2621, 'ताज़ा': 2622, 'जाएगी': 2623, 'तभी': 2624, 'इलेक्ट्रिकल': 2625, 'इंजीनियर': 2626, 'खानी': 2627, 'चाहिएँ।': 2628, 'भुला': 2629, 'यहीं': 2630, 'करूंगी।': 2631, 'लूँ': 2632, 'लूँ।': 2633, 'लगातार': 2634, 'आएँ।': 2635, 'प्रसिद्ध': 2636, 'सड़े': 2637, 'बिल्लियाँ': 2638, 'कुत्ते।': 2639, 'क़ुतुब': 2640, 'मीनार': 2641, 'किला': 2642, 'तोदाइजी': 2643, 'बरबाद': 2644, 'ऐनक': 2645, 'होक्काईदो': 2646, 'घायल': 2647, 'कंबल': 2648, 'ढक': 2649, 'उद्देश्य': 2650, 'परिस्तिथि': 2651, 'बदतर': 2652, 'नीला': 2653, 'दौरान': 2654, 'एकसमान': 2655, 'आदमियों': 2656, 'जिसने': 2657, 'बधाईंयाँ।': 2658, 'दिक्कत': 2659, 'मर्यादा': 2660, 'संविधान': 2661, 'सुधारना': 2662, 'ताला': 2663, 'सके।': 2664, 'आँसुओं': 2665, 'बीजों': 2666, 'लेजाती': 2667, 'बादल': 2668, 'प्लैन': 2669, 'मामले': 2670, 'छानबीन': 2671, 'बिताई।': 2672, 'फ़ोटोकॉपियर': 2673, 'कागज़': 2674, 'किये': 2675, 'धरे': 2676, 'ठहराया': 2677, 'रबड़': 2678, 'उछलती': 2679, 'लचीली': 2680, 'हिस्से': 2681, 'नागरिक': 2682, 'कलाकार': 2683, 'लिखेगा': 2684, 'भेजी': 2685, 'रोज़ाना': 2686, 'मंजन': 2687, 'होएगी।': 2688, 'रहोगे': 2689, 'समझाना': 2690, 'पहुँचें': 2691, 'चिल्ला': 2692, 'उठी।': 2693, 'अखबारों': 2694, 'ढेर': 2695, 'सिनेमा': 2696, 'हॉल': 2697, 'आधी': 2698, 'खुल': 2699, 'सुधारने': 2700, 'मोर': 2701, 'पूंछ': 2702, 'बिरंगी': 2703, 'पकड़कर': 2704, 'पकड़ने': 2705, 'गाली': 2706, 'जागना': 2707, 'विलोम': 2708, 'सीटें': 2709, 'मिलेंगीं।': 2710, 'डालोगे': 2711, 'भुजाना': 2712, 'खिड़कियाँ': 2713, 'सूझी': 2714, 'कॉपीराईट': 2715, 'सोत्रों': 2716, 'जोड़ें।': 2717, 'संतुलन': 2718, 'सोचना': 2719, 'जातें': 2720, 'शाम': 2721, 'छपेगी।': 2722, 'मुझा': 2723, 'पहुँचते': 2724, 'करूँगी।': 2725, 'दबाकर': 2726, 'पहुँचाने': 2727, 'एवरेस्ट': 2728, 'शिखर': 2729, 'नें': 2730, 'रखे': 2731, 'कपों': 2732, 'डाली।': 2733, 'वॉशिंग': 2734, 'खराबी': 2735, 'क्लासरूम': 2736, 'घुसते': 2737, 'उतारा': 2738, 'एयरपोर्ट': 2739, 'फ़ैक्टरी': 2740, 'दहशत': 2741, 'फैला': 2742, 'पुलीसवाले': 2743, 'हज़ार': 2744, 'जुर्माना': 2745, 'रेस': 2746, 'जीतेगा': 2747, 'ईनाम': 2748, 'उसी': 2749, 'मगर': 2750, 'झगड़ा': 2751, 'लड़ाई': 2752, 'क': 2753, 'ख': 2754, 'ग': 2755, 'ध': 2756, 'सिखाए': 2757, 'आश्चर्यचकित': 2758, 'टाँगा': 2759, 'जाऊँ।': 2760, 'कंपनियां': 2761, 'उत्पादों': 2762, 'विज्ञापन': 2763, 'प्रेरणा': 2764, 'स्रोत': 2765, 'हिचकिचाएँ।': 2766, 'बताईये।': 2767, 'दवा': 2768, 'तस्कर': 2769, 'अड्डे': 2770, 'गिरफ्तार': 2771, 'दूसरी': 2772, 'तरफ': 2773, 'वालो': 2774, 'जाओगी।': 2775, 'लौटाना': 2776, 'सदस्य': 2777, 'आत्महत्या': 2778, 'लेगा।': 2779, 'कमर': 2780, 'ब्रिटेन': 2781, '१९४७': 2782, 'प्राप्त': 2783, 'डाँटा।': 2784, 'दिए': 2785, 'समझना': 2786, 'नगरों': 2787, 'स्थित': 2788, 'सोचने': 2789, 'अंगूर': 2790, 'खट्टे': 2791, 'खाए': 2792, 'कयोंकि': 2793, 'निकाल': 2794, 'बैक': 2795, 'ग्राहक': 2796, 'करदी।': 2797, 'प्रॉडक्ट्स': 2798, 'दिखाना': 2799, 'मिली': 2800, 'ताईवान': 2801, 'रिपोर्ट': 2802, 'सौंप': 2803, 'प्रेसीडेंट': 2804, 'चुना': 2805, 'खुलकर': 2806, 'बोलूँ': 2807, 'चाहता।': 2808, 'पार्सल': 2809, 'अनुवाद': 2810, 'तैवान': 2811, 'दोस्ती': 2812, 'अड़ियल': 2813, 'वाक्यांशों': 2814, 'रटना': 2815, 'फ़्रांसीसी': 2816, 'बोलनी': 2817, 'जिसका': 2818, 'अस्तित्व': 2819, 'तुरन्त': 2820, 'अनिवार्य': 2821, 'सुधार': 2822, 'पक्ष': 2823, 'छटी': 2824, 'मंज़िल': 2825, 'थें।': 2826, 'लोकप्रिय': 2827, 'स्वेटर': 2828, 'देंगे': 2829, 'लिखकर': 2830, 'देना।': 2831, 'मलेरिया': 2832, 'बाताऊँगा।': 2833, 'बाताऊँगी।': 2834, 'यात्रा': 2835, 'कड़वी': 2836, 'डाललो।': 2837, 'थेम्स': 2838, 'ज़रूरतमंदों': 2839, 'बाँट': 2840, 'लौटाने': 2841, 'बाज़ी': 2842, 'करेंगे': 2843, 'कसम': 2844, 'खालूँ।': 2845, 'जाएं': 2846, 'अनुमति': 2847, 'उत्तीर्ण': 2848, 'दोपहरभर': 2849, 'मारी।': 2850, 'सातवाँ': 2851, 'अभिलाषाओं': 2852, 'बढ़ावा': 2853, 'भूलती': 2854, 'ध्यानपूर्वक': 2855, 'सिद्धांत': 2856, 'पाई।': 2857, 'आपातकालीन': 2858, 'स्तिथि': 2859, 'मिलाना': 2860, 'प्रदूषित': 2861, 'वातावरण': 2862, 'सिवाय': 2863, 'चलाकर': 2864, 'इन्तज़ार': 2865, 'करवाया': 2866, 'अंतर्राष्ट्रीय': 2867, 'मज़बूत': 2868, 'अर्थव्यवस्था': 2869, 'आवश्यक': 2870, 'बैट': 2871, 'बॉल': 2872, 'एकसाथ': 2873, 'गर्व': 2874, 'जिसमें': 2875, 'अबसे': 2876, 'पहुँचे': 2877, 'लूँगा।': 2878, 'ग़ौर': 2879, 'दिखाऊँगा': 2880, 'भावनाओं': 2881, 'बाग': 2882, 'पुराना': 2883, 'ढूँढता': 2884, 'गिरा': 2885, 'बनवानी': 2886, 'भिजवादूँगा।': 2887, 'हेलमेट': 2888, 'मोटरसाईकल': 2889, 'बहतर': 2890, 'गंदे': 2891, 'उद्योग': 2892, 'अधिकांश': 2893, 'सदस्यों': 2894, 'बिल': 2895, 'पारित': 2896, 'एड्स': 2897, 'फैलाव': 2898, 'भयानक': 2899, 'फ्रेंच': 2900, 'फ्रांस': 2901, 'अौर': 2902, 'हिस्सो': 2903, 'पकड़नी': 2904, 'फंस': 2905, 'भीग': 2906, 'बीवा': 2907, 'बतादूँगा।': 2908, 'बहार': 2909, 'विशाल': 2910, 'हुक़्म': 2911, 'मरीज़': 2912, 'बिस्टर': 2913, 'लेटा': 2914, 'क़ातिल': 2915, 'हरासत': 2916, 'तुममें': 2917, 'सब्र': 2918, 'जाते।': 2919, 'बांध': 2920, 'ले।': 2921, 'स्थापित': 2922, 'समाचार': 2923, 'पाने': 2924, 'खोना': 2925, 'तस्वीरों': 2926, 'गोलियों': 2927, 'निगल': 2928, 'ताज': 2929, 'महल': 2930, 'आश्चर्यों': 2931, 'पकड़ीं': 2932, 'गईं।': 2933, 'इनवेस्टमेंट': 2934, '८': 2935, 'प्रतिशत': 2936, 'चढ़ने': 2937, 'प्रदूषण': 2938, 'प्रयास': 2939, 'कोलम्बस': 2940, 'पश्चिम': 2941, 'दिशा': 2942, 'जगे': 2943, 'पीनी': 2944, '१६००': 2945, 'लाया': 2946, 'डिक्शनरी': 2947, 'चलेगा।': 2948, 'मुम्बई': 2949, 'भारतीय': 2950, 'महाराष्ट्र': 2951, 'सुरक्षा': 2952, 'गिनती': 2953, 'नाकामयाब': 2954, 'ज़िंदगी': 2955, 'बीमारों': 2956, 'समर्पित': 2957, 'पहनूँ।': 2958, 'ग़रीब': 2959, 'ताकतशाली': 2960, 'अर्थतंत्रों': 2961, 'पंद्रह': 2962, 'उड़ातें': 2963, 'मोबाइल': 2964, 'वस्तु': 2965, 'सूर्य': 2966, 'प्रभाव': 2967, 'असर': 2968, 'जानबूझकर': 2969, 'पहचाना': 2970, 'सावधान': 2971, 'रहेगा।': 2972, 'अधिकारियों': 2973, 'जनता': 2974, 'जलने': 2975, 'सुँघाई': 2976, 'नकली': 2977, 'हीरों': 2978, 'लिपटी': 2979, 'कोने': 2980, 'खाकर': 2981, 'टाईम': 2982, 'बड़ाई': 2983, 'मांग': 2984, 'कॉपियाँ': 2985, 'दीं': 2986, 'बकरियों': 2987, 'वेतन': 2988, 'मछवारे': 2989, 'पकड़ी': 2990, 'आकार': 2991, 'बढ़ा': 2992, 'चढ़ाकर': 2993, 'भ्रष्टाचार': 2994, 'मुक्त': 2995, 'ऊँगलियाँ': 2996, 'पाते।': 2997, 'चरित्र': 2998, 'पाऊँगा।': 2999, 'अगला': 3000, 'कम्पनियाँ': 3001, 'कटवाना': 3002, 'घूरने': 3003, 'बजाए': 3004, 'पढ़लो।': 3005, 'तम्हें': 3006, 'मुट्ठीभर': 3007, 'मूँगफलियाँ': 3008, 'लीं': 3009, 'दिवालिया': 3010, 'निकलने': 3011, 'दीजिएगा।': 3012, 'करेगा': 3013, 'पायेंगे।': 3014, 'ग़लतियों': 3015, 'डरना': 3016, 'उपलब्ध': 3017, 'सेवाओं': 3018, 'सोनी': 3019, 'टुकड़ो': 3020, 'टुकड़ा': 3021, 'जुलतीं': 3022, 'निकालने': 3023, 'इनके': 3024, 'करदें': 3025, 'अभ': 3026, 'चोरों': 3027, 'दराज़ें': 3028, 'डालीं।': 3029, 'अठारह': 3030, 'चलानी': 3031, 'लाईसेंस': 3032, 'बनवालिया।': 3033, 'कैथोलिक': 3034, 'नन': 3035, 'थीं': 3036, 'करतीं': 3037, 'जार्ज': 3038, 'वाशिंगटन': 3039, 'संयुक्त': 3040, 'राष्ट्रपति': 3041, 'नज़रिए': 3042, 'सर्व': 3043, 'श्रेष्ठ': 3044, '१९५१': 3045, 'सिस्टर': 3046, 'इनाम': 3047, 'विदोश': 3048, 'सूपरमार्केट': 3049, 'रोजाने': 3050, 'जिन': 3051, 'यात्रियों': 3052, 'लोकतंत्र': 3053, 'घिनौना': 3054, 'सरकारों': 3055, 'अंदेखा': 3056, 'ट्रेफ़िक': 3057, 'हादसे': 3058, 'कीड़ों': 3059, 'परेशानी': 3060}\n",
            "target word to index mapping: {'<start>': 1, '<end>': 2, '.': 3, 'the': 4, 'i': 5, 'to': 6, 'you': 7, '?': 8, 'a': 9, 'is': 10, 'he': 11, 'of': 12, 't': 13, 'in': 14, 'it': 15, 'my': 16, 'me': 17, 'have': 18, 'this': 19, 'she': 20, 'do': 21, 'that': 22, 'was': 23, ',': 24, 's': 25, 'for': 26, 'are': 27, 'what': 28, 'we': 29, 'his': 30, 'your': 31, 'don': 32, 'can': 33, 'will': 34, 'on': 35, 'at': 36, 'him': 37, 'not': 38, 'her': 39, 'go': 40, 'like': 41, 'tom': 42, 'with': 43, 'be': 44, 'm': 45, 'how': 46, 'and': 47, 'know': 48, 'has': 49, 'there': 50, 'all': 51, 'up': 52, 'they': 53, 'very': 54, 'time': 55, 'come': 56, 'as': 57, 'had': 58, 'want': 59, 'from': 60, 'please': 61, 'did': 62, 'here': 63, '!': 64, 'by': 65, 'out': 66, 'when': 67, 'get': 68, 'll': 69, 'am': 70, 'an': 71, 'going': 72, 'no': 73, 'father': 74, 'been': 75, 'one': 76, 'book': 77, 'take': 78, 'about': 79, 'if': 80, 'where': 81, 'would': 82, 'day': 83, 'were': 84, 'money': 85, 'india': 86, 'but': 87, 'us': 88, 'let': 89, 'now': 90, 'make': 91, 'today': 92, 'long': 93, 'two': 94, 'didn': 95, 'help': 96, 'who': 97, 'good': 98, 'live': 99, 'see': 100, 'tomorrow': 101, 'must': 102, 'back': 103, 'man': 104, 'our': 105, 'home': 106, 'car': 107, 're': 108, 'should': 109, 'so': 110, 'work': 111, 'these': 112, 'english': 113, 'yesterday': 114, 'never': 115, 'room': 116, 'think': 117, 've': 118, 'house': 119, 'many': 120, 'too': 121, 'every': 122, 'made': 123, 'last': 124, 'much': 125, 'may': 126, 'went': 127, 'old': 128, 'nothing': 129, 'mother': 130, 'than': 131, 'off': 132, 'again': 133, 'dog': 134, 'give': 135, 'could': 136, 'any': 137, 'more': 138, 'people': 139, 'door': 140, 'some': 141, 'tell': 142, 'mary': 143, 'speak': 144, 'always': 145, 'got': 146, 'well': 147, 'down': 148, 'them': 149, 'children': 150, 'turn': 151, 'night': 152, 'train': 153, 'say': 154, 'why': 155, 'leave': 156, 'call': 157, 'lot': 158, 'put': 159, 'school': 160, 'before': 161, 'happy': 162, 'doctor': 163, 'isn': 164, 'teacher': 165, 'into': 166, 'or': 167, 'new': 168, 'read': 169, 'job': 170, 'water': 171, 'way': 172, 'their': 173, 'away': 174, 'tired': 175, 'left': 176, 'everyone': 177, 'open': 178, 'problem': 179, 'right': 180, 'believe': 181, 'true': 182, 'use': 183, 'next': 184, 'soon': 185, 'ten': 186, 'keep': 187, 'because': 188, 'world': 189, 'answer': 190, 'once': 191, 'drive': 192, 'year': 193, 'hard': 194, 'saw': 195, 'really': 196, 'd': 197, 'few': 198, 'three': 199, 'times': 200, 'seen': 201, 'letter': 202, 'won': 203, 'both': 204, 'wrong': 205, 'big': 206, 'birthday': 207, 'feel': 208, 'watch': 209, 'cut': 210, 'met': 211, 'does': 212, 'books': 213, 'doing': 214, 'little': 215, 'tea': 216, 'couldn': 217, 'afraid': 218, 'without': 219, 'looking': 220, 'said': 221, 'morning': 222, 'lost': 223, 'came': 224, 'understand': 225, 'yet': 226, 'play': 227, 'need': 228, 'girl': 229, 'while': 230, 'years': 231, 'other': 232, 'such': 233, 'japan': 234, 'something': 235, 'love': 236, 'try': 237, 'bed': 238, 'around': 239, 'likes': 240, 'after': 241, 'told': 242, 'talking': 243, 'friends': 244, 'bought': 245, 'tried': 246, 'wanted': 247, 'mind': 248, 'gave': 249, 'asked': 250, 'clock': 251, 'doesn': 252, 'used': 253, 'six': 254, 'able': 255, 'cannot': 256, 'month': 257, 'took': 258, 'alone': 259, 'coming': 260, 'buy': 261, 'stay': 262, 'study': 263, 'early': 264, 'running': 265, 'first': 266, 'meet': 267, 'bad': 268, 'already': 269, 'news': 270, 'ask': 271, 'sister': 272, 'caught': 273, 'just': 274, 'easy': 275, 'looked': 276, 'shoes': 277, 'river': 278, 'comes': 279, 'o': 280, 'own': 281, 'better': 282, 'ever': 283, 'between': 284, 'medicine': 285, 'usually': 286, 'brother': 287, 'smoking': 288, 'days': 289, 'fun': 290, 'broke': 291, 'cold': 292, 'knows': 293, 'boy': 294, 'drink': 295, 'fish': 296, 'dinner': 297, 'person': 298, 'friend': 299, 'eyes': 300, 'abroad': 301, 'married': 302, 'small': 303, 'felt': 304, 'city': 305, 'box': 306, 'health': 307, 'week': 308, 'walk': 309, 'happened': 310, 'station': 311, 'hair': 312, 'coffee': 313, 'difficult': 314, 'enough': 315, 'tv': 316, 'accident': 317, 'wants': 318, 'sit': 319, 'nobody': 320, 'things': 321, 'busy': 322, 'town': 323, 'stop': 324, 'mine': 325, 'name': 326, 'questions': 327, 'reading': 328, 'life': 329, 'poor': 330, 'died': 331, 'another': 332, 'ran': 333, 'party': 334, 'five': 335, 'found': 336, 'almost': 337, 'question': 338, 'mistakes': 339, 'wait': 340, 'die': 341, 'baby': 342, 'food': 343, 'eight': 344, 'afternoon': 345, 'london': 346, 'watching': 347, 'idea': 348, 'hours': 349, 'parents': 350, 'possible': 351, 'saying': 352, 'forgot': 353, 'fly': 354, 'done': 355, 'fire': 356, 'swim': 357, 'flowers': 358, 'hot': 359, 'music': 360, 'look': 361, 'ill': 362, 'heard': 363, 'noise': 364, 'power': 365, 'nice': 366, 'hurry': 367, 'story': 368, 'talk': 369, 'sure': 370, 'later': 371, 'kept': 372, 'write': 373, 'language': 374, 'hand': 375, 'became': 376, 'each': 377, 'bus': 378, 'anyone': 379, 'king': 380, 'beautiful': 381, 'someone': 382, 'large': 383, 'police': 384, 'america': 385, 'others': 386, 'desk': 387, 'sorry': 388, 'bicycle': 389, 'eat': 390, 'care': 391, 'rain': 392, 'slowly': 393, 'instead': 394, 'written': 395, 'weather': 396, 'kind': 397, 'behind': 398, 'since': 399, 'difference': 400, 'birds': 401, 'excuse': 402, 'move': 403, 'sick': 404, 'bring': 405, 'free': 406, 'son': 407, 'clean': 408, 'phone': 409, 'only': 410, 'ready': 411, 'boys': 412, 'anything': 413, 'getting': 414, 'along': 415, 'sleep': 416, 'works': 417, 'address': 418, 'born': 419, 'yours': 420, 'family': 421, 'which': 422, 'everybody': 423, 'called': 424, 'lives': 425, 'rich': 426, 'yourself': 427, 'waiting': 428, 'fever': 429, 'rumor': 430, 'size': 431, 'visit': 432, 'wherever': 433, 'thing': 434, 'often': 435, 'forget': 436, 'country': 437, 'playing': 438, 'wish': 439, 'outside': 440, 'makes': 441, 'tennis': 442, 'shouldn': 443, 'homework': 444, 'wife': 445, 'minutes': 446, 'learn': 447, 'window': 448, 'standing': 449, 'picture': 450, 'class': 451, 'best': 452, 'interesting': 453, 'raining': 454, 'french': 455, 'spoken': 456, 'clothes': 457, 'telephone': 458, 'capital': 459, 'wouldn': 460, 'find': 461, 'hear': 462, 'village': 463, 'child': 464, 'longer': 465, 'through': 466, 'whether': 467, 'pay': 468, 'hungry': 469, 'smiled': 470, 'dogs': 471, 'summer': 472, 'bag': 473, 'wash': 474, 'run': 475, 'guitar': 476, 'black': 477, 'crying': 478, 'talks': 479, 'began': 480, 'cried': 481, 'haven': 482, 'hands': 483, 'blue': 484, 'against': 485, 'war': 486, 'matter': 487, 'closed': 488, 'those': 489, 'still': 490, 'television': 491, 'looks': 492, 'seems': 493, 'taking': 494, 'baseball': 495, 'working': 496, 'plan': 497, 'eating': 498, 'apple': 499, 'sunday': 500, 'quickly': 501, 'dress': 502, 'disappointed': 503, 'eggs': 504, 'reap': 505, 'sow': 506, 'lose': 507, 'quit': 508, 'business': 509, 'begins': 510, 'anymore': 511, 'easily': 512, 'decided': 513, 'sky': 514, 'fell': 515, 'studying': 516, 'late': 517, 'sugar': 518, 'rains': 519, 'then': 520, 'air': 521, 'apples': 522, 'larger': 523, 'might': 524, 'interested': 525, 'thank': 526, 'changing': 527, 'suddenly': 528, 'europe': 529, 'cup': 530, 'number': 531, 'office': 532, 'set': 533, 'grandmother': 534, 'hobby': 535, 'population': 536, 'ship': 537, 'across': 538, 'surprised': 539, 'anxious': 540, 'men': 541, 'plane': 542, 'china': 543, 'finish': 544, 'making': 545, 'heat': 546, 'whoever': 547, 'strange': 548, 'being': 549, 'mountain': 550, 'hospital': 551, 'advice': 552, 'finished': 553, 'bit': 554, 'machine': 555, 'known': 556, 'necessary': 557, 'different': 558, 'arrested': 559, 'england': 560, 'jump': 561, 'laughed': 562, 'sing': 563, 'stood': 564, 'strong': 565, 'cake': 566, 'attend': 567, 'fat': 568, 'history': 569, 'god': 570, 'over': 571, 'cooked': 572, 'beauty': 573, 'age': 574, 'remember': 575, 'april': 576, 'key': 577, 'whose': 578, 'bank': 579, 'sight': 580, 'truth': 581, 'earth': 582, 'hope': 583, 'mistake': 584, 'worked': 585, 'dark': 586, 'snow': 587, 'started': 588, 'expensive': 589, 'thief': 590, 'taxi': 591, 'shirt': 592, 'clear': 593, 'airport': 594, 'angry': 595, 'agree': 596, 'red': 597, 'broken': 598, 'return': 599, 'secret': 600, 'policeman': 601, 'swimming': 602, 'close': 603, 'lake': 604, 'game': 605, 'knew': 606, 'learned': 607, 'japanese': 608, 'empty': 609, 'woman': 610, 'prefer': 611, 'myself': 612, 'nine': 613, 'rather': 614, 'light': 615, 'memory': 616, 'milk': 617, 'abandoned': 618, 'tends': 619, 'present': 620, 'chair': 621, 'show': 622, 'hasn': 623, 'face': 624, 'four': 625, 'table': 626, 'garden': 627, 'stand': 628, 'explain': 629, 'bath': 630, 'harder': 631, 'least': 632, 'death': 633, 'cars': 634, 'rest': 635, 'dollars': 636, 'shade': 637, 'cats': 638, 'movie': 639, 'aren': 640, 'believes': 641, 'arrived': 642, 'dead': 643, 'hardly': 644, 'brought': 645, 'famous': 646, 'great': 647, 'head': 648, 'promise': 649, 'canada': 650, 'france': 651, 'dream': 652, 'speaking': 653, 'meeting': 654, 'africa': 655, 'become': 656, 'result': 657, 'happen': 658, 'most': 659, 'australia': 660, 'future': 661, 'students': 662, 'sisters': 663, 'college': 664, 'bigger': 665, 'having': 666, 'paris': 667, 'trouble': 668, 'pictures': 669, 'older': 670, 'leaving': 671, 'stayed': 672, 'languages': 673, 'doubt': 674, 'covered': 675, 'ordered': 676, 'whole': 677, 'together': 678, 'street': 679, 'uncle': 680, 'amateur': 681, 'cricket': 682, 'player': 683, 'bridge': 684, 'supposed': 685, 'cost': 686, 'government': 687, 'pass': 688, 'responsible': 689, 'bored': 690, 'wonderful': 691, 'follow': 692, 'shout': 693, 'promised': 694, 'cat': 695, 'map': 696, 'feet': 697, 'waited': 698, 'hat': 699, 'husband': 700, 'cook': 701, 'anybody': 702, 'kites': 703, 'fault': 704, 'carefully': 705, 'teach': 706, 'join': 707, 'rice': 708, 'legs': 709, 'speaks': 710, 'near': 711, 'thirsty': 712, 'bird': 713, 'walking': 714, 'turned': 715, 'listen': 716, 'student': 717, 'stolen': 718, 'radio': 719, 'yes': 720, 'simple': 721, 'admit': 722, 'women': 723, 'sort': 724, 'tall': 725, 'suitcase': 726, 'crow': 727, 'entered': 728, 'continued': 729, 'win': 730, 'wine': 731, 'pulled': 732, 'trees': 733, 'tax': 734, 'jog': 735, 'worry': 736, 'success': 737, 'succeed': 738, 'expect': 739, 'meant': 740, 'joke': 741, 'glasses': 742, 'eleven': 743, 'shut': 744, 'goes': 745, 'accepted': 746, 'offer': 747, 'horse': 748, 'daughter': 749, 'correct': 750, 'ahead': 751, 'eye': 752, 'ball': 753, 'lived': 754, 'animal': 755, 'fast': 756, 'foot': 757, 'wake': 758, 'thinking': 759, 'absent': 760, 'shall': 761, 'piano': 762, 'heart': 763, 'showed': 764, 'oil': 765, 'smooth': 766, 'arrive': 767, 'plenty': 768, 'bother': 769, 'glass': 770, 'park': 771, 'arrogant': 772, 'accused': 773, 'sent': 774, 'important': 775, 'brothers': 776, 'under': 777, 'thirty': 778, 'cancer': 779, 'novel': 780, 'half': 781, 'forest': 782, 'team': 783, 'rooms': 784, 'road': 785, 'tokyo': 786, 'satisfied': 787, 'neighbors': 788, 'plays': 789, 'burning': 790, 'sleeping': 791, 'account': 792, 'sold': 793, 'travel': 794, 'towel': 795, 'add': 796, 'herself': 797, 'reason': 798, 'cry': 799, 'twenty': 800, 'protect': 801, 'favorite': 802, 'smoke': 803, 'officer': 804, 'whatever': 805, 'opinions': 806, 'miles': 807, 'following': 808, 'items': 809, 'place': 810, 'feed': 811, 'word': 812, 'order': 813, 'bread': 814, 'somewhere': 815, 'explained': 816, 'rule': 817, 'osaka': 818, 'waste': 819, 'voice': 820, 'allowed': 821, 'saved': 822, 'danger': 823, 'store': 824, 'brush': 825, 'teeth': 826, 'meals': 827, 'words': 828, 'tickets': 829, 'speech': 830, 'advise': 831, 'pleased': 832, 'allow': 833, 'pain': 834, 'italy': 835, 'tree': 836, 'worse': 837, 'fact': 838, 'butter': 839, 'advantage': 840, 'monday': 841, 'movies': 842, 'trip': 843, 'traffic': 844, 'mail': 845, 'pieces': 846, 'favor': 847, 'flying': 848, 'kite': 849, 'dangerous': 850, 'due': 851, 'illness': 852, 'interpret': 853, 'poem': 854, 'pick': 855, 'borrow': 856, 'subject': 857, 'lie': 858, 'helped': 859, 'tonight': 860, 'sun': 861, 'wedding': 862, 'fresh': 863, 'promote': 864, 'buried': 865, 'lying': 866, 'until': 867, 'dictionary': 868, 'trust': 869, 'rules': 870, 'killed': 871, 'ashamed': 872, 'wrote': 873, 'temples': 874, 'fifty': 875, 'end': 876, 'extent': 877, 'wind': 878, 'leaves': 879, 'computer': 880, 'short': 881, 'prize': 882, 'message': 883, 'point': 884, 'delhi': 885, 'speed': 886, 'breakfast': 887, 'case': 888, 'living': 889, 'depends': 890, 'teaching': 891, 'destroyed': 892, 'catch': 893, 'according': 894, 'front': 895, 'company': 896, 'advised': 897, 'far': 898, 'its': 899, 'passed': 900, 'weeks': 901, 'lights': 902, 'workers': 903, 'museum': 904, 'library': 905, 'answers': 906, 'test': 907, 'ought': 908, 'till': 909, 'couple': 910, 'except': 911, 'largest': 912, 'feeling': 913, 'spent': 914, 'teresa': 915, 'hello': 916, 'cheers': 917, 'ok': 918, 'perfect': 919, 'welcome': 920, 'fine': 921, 'math': 922, 'shot': 923, 'touch': 924, 'atheist': 925, 'congratulations': 926, 'miss': 927, 'reads': 928, 'arabic': 929, 'rude': 930, 'lucky': 931, 'cafe': 932, 'fair': 933, 'lack': 934, 'choose': 935, 'top': 936, 'oranges': 937, 'sign': 938, 'betrayed': 939, 'build': 940, 'nests': 941, 'headache': 942, 'loved': 943, 'happiness': 944, 'throw': 945, 'breathed': 946, 'deeply': 947, 'cousin': 948, 'toes': 949, 'pretty': 950, 'guy': 951, 'enjoyed': 952, 'kids': 953, 'vase': 954, 'pen': 955, 'gym': 956, 'state': 957, 'taste': 958, 'eaten': 959, 'ticket': 960, 'green': 961, 'forgive': 962, 'pencil': 963, 'sea': 964, 'lunch': 965, 'noon': 966, 'consciousness': 967, 'decision': 968, 'wore': 969, 'haunted': 970, 'sheets': 971, 'burst': 972, 'feels': 973, 'silk': 974, 'beer': 975, 'hens': 976, 'bell': 977, 'climbed': 978, 'stairs': 979, 'sharp': 980, 'race': 981, 'boston': 982, 'start': 983, 'swollen': 984, 'hated': 985, 'stubborn': 986, 'nearby': 987, 'missed': 988, 'shouted': 989, 'exciting': 990, 'elevator': 991, 'song': 992, 'earns': 993, 'knocked': 994, 'robbed': 995, 'physics': 996, 'wonder': 997, 'stomach': 998, 'york': 999, 'wears': 1000, 'glad': 1001, 'lion': 1002, 'chairs': 1003, 'passport': 1004, 'soccer': 1005, 'complaining': 1006, 'dozen': 1007, 'dressed': 1008, 'white': 1009, 'whichever': 1010, 'applies': 1011, 'wood': 1012, 'cheese': 1013, 'fond': 1014, 'gun': 1015, 'murder': 1016, 'seat': 1017, 'further': 1018, 'cups': 1019, 'iron': 1020, 'gold': 1021, 'healthy': 1022, 'successful': 1023, 'gathered': 1024, 'amount': 1025, 'trusted': 1026, 'import': 1027, 'part': 1028, 'fairies': 1029, 'moment': 1030, 'taught': 1031, 'walked': 1032, 'witnessed': 1033, 'steal': 1034, 'lately': 1035, 'manager': 1036, 'stopped': 1037, 'hates': 1038, 'bags': 1039, 'missing': 1040, 'plants': 1041, 'prisoner': 1042, 'independence': 1043, 'pond': 1044, 'coal': 1045, 'personally': 1046, 'koala': 1047, 'visited': 1048, 'kyoto': 1049, 'says': 1050, 'pencils': 1051, 'cover': 1052, 'sat': 1053, 'mouse': 1054, 'alive': 1055, 'same': 1056, 'hit': 1057, 'mud': 1058, 'season': 1059, 'celebrated': 1060, 'chose': 1061, 'pride': 1062, 'western': 1063, 'german': 1064, 'treats': 1065, 'august': 1066, 'accompanied': 1067, 'useful': 1068, 'spanish': 1069, 'mexico': 1070, 'yen': 1071, 'loves': 1072, 'answered': 1073, 'else': 1074, 'low': 1075, 'hundred': 1076, 'real': 1077, 'diamond': 1078, 'wall': 1079, 'roses': 1080, 'degree': 1081, 'followed': 1082, 'deer': 1083, 'tracks': 1084, 'science': 1085, 'farm': 1086, 'young': 1087, 'grown': 1088, 'rome': 1089, 'monkey': 1090, 'increasing': 1091, 'send': 1092, 'taken': 1093, 'rotten': 1094, 'spread': 1095, 'youth': 1096, 'jam': 1097, 'jobs': 1098, 'thought': 1099, 'patient': 1100, 'bound': 1101, 'contains': 1102, 'undone': 1103, 'absence': 1104, 'meal': 1105, 'distance': 1106, 'roof': 1107, 'dust': 1108, 'itself': 1109, 'crash': 1110, 'shop': 1111, 'someday': 1112, 'juice': 1113, 'supper': 1114, 'listened': 1115, 'struck': 1116, 'even': 1117, 'everything': 1118, 'vegetables': 1119, 'graveyard': 1120, 'supermarket': 1121, 'rainy': 1122, 'vain': 1123, 'sinking': 1124, 'high': 1125, 'cross': 1126, 'newspapers': 1127, 'dance': 1128, 'count': 1129, 'stingy': 1130, 'paper': 1131, 'single': 1132, 'lazy': 1133, 'boss': 1134, 'consists': 1135, 'past': 1136, 'reproached': 1137, 'starts': 1138, 'rang': 1139, 'scolded': 1140, 'worst': 1141, 'rid': 1142, 'habit': 1143, 'gets': 1144, 'nerves': 1145, 'hid': 1146, 'among': 1147, 'realized': 1148, 'program': 1149, 'smile': 1150, 'arrogance': 1151, 'fortune': 1152, 'proved': 1153, 'laid': 1154, 'prevented': 1155, 'murders': 1156, 'willing': 1157, 'observe': 1158, 'limit': 1159, 'market': 1160, 'tolerate': 1161, 'statement': 1162, 'art': 1163, 'friday': 1164, 'learning': 1165, 'foreign': 1166, 'nowadays': 1167, 'overseas': 1168, 'insecure': 1169, 'animals': 1170, 'asleep': 1171, 'pocket': 1172, 'jungle': 1173, 'storm': 1174, 'proud': 1175, 'themselves': 1176, 'chance': 1177, 'sudden': 1178, 'toilet': 1179, 'pet': 1180, 'spend': 1181, 'dreamed': 1182, 'twice': 1183, 'vary': 1184, 'stars': 1185, 'law': 1186, 'scattered': 1187, 'talked': 1188, 'less': 1189, 'answering': 1190, 'corner': 1191, 'sentences': 1192, 'opportunity': 1193, 'current': 1194, 'income': 1195, 'fit': 1196, 'wearing': 1197, 'inside': 1198, 'occurred': 1199, 'regret': 1200, 'imitate': 1201, 'education': 1202, 'ride': 1203, 'staying': 1204, 'months': 1205, 'fall': 1206, 'received': 1207, 'sometimes': 1208, 'hesitation': 1209, 'convinced': 1210, 'doll': 1211, 'gentleman': 1212, 'absolute': 1213, 'shows': 1214, 'common': 1215, 'environment': 1216, 'club': 1217, 'examination': 1218, 'reduce': 1219, 'invited': 1220, 'confident': 1221, 'writing': 1222, 'letters': 1223, 'recognize': 1224, 'video': 1225, 'caused': 1226, 'earthquake': 1227, 'failed': 1228, 'jumped': 1229, 'locked': 1230, 'countries': 1231, 'conditioner': 1232, 'situation': 1233, 'himself': 1234, 'precious': 1235, 'injured': 1236, 'during': 1237, 'stole': 1238, 'disappointment': 1239, 'respected': 1240, 'tears': 1241, 'impossible': 1242, 'opinion': 1243, 'certain': 1244, 'noticed': 1245, 'misunderstanding': 1246, 'fight': 1247, 'companies': 1248, 'products': 1249, 'instant': 1250, 'ago': 1251, 'lots': 1252, 'gained': 1253, 'thousands': 1254, 'taiwan': 1255, 'strike': 1256, 'president': 1257, 'quality': 1258, 'bothered': 1259, 'seventeen': 1260, 'sad': 1261, 'strawberries': 1262, 'cities': 1263, 'gut': 1264, 'regard': 1265, 'names': 1266, 'careful': 1267, 'backs': 1268, 'selfish': 1269, 'thinks': 1270, 'feelings': 1271, 'committee': 1272, 'exam': 1273, 'investigate': 1274, 'reach': 1275, 'takes': 1276, 'safety': 1277, 'affected': 1278, 'realize': 1279, 'value': 1280, 'calcutta': 1281, 'wow': 1282, 'awesome': 1283, 'goodbye': 1284, 'full': 1285, 'fantastic': 1286, 'fainted': 1287, 'fear': 1288, 'definitely': 1289, 'burns': 1290, 'yawned': 1291, 'lied': 1292, 'easter': 1293, 'snowing': 1294, 'unbelievable': 1295, 'dies': 1296, 'bloom': 1297, 'donuts': 1298, 'quick': 1299, 'aloud': 1300, 'bent': 1301, 'holidays': 1302, 'beard': 1303, 'actor': 1304, 'needs': 1305, 'idol': 1306, 'kidding': 1307, 'guys': 1308, 'absurd': 1309, 'nauseous': 1310, 'assaulted': 1311, 'startled': 1312, 'climb': 1313, 'potatoes': 1314, 'faces': 1315, 'responded': 1316, 'shopping': 1317, 'bar': 1318, 'deceive': 1319, 'screamed': 1320, 'employs': 1321, 'maid': 1322, 'studied': 1323, 'traitor': 1324, 'sleepy': 1325, 'truly': 1326, 'starting': 1327, 'rotates': 1328, 'invite': 1329, 'beach': 1330, 'pie': 1331, 'stones': 1332, 'gone': 1333, 'nuts': 1334, 'handle': 1335, 'toyota': 1336, 'frozen': 1337, 'leaped': 1338, 'joy': 1339, 'happily': 1340, 'annoys': 1341, 'batter': 1342, 'flew': 1343, 'vanished': 1344, 'skating': 1345, 'pumpkin': 1346, 'begin': 1347, 'wheel': 1348, 'lonely': 1349, 'singing': 1350, 'hate': 1351, 'risks': 1352, 'marry': 1353, 'ink': 1354, 'tiger': 1355, 'skies': 1356, 'sweating': 1357, 'winter': 1358, 'saver': 1359, 'envied': 1360, 'lent': 1361, 'stranger': 1362, 'counting': 1363, 'vomiting': 1364, 'stomachache': 1365, 'problems': 1366, 'finger': 1367, 'allergic': 1368, 'ringing': 1369, 'charge': 1370, 'boring': 1371, 'victory': 1372, 'windy': 1373, 'lincoln': 1374, 'specialty': 1375, 'ablaze': 1376, 'damp': 1377, 'pipe': 1378, 'hers': 1379, 'zoo': 1380, 'contain': 1381, 'prove': 1382, 'camera': 1383, 'lay': 1384, 'rung': 1385, 'deals': 1386, 'furniture': 1387, 'shooter': 1388, 'sixty': 1389, 'sang': 1390, 'dear': 1391, 'grateful': 1392, 'dove': 1393, 'servant': 1394, 'liked': 1395, 'biology': 1396, 'korea': 1397, 'tiny': 1398, 'toy': 1399, 'deep': 1400, 'disturbing': 1401, 'rested': 1402, 'nonsense': 1403, 'fox': 1404, 'wild': 1405, 'color': 1406, 'temper': 1407, 'slap': 1408, 'salary': 1409, 'daughters': 1410, 'tore': 1411, 'apart': 1412, 'understands': 1413, 'pity': 1414, 'cage': 1415, 'seem': 1416, 'wasn': 1417, 'fired': 1418, 'bloody': 1419, 'growling': 1420, 'gentle': 1421, 'wealthy': 1422, 'prattles': 1423, 'weird': 1424, 'gate': 1425, 'knife': 1426, 'sooner': 1427, 'thin': 1428, 'tame': 1429, 'engine': 1430, 'temperature': 1431, 'stuttering': 1432, 'tuesday': 1433, 'spoil': 1434, 'alcohol': 1435, 'sand': 1436, 'catches': 1437, 'colds': 1438, 'smelling': 1439, 'soup': 1440, 'theft': 1441, 'throwing': 1442, 'dentist': 1443, 'drinking': 1444, 'concern': 1445, 'example': 1446, 'debts': 1447, 'flames': 1448, 'adopted': 1449, 'orphan': 1450, 'note': 1451, 'plus': 1452, 'round': 1453, 'nationality': 1454, 'pours': 1455, 'travels': 1456, 'ambulance': 1457, 'envelope': 1458, 'leveled': 1459, 'dissatisfied': 1460, 'kilo': 1461, 'beg': 1462, 'differ': 1463, 'jacket': 1464, 'subway': 1465, 'condition': 1466, 'knocking': 1467, 'coughing': 1468, 'refund': 1469, 'page': 1470, 'introduce': 1471, 'quiet': 1472, 'obstinate': 1473, 'refused': 1474, 'notice': 1475, 'pulse': 1476, 'committed': 1477, 'includes': 1478, 'narrow': 1479, 'lacks': 1480, 'courage': 1481, 'line': 1482, 'b': 1483, 'sale': 1484, 'arrest': 1485, 'hammered': 1486, 'hesitated': 1487, 'sentenced': 1488, 'quota': 1489, 'bowls': 1490, 'hunger': 1491, 'drove': 1492, 'farther': 1493, 'glimpse': 1494, 'fixed': 1495, 'facebook': 1496, 'barber': 1497, 'terribly': 1498, 'smog': 1499, 'causes': 1500, 'snakes': 1501, 'poisonous': 1502, 'enemy': 1503, 'haze': 1504, 'enveloped': 1505, 'abused': 1506, 'released': 1507, 'families': 1508, 'painted': 1509, 'appeared': 1510, 'appointment': 1511, 'fail': 1512, 'watering': 1513, 'greeks': 1514, 'engaged': 1515, 'occasionally': 1516, 'worthless': 1517, 'honesty': 1518, 'policy': 1519, 'actually': 1520, 'usual': 1521, 'decline': 1522, 'john': 1523, 'june': 1524, 'bum': 1525, 'aunt': 1526, 'arms': 1527, 'bride': 1528, 'tastes': 1529, 'bitter': 1530, 'clung': 1531, 'paint': 1532, 'dried': 1533, 'drinkable': 1534, 'monsoon': 1535, 'greek': 1536, 'captain': 1537, 'figured': 1538, 'hurt': 1539, 'soft': 1540, 'drinks': 1541, 'breathe': 1542, 'digging': 1543, 'grave': 1544, 'prefers': 1545, 'repeated': 1546, 'slave': 1547, 'st': 1548, 'cleaned': 1549, 'cycling': 1550, 'crossing': 1551, 'insert': 1552, 'metal': 1553, 'million': 1554, 'sheer': 1555, 'expenses': 1556, 'spa': 1557, 'jeans': 1558, 'shrank': 1559, 'players': 1560, 'also': 1561, 'offered': 1562, 'declined': 1563, 'invitation': 1564, 'dialed': 1565, 'purse': 1566, 'bun': 1567, 'soldiers': 1568, 'silent': 1569, 'socks': 1570, 'houses': 1571, 'burned': 1572, 'smelled': 1573, 'tobacco': 1574, 'teachers': 1575, 'ourselves': 1576, 'south': 1577, 'terminal': 1578, 'tidy': 1579, 'chinese': 1580, 'underlined': 1581, 'lean': 1582, 'football': 1583, 'changed': 1584, 'schools': 1585, 'eats': 1586, 'cafeteria': 1587, 'ear': 1588, 'shirts': 1589, 'washed': 1590, 'wishes': 1591, 'smell': 1592, 'forever': 1593, 'bottles': 1594, 'informed': 1595, 'mentioned': 1596, 'dozens': 1597, 'catching': 1598, 'appears': 1599, 'honest': 1600, 'fate': 1601, 'arguing': 1602, 'collecting': 1603, 'coins': 1604, 'notebook': 1605, 'beating': 1606, 'bush': 1607, 'widely': 1608, 'begun': 1609, 'decay': 1610, 'pole': 1611, 'cliff': 1612, 'vertical': 1613, 'crushed': 1614, 'enemies': 1615, 'sail': 1616, 'bombay': 1617, 'resolved': 1618, 'rodica': 1619, 'fifth': 1620, 'island': 1621, 'concealed': 1622, 'accustomed': 1623, 'costly': 1624, 'purchases': 1625, 'toward': 1626, 'within': 1627, 'disturbed': 1628, 'bear': 1629, 'sundays': 1630, 'reasonable': 1631, 'basketball': 1632, 'escaped': 1633, 'dreams': 1634, 'seicho': 1635, 'matsumoto': 1636, 'withered': 1637, 'governed': 1638, 'finland': 1639, 'consider': 1640, 'intelligent': 1641, 'solve': 1642, 'mile': 1643, 'ours': 1644, 'slow': 1645, 'dad': 1646, 'shaving': 1647, 'bathroom': 1648, 'cheaper': 1649, 'fighting': 1650, 'settle': 1651, 'attention': 1652, 'walks': 1653, 'behavior': 1654, 'odd': 1655, 'bone': 1656, 'keys': 1657, 'wallet': 1658, 'motioned': 1659, 'folder': 1660, 'worrying': 1661, 'doable': 1662, 'politics': 1663, 'louder': 1664, 'remove': 1665, 'tries': 1666, 'pack': 1667, 'appearing': 1668, 'warned': 1669, 'string': 1670, 'occurs': 1671, 'frequently': 1672, 'raised': 1673, 'cloud': 1674, 'barking': 1675, 'moves': 1676, 'investigation': 1677, 'hunting': 1678, 'lions': 1679, 'carried': 1680, 'leather': 1681, 'goods': 1682, 'towels': 1683, 'church': 1684, 'sixteenth': 1685, 'graduated': 1686, 'forced': 1687, 'peace': 1688, 'author': 1689, 'dine': 1690, 'owe': 1691, 'apology': 1692, 'owner': 1693, 'solved': 1694, 'exports': 1695, 'wool': 1696, 'peasant': 1697, 'bet': 1698, 'stuff': 1699, 'heavily': 1700, 'properly': 1701, 'perhaps': 1702, 'pounds': 1703, 'gazed': 1704, 'apartment': 1705, 'discussing': 1706, 'strict': 1707, 'princess': 1708, 'crows': 1709, 'unless': 1710, 'ocean': 1711, 'hurried': 1712, 'boat': 1713, 'baggage': 1714, 'blame': 1715, 'wipe': 1716, 'conform': 1717, 'similar': 1718, 'rope': 1719, 'thrown': 1720, 'plans': 1721, 'detail': 1722, 'pressed': 1723, 'prompt': 1724, 'reply': 1725, 'bullet': 1726, 'weighed': 1727, 'stone': 1728, 'grandfather': 1729, 'housework': 1730, 'sin': 1731, 'anywhere': 1732, 'asking': 1733, 'visiting': 1734, 'oh': 1735, 'gas': 1736, 'billion': 1737, 'quite': 1738, 'accidental': 1739, 'pardon': 1740, 'raise': 1741, 'funds': 1742, 'gladly': 1743, 'proposal': 1744, 'younger': 1745, 'remained': 1746, 'stamps': 1747, 'stripped': 1748, 'conference': 1749, 'aware': 1750, 'shooting': 1751, 'several': 1752, 'flat': 1753, 'planted': 1754, 'cave': 1755, 'tie': 1756, 'suit': 1757, 'hotel': 1758, 'beatles': 1759, 'chat': 1760, 'squirrel': 1761, 'branches': 1762, 'fallen': 1763, 'coincidentally': 1764, 'elephants': 1765, 'asia': 1766, 'neither': 1767, 'sadness': 1768, 'pigeons': 1769, 'experiment': 1770, 'cash': 1771, 'fool': 1772, 'ability': 1773, 'ignore': 1774, 'neat': 1775, 'piece': 1776, 'prided': 1777, 'accompany': 1778, 'fewer': 1779, 'harm': 1780, 'exemplary': 1781, 'performance': 1782, 'p': 1783, 'exactly': 1784, 'parallel': 1785, 'besides': 1786, 'worth': 1787, 'shared': 1788, 'profit': 1789, 'elephant': 1790, 'dislike': 1791, 'bern': 1792, 'switzerland': 1793, 'classmates': 1794, 'comfort': 1795, 'faults': 1796, 'reverse': 1797, 'neighborhood': 1798, 'sense': 1799, 'rebellion': 1800, 'faster': 1801, 'rescued': 1802, 'sandwiches': 1803, 'remain': 1804, 'naughty': 1805, 'haste': 1806, 'repair': 1807, 'group': 1808, 'actress': 1809, 'dishes': 1810, 'germany': 1811, 'wings': 1812, 'golf': 1813, 'cleared': 1814, 'ghosts': 1815, 'preparing': 1816, 'planting': 1817, 'profession': 1818, 'cradle': 1819, 'holding': 1820, 'hole': 1821, 'deprived': 1822, 'mystery': 1823, 'remains': 1824, 'unsolved': 1825, 'discussed': 1826, 'clever': 1827, 'newspaper': 1828, 'matters': 1829, 'land': 1830, 'moon': 1831, 'eager': 1832, 'wooden': 1833, 'buildings': 1834, 'opening': 1835, 'loyalty': 1836, 'century': 1837, 'laugh': 1838, 'extend': 1839, 'helps': 1840, 'russian': 1841, 'sentence': 1842, 'seemed': 1843, 'ignorance': 1844, 'stuck': 1845, 'oxford': 1846, 'university': 1847, 'cemetery': 1848, 'jogging': 1849, 'innocent': 1850, 'complains': 1851, 'daytime': 1852, 'ninth': 1853, 'completely': 1854, 'unfounded': 1855, 'approached': 1856, 'equal': 1857, 'hour': 1858, 'match': 1859, 'brown': 1860, 'stabbed': 1861, 'agreement': 1862, 'managed': 1863, 'genuine': 1864, 'thick': 1865, 'mist': 1866, 'countryside': 1867, 'quitting': 1868, 'buddhism': 1869, 'beginnings': 1870, 'classical': 1871, 'bones': 1872, 'leg': 1873, 'impatient': 1874, 'gently': 1875, 'shoulder': 1876, 'grows': 1877, 'wiped': 1878, 'sweat': 1879, 'forehead': 1880, 'follows': 1881, 'scale': 1882, 'amazed': 1883, 'scared': 1884, 'anchorage': 1885, 'ache': 1886, 'imagine': 1887, 'earlier': 1888, 'complained': 1889, 'rudeness': 1890, 'prepared': 1891, 'pretending': 1892, 'fifteen': 1893, 'dug': 1894, 'treasure': 1895, 'denied': 1896, 'type': 1897, 'attended': 1898, 'exhibited': 1899, 'remorse': 1900, 'crime': 1901, 'failure': 1902, 'board': 1903, 'childhood': 1904, 'mohan': 1905, 'acquainted': 1906, 'sofa': 1907, 'veracity': 1908, 'unicycle': 1909, 'umbrella': 1910, 'phrase': 1911, 'mom': 1912, 'keeps': 1913, 'peacefully': 1914, 'sickness': 1915, 'sound': 1916, 'beast': 1917, 'patrolling': 1918, 'trying': 1919, 'persuade': 1920, 'charged': 1921, 'directions': 1922, 'cloth': 1923, 'silky': 1924, 'driven': 1925, 'electricity': 1926, 'unused': 1927, 'pink': 1928, 'remote': 1929, 'control': 1930, 'embezzled': 1931, 'employees': 1932, 'stories': 1933, 'cooking': 1934, 'fully': 1935, 'innocence': 1936, 'american': 1937, 'literature': 1938, 'obliged': 1939, 'youngster': 1940, 'pair': 1941, 'scissors': 1942, 'debt': 1943, 'drop': 1944, 'consented': 1945, 'suffers': 1946, 'headaches': 1947, 'miracle': 1948, 'save': 1949, 'reminds': 1950, 'pianist': 1951, 'scar': 1952, 'cheek': 1953, 'completed': 1954, 'smartest': 1955, 'proverb': 1956, 'turning': 1957, 'volume': 1958, 'nerve': 1959, 'results': 1960, 'excellent': 1961, 'cure': 1962, 'mood': 1963, 'cows': 1964, 'sacred': 1965, 'hardships': 1966, 'price': 1967, 'wares': 1968, 'poet': 1969, 'destined': 1970, 'adding': 1971, 'salt': 1972, 'concert': 1973, 'pronounce': 1974, 'angels': 1975, 'addicted': 1976, 'chocolate': 1977, 'ice': 1978, 'cream': 1979, 'straight': 1980, 'matches': 1981, 'everywhere': 1982, 'forward': 1983, 'named': 1984, 'rainbow': 1985, 'burglar': 1986, 'satisfying': 1987, 'spoiled': 1988, 'prison': 1989, 'calm': 1990, 'film': 1991, 'punished': 1992, 'break': 1993, 'spit': 1994, 'identify': 1995, 'recognized': 1996, 'defeated': 1997, 'opponent': 1998, 'election': 1999, 'expectations': 2000, 'release': 2001, 'prisoners': 2002, 'rely': 2003, 'watched': 2004, 'beginning': 2005, 'materials': 2006, 'acquaintance': 2007, 'woods': 2008, 'strangers': 2009, 'heavy': 2010, 'bakery': 2011, 'cute': 2012, 'lady': 2013, 'granddaughter': 2014, 'calls': 2015, 'drastic': 2016, 'measures': 2017, 'penalty': 2018, 'continent': 2019, 'cured': 2020, 'discovered': 2021, 'brave': 2022, 'act': 2023, 'pickpocketing': 2024, 'breath': 2025, 'operate': 2026, 'electrical': 2027, 'engineer': 2028, 'erase': 2029, 'wondering': 2030, 'definite': 2031, 'carelessness': 2032, 'qutub': 2033, 'minar': 2034, 'fort': 2035, 'farmer': 2036, 'toudaiji': 2037, 'spending': 2038, 'hokkaido': 2039, 'blanket': 2040, 'growing': 2041, 'poorer': 2042, 'obvious': 2043, 'main': 2044, 'object': 2045, 'climate': 2046, 'congratulate': 2047, 'engagement': 2048, 'possession': 2049, 'respect': 2050, 'vocabulary': 2051, 'amend': 2052, 'constitution': 2053, 'holiday': 2054, 'hold': 2055, 'carries': 2056, 'seeds': 2057, 'distances': 2058, 'clouds': 2059, 'furnished': 2060, 'originally': 2061, 'journey': 2062, 'investigated': 2063, 'angles': 2064, 'photocopier': 2065, 'requires': 2066, 'madman': 2067, 'accountable': 2068, 'actions': 2069, 'rubber': 2070, 'bounces': 2071, 'elastic': 2072, 'british': 2073, 'citizen': 2074, 'becoming': 2075, 'artist': 2076, 'closing': 2077, 'spends': 2078, 'entirely': 2079, 'heap': 2080, 'theater': 2081, 'woke': 2082, 'middle': 2083, 'reforming': 2084, 'male': 2085, 'peacock': 2086, 'colorful': 2087, 'tail': 2088, 'feathers': 2089, 'leading': 2090, 'cursed': 2091, 'finding': 2092, 'waking': 2093, 'opposite': 2094, 'seats': 2095, 'occur': 2096, 'windows': 2097, 'copyrighted': 2098, 'sources': 2099, 'balance': 2100, 'allowances': 2101, 'oppose': 2102, 'whom': 2103, 'pouring': 2104, 'lift': 2105, 'mt': 2106, 'everest': 2107, 'highest': 2108, 'peak': 2109, 'poured': 2110, 'washing': 2111, 'enter': 2112, 'classroom': 2113, 'careless': 2114, 'driving': 2115, 'factory': 2116, 'cease': 2117, 'operations': 2118, 'alarm': 2119, 'throughout': 2120, 'observed': 2121, 'eventually': 2122, 'fined': 2123, 'illegal': 2124, 'parking': 2125, 'distinguish': 2126, 'granted': 2127, 'wins': 2128, 'receive': 2129, 'gives': 2130, 'innumerable': 2131, 'contact': 2132, 'alphabet': 2133, 'hang': 2134, 'given': 2135, 'advertise': 2136, 'biggest': 2137, 'source': 2138, 'inspiration': 2139, 'hesitate': 2140, 'drug': 2141, 'smuggler': 2142, 'side': 2143, 'fortunate': 2144, 'loving': 2145, 'presents': 2146, 'switch': 2147, 'member': 2148, 'commit': 2149, 'suicide': 2150, 'upon': 2151, 'weekend': 2152, 'waist': 2153, 'britain': 2154, 'located': 2155, 'towns': 2156, 'grapes': 2157, 'sour': 2158, 'booted': 2159, 'foreigners': 2160, 'customers': 2161, 'independent': 2162, 'softer': 2163, 'report': 2164, 'resting': 2165, 'elected': 2166, 'frankly': 2167, 'reminded': 2168, 'parcel': 2169, 'translate': 2170, 'phrases': 2171, 'ease': 2172, 'searching': 2173, 'exist': 2174, 'immediately': 2175, 'private': 2176, 'acquaintances': 2177, 'reform': 2178, 'laws': 2179, 'above': 2180, 'sixth': 2181, 'floor': 2182, 'superior': 2183, 'popular': 2184, 'exchange': 2185, 'sweater': 2186, 'u': 2187, 'contracted': 2188, 'malaria': 2189, 'property': 2190, 'slept': 2191, 'thames': 2192, 'distributed': 2193, 'returning': 2194, 'weren': 2195, 'swear': 2196, 'decide': 2197, 'freedom': 2198, 'objected': 2199, 'removing': 2200, 'chatting': 2201, 'seventh': 2202, 'noisy': 2203, 'encouraged': 2204, 'fulfill': 2205, 'ambitions': 2206, 'constantly': 2207, 'forgetting': 2208, 'seldom': 2209, 'theory': 2210, 'comprehend': 2211, 'surprise': 2212, 'emergency': 2213, 'polluted': 2214, 'atmosphere': 2215, 'reached': 2216, 'international': 2217, 'trade': 2218, 'vital': 2219, 'economies': 2220, 'richest': 2221, 'bat': 2222, 'balls': 2223, 'protection': 2224, 'kindness': 2225, 'dropped': 2226, 'photograph': 2227, 'developed': 2228, 'arrange': 2229, 'motorbike': 2230, 'helmet': 2231, 'dirty': 2232, 'repairing': 2233, 'industry': 2234, 'majority': 2235, 'voted': 2236, 'bill': 2237, 'aids': 2238, 'horrifyingly': 2239, 'parts': 2240, 'shower': 2241, 'drenched': 2242, 'skin': 2243, 'lakes': 2244, 'biwa': 2245, 'beforehand': 2246, 'maybe': 2247, 'unhappy': 2248, 'intend': 2249, 'kill': 2250, 'huge': 2251, 'snake': 2252, 'murdered': 2253, 'entrance': 2254, 'communicate': 2255, 'patience': 2256, 'succeeded': 2257, 'chain': 2258, 'bite': 2259, 'ventured': 2260, 'swallow': 2261, 'tablets': 2262, 'taj': 2263, 'mahal': 2264, 'seven': 2265, 'wonders': 2266, 'voyage': 2267, 'obtained': 2268, 'yield': 2269, 'percent': 2270, 'investment': 2271, 'pollute': 2272, 'conduct': 2273, 'columbus': 2274, 'argued': 2275, 'west': 2276, 'awake': 2277, 'introduced': 2278, 'barely': 2279, 'afford': 2280, 'essential': 2281, 'command': 2282, 'mumbai': 2283, 'indian': 2284, 'maharashtra': 2285, 'fishing': 2286, 'intends': 2287, 'devote': 2288, 'curing': 2289, 'wear': 2290, 'greatest': 2291, 'economic': 2292, 'powers': 2293, 'fifteenth': 2294, 'mobile': 2295, 'calculation': 2296, 'although': 2297, 'twins': 2298, 'interests': 2299, 'paid': 2300, 'dues': 2301, 'deliberately': 2302, 'ignored': 2303, 'seeing': 2304, 'authorities': 2305, 'hiding': 2306, 'facts': 2307, 'public': 2308, 'opened': 2309, 'smelt': 2310, 'imitation': 2311, 'diamonds': 2312, 'blowing': 2313, 'horn': 2314, 'demanded': 2315, 'copies': 2316, 'sheep': 2317, 'field': 2318, 'higher': 2319, 'wars': 2320, 'fisherman': 2321, 'exaggerated': 2322, 'corruption': 2323, 'sticking': 2324, 'cleaning': 2325, 'prepare': 2326, 'resembles': 2327, 'appearance': 2328, 'character': 2329, 'incident': 2330, 'electric': 2331, 'seeking': 2332, 'staring': 2333, 'ceiling': 2334, 'handful': 2335, 'peanuts': 2336, 'firm': 2337, 'bankruptcy': 2338, 'access': 2339, 'acknowledgement': 2340, 'services': 2341, 'twin': 2342, 'girls': 2343, 'alike': 2344, 'practice': 2345, 'laying': 2346, 'thieves': 2347, 'drawers': 2348, 'search': 2349, 'driver': 2350, 'license': 2351, 'eighteen': 2352, 'catholic': 2353, 'nun': 2354, 'george': 2355, 'washington': 2356, 'unites': 2357, 'states': 2358, 'view': 2359, 'daily': 2360, 'passengers': 2361, 'nearest': 2362, 'democracy': 2363, 'form': 2364, 'kid': 2365, 'touching': 2366, 'bugs': 2367, 'UNKNOWN': 2368}\n",
            "tf.Tensor(\n",
            "[[   1    8  589 ...    0    0    0]\n",
            " [   1   54  117 ...    0    0    0]\n",
            " [   1  147  270 ...    0    0    0]\n",
            " ...\n",
            " [   1    7   59 ...    0    0    0]\n",
            " [   1    7  109 ...    0    0    0]\n",
            " [   1   26 1346 ...    0    0    0]], shape=(64, 29), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index) + 1\n",
        "vocab_tar_size = len(targ_lang.word_index) + 1\n",
        "\n",
        "print(\"vocab_inp_size: {}\".format(vocab_inp_size))\n",
        "print(\"vocab_tar_size: {}\".format(vocab_tar_size))\n",
        "print(\"input word to index mapping: {}\".format(inp_lang.word_index))\n",
        "print(\"target word to index mapping: {}\".format(targ_lang.word_index))\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape\n",
        "\n",
        "print(example_input_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTunhWMKvK2C",
        "outputId": "d8278162-449c-43ea-83bf-7d8404a61f40",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 29, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDEA9WayvcVj",
        "outputId": "c7ba6e40-28b0-4c78-c0cc-f5a05e7ce4a6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "score shape: (64, 29, 1)\n",
            "attention_weights shape: (64, 29, 1)\n",
            "Values shape: (64, 29, 1024)\n",
            "Score shape: (64, 29, 1)\n",
            "context_vector shape: (64, 29, 1024)\n",
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 29, 1)\n"
          ]
        }
      ],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    \n",
        "    print(\"score shape: {}\".format(score.shape))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    print(\"attention_weights shape: {}\".format(attention_weights.shape))\n",
        "    print(\"Values shape: {}\".format(values.shape))\n",
        "    print(\"Score shape: {}\".format(score.shape))\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    print(\"context_vector shape: {}\".format(context_vector.shape))\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xRSQXnOxocS",
        "outputId": "a006399e-87b9-4fd1-f315-3e5e313f2f2b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attention_weights shape: (64, 1, 29)\n",
            "Values shape: (64, 29, 1024)\n",
            "Score shape: (64, 1, 29)\n",
            "context_vector shape: (64, 29, 1024)\n",
            "Dot product Attention result shape: (batch size, units) (64, 1024)\n",
            "Dot product Attention weights shape: (batch_size, sequence_length, 1) (64, 1, 29)\n"
          ]
        }
      ],
      "source": [
        "class Dotproductattention(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(Dotproductattention,self).__init__()\n",
        "    # self.W1 = tf.keras.layers.Dense(units)\n",
        "    # self.W2 = tf.keras.layers.Dense(units)\n",
        "    # self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # print(\"query_with_time_axis shape: {}\".format(query_with_time_axis.shape))\n",
        "    # print(\"values shape: {}\".format(values.shape))\n",
        "    # print(\"query_with_time_axis T shape: {}\".format(tf.transpose(query_with_time_axis,[0,2,1]).shape))\n",
        "\n",
        "    score = tf.matmul(query_with_time_axis,tf.transpose(values,[0,2,1]))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    print(\"attention_weights shape: {}\".format(attention_weights.shape))\n",
        "    print(\"Values shape: {}\".format(values.shape))\n",
        "    print(\"Score shape: {}\".format(score.shape))\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = tf.transpose(attention_weights,[0,2,1]) *  values #tf.transpose(values,[0,2,1]) #values\n",
        "\n",
        "    print(\"context_vector shape: {}\".format(context_vector.shape))\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "attention_layer = Dotproductattention()\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Dot product Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Dot product Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaMnJsYS1P12",
        "outputId": "fbf7ce18-3c5a-435b-f53b-f3cf1c6720d0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dot product Attention result shape: (batch size, units) (64, 1024)\n",
            "Dot product Attention weights shape: (batch_size, sequence_length, 1) (64, 1, 29)\n"
          ]
        }
      ],
      "source": [
        "class Luongattention(tf.keras.layers.Layer):\n",
        "  def __init__(self,units):\n",
        "    super(Luongattention,self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # print(\"query_with_time_axis shape: {}\".format(query_with_time_axis.shape))\n",
        "    # print(\"values shape: {}\".format(values.shape))\n",
        "    # print(\"query_with_time_axis T shape: {}\".format(tf.transpose(query_with_time_axis,[0,2,1]).shape))\n",
        "\n",
        "    #print(\"shape self.W1(values) : {}\".format(self.W1(values).shape))\n",
        "\n",
        "    #score = tf.matmul(query_with_time_axis,tf.transpose(values,[0,2,1]))\n",
        "    score = tf.matmul(query_with_time_axis,tf.transpose(self.W1(values),[0,2,1]))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = tf.transpose(attention_weights,[0,2,1]) * values #values \n",
        "\n",
        "    #print(\"context_vector shape: {}\".format(context_vector.shape))\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "attention_layer = Luongattention(1024) # should it fixed to 1024\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Dot product Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Dot product Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZXF0fHM7Vul",
        "outputId": "9e089365-1a7f-4016-ca80-1d2475c87185",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 2369)\n"
          ]
        }
      ],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz,attention_type=1):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # use for attention\n",
        "    if attention_type == 1:\n",
        "      self.attention = BahdanauAttention(self.dec_units)     \n",
        "    elif attention_type == 2:\n",
        "      self.attention = Dotproductattention()    \n",
        "    else:\n",
        "      self.attention = Luongattention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden,enc_output )\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    #print(\"x.shape: \",x.shape)\n",
        "    #print(\"tf.expand_dims(context_vector, 1): \",tf.expand_dims(context_vector, 1).shape)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    #print(\"output: \",output.shape)\n",
        "    #print(\"state: \",state.shape)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n",
        "\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE,3)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "JvtyskWGvu_w",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCsDQaDrv7On",
        "outputId": "ee89c868-5332-440b-ee73-73c0c12cc313",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.3780\n",
            "Epoch 1 Loss 1.6890\n",
            "Time taken for 1 epoch 35.49098491668701 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5374\n",
            "Epoch 2 Loss 1.3571\n",
            "Time taken for 1 epoch 8.110131740570068 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.2074\n",
            "Epoch 3 Loss 1.1573\n",
            "Time taken for 1 epoch 7.634407043457031 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.1008\n",
            "Epoch 4 Loss 0.9954\n",
            "Time taken for 1 epoch 7.991867303848267 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.8074\n",
            "Epoch 5 Loss 0.8409\n",
            "Time taken for 1 epoch 7.44383430480957 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.7901\n",
            "Epoch 6 Loss 0.6956\n",
            "Time taken for 1 epoch 7.824387311935425 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.5222\n",
            "Epoch 7 Loss 0.5670\n",
            "Time taken for 1 epoch 7.365309476852417 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.3647\n",
            "Epoch 8 Loss 0.4618\n",
            "Time taken for 1 epoch 7.750938177108765 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.4031\n",
            "Epoch 9 Loss 0.3831\n",
            "Time taken for 1 epoch 7.338906526565552 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.2936\n",
            "Epoch 10 Loss 0.3212\n",
            "Time taken for 1 epoch 7.76426887512207 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.2367\n",
            "Epoch 11 Loss 0.2658\n",
            "Time taken for 1 epoch 7.442473888397217 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.2565\n",
            "Epoch 12 Loss 0.2255\n",
            "Time taken for 1 epoch 7.802751064300537 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.1964\n",
            "Epoch 13 Loss 0.1948\n",
            "Time taken for 1 epoch 7.474331378936768 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.1348\n",
            "Epoch 14 Loss 0.1665\n",
            "Time taken for 1 epoch 7.8764495849609375 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.1433\n",
            "Epoch 15 Loss 0.1446\n",
            "Time taken for 1 epoch 7.506110191345215 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.1289\n",
            "Epoch 16 Loss 0.1216\n",
            "Time taken for 1 epoch 7.840245008468628 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.1029\n",
            "Epoch 17 Loss 0.1038\n",
            "Time taken for 1 epoch 7.450676679611206 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0840\n",
            "Epoch 18 Loss 0.0917\n",
            "Time taken for 1 epoch 7.790608167648315 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0836\n",
            "Epoch 19 Loss 0.0816\n",
            "Time taken for 1 epoch 7.404869556427002 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0621\n",
            "Epoch 20 Loss 0.0739\n",
            "Time taken for 1 epoch 7.776110887527466 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.0654\n",
            "Epoch 21 Loss 0.0651\n",
            "Time taken for 1 epoch 7.396845102310181 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.0454\n",
            "Epoch 22 Loss 0.0587\n",
            "Time taken for 1 epoch 7.794036149978638 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.0503\n",
            "Epoch 23 Loss 0.0523\n",
            "Time taken for 1 epoch 7.44913649559021 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.0397\n",
            "Epoch 24 Loss 0.0488\n",
            "Time taken for 1 epoch 7.818335771560669 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.0514\n",
            "Epoch 25 Loss 0.0449\n",
            "Time taken for 1 epoch 7.449167251586914 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 0.0267\n",
            "Epoch 26 Loss 0.0419\n",
            "Time taken for 1 epoch 7.813506841659546 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 0.0302\n",
            "Epoch 27 Loss 0.0399\n",
            "Time taken for 1 epoch 7.40395712852478 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 0.0362\n",
            "Epoch 28 Loss 0.0370\n",
            "Time taken for 1 epoch 7.801711797714233 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.0316\n",
            "Epoch 29 Loss 0.0346\n",
            "Time taken for 1 epoch 7.441738843917847 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.0246\n",
            "Epoch 30 Loss 0.0317\n",
            "Time taken for 1 epoch 7.815957069396973 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 0.0344\n",
            "Epoch 31 Loss 0.0318\n",
            "Time taken for 1 epoch 7.4160590171813965 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 0.0197\n",
            "Epoch 32 Loss 0.0308\n",
            "Time taken for 1 epoch 7.78398871421814 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 0.0267\n",
            "Epoch 33 Loss 0.0304\n",
            "Time taken for 1 epoch 7.403695344924927 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 0.0243\n",
            "Epoch 34 Loss 0.0287\n",
            "Time taken for 1 epoch 7.770814895629883 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 0.0203\n",
            "Epoch 35 Loss 0.0290\n",
            "Time taken for 1 epoch 7.422357559204102 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 0.0246\n",
            "Epoch 36 Loss 0.0274\n",
            "Time taken for 1 epoch 7.784008026123047 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 0.0208\n",
            "Epoch 37 Loss 0.0267\n",
            "Time taken for 1 epoch 7.405677556991577 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 0.0184\n",
            "Epoch 38 Loss 0.0255\n",
            "Time taken for 1 epoch 7.781260251998901 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 0.0273\n",
            "Epoch 39 Loss 0.0261\n",
            "Time taken for 1 epoch 7.3944220542907715 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 0.0290\n",
            "Epoch 40 Loss 0.0244\n",
            "Time taken for 1 epoch 7.887268304824829 sec\n",
            "\n",
            "Epoch 41 Batch 0 Loss 0.0184\n",
            "Epoch 41 Loss 0.0259\n",
            "Time taken for 1 epoch 7.408754348754883 sec\n",
            "\n",
            "Epoch 42 Batch 0 Loss 0.0166\n",
            "Epoch 42 Loss 0.0249\n",
            "Time taken for 1 epoch 7.833114147186279 sec\n",
            "\n",
            "Epoch 43 Batch 0 Loss 0.0124\n",
            "Epoch 43 Loss 0.0251\n",
            "Time taken for 1 epoch 7.418580770492554 sec\n",
            "\n",
            "Epoch 44 Batch 0 Loss 0.0172\n",
            "Epoch 44 Loss 0.0238\n",
            "Time taken for 1 epoch 7.795131683349609 sec\n",
            "\n",
            "Epoch 45 Batch 0 Loss 0.0210\n",
            "Epoch 45 Loss 0.0245\n",
            "Time taken for 1 epoch 7.425242900848389 sec\n",
            "\n",
            "Epoch 46 Batch 0 Loss 0.0302\n",
            "Epoch 46 Loss 0.0233\n",
            "Time taken for 1 epoch 7.8065345287323 sec\n",
            "\n",
            "Epoch 47 Batch 0 Loss 0.0210\n",
            "Epoch 47 Loss 0.0247\n",
            "Time taken for 1 epoch 7.426508665084839 sec\n",
            "\n",
            "Epoch 48 Batch 0 Loss 0.0297\n",
            "Epoch 48 Loss 0.0244\n",
            "Time taken for 1 epoch 7.780322790145874 sec\n",
            "\n",
            "Epoch 49 Batch 0 Loss 0.0138\n",
            "Epoch 49 Loss 0.0257\n",
            "Time taken for 1 epoch 7.413626670837402 sec\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.0202\n",
            "Epoch 50 Loss 0.0245\n",
            "Time taken for 1 epoch 7.798901796340942 sec\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.0266\n",
            "Epoch 51 Loss 0.0268\n",
            "Time taken for 1 epoch 7.395537614822388 sec\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.0316\n",
            "Epoch 52 Loss 0.0274\n",
            "Time taken for 1 epoch 7.806212902069092 sec\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.0235\n",
            "Epoch 53 Loss 0.0275\n",
            "Time taken for 1 epoch 7.427121877670288 sec\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.0217\n",
            "Epoch 54 Loss 0.0264\n",
            "Time taken for 1 epoch 7.787111043930054 sec\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.0256\n",
            "Epoch 55 Loss 0.0276\n",
            "Time taken for 1 epoch 7.418472528457642 sec\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.0298\n",
            "Epoch 56 Loss 0.0266\n",
            "Time taken for 1 epoch 7.836585521697998 sec\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.0199\n",
            "Epoch 57 Loss 0.0276\n",
            "Time taken for 1 epoch 7.396809101104736 sec\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.0347\n",
            "Epoch 58 Loss 0.0282\n",
            "Time taken for 1 epoch 7.736228942871094 sec\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.0203\n",
            "Epoch 59 Loss 0.0286\n",
            "Time taken for 1 epoch 7.3995521068573 sec\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.0254\n",
            "Epoch 60 Loss 0.0284\n",
            "Time taken for 1 epoch 7.807696580886841 sec\n",
            "\n",
            "Epoch 61 Batch 0 Loss 0.0304\n",
            "Epoch 61 Loss 0.0293\n",
            "Time taken for 1 epoch 7.400151491165161 sec\n",
            "\n",
            "Epoch 62 Batch 0 Loss 0.0231\n",
            "Epoch 62 Loss 0.0282\n",
            "Time taken for 1 epoch 7.766659736633301 sec\n",
            "\n",
            "Epoch 63 Batch 0 Loss 0.0257\n",
            "Epoch 63 Loss 0.0310\n",
            "Time taken for 1 epoch 7.388002395629883 sec\n",
            "\n",
            "Epoch 64 Batch 0 Loss 0.0131\n",
            "Epoch 64 Loss 0.0300\n",
            "Time taken for 1 epoch 7.774142503738403 sec\n",
            "\n",
            "Epoch 65 Batch 0 Loss 0.0180\n",
            "Epoch 65 Loss 0.0312\n",
            "Time taken for 1 epoch 7.368865966796875 sec\n",
            "\n",
            "Epoch 66 Batch 0 Loss 0.0410\n",
            "Epoch 66 Loss 0.0292\n",
            "Time taken for 1 epoch 7.779772758483887 sec\n",
            "\n",
            "Epoch 67 Batch 0 Loss 0.0139\n",
            "Epoch 67 Loss 0.0286\n",
            "Time taken for 1 epoch 7.394255876541138 sec\n",
            "\n",
            "Epoch 68 Batch 0 Loss 0.0319\n",
            "Epoch 68 Loss 0.0280\n",
            "Time taken for 1 epoch 7.794956922531128 sec\n",
            "\n",
            "Epoch 69 Batch 0 Loss 0.0168\n",
            "Epoch 69 Loss 0.0279\n",
            "Time taken for 1 epoch 7.390986919403076 sec\n",
            "\n",
            "Epoch 70 Batch 0 Loss 0.0317\n",
            "Epoch 70 Loss 0.0259\n",
            "Time taken for 1 epoch 7.762322425842285 sec\n",
            "\n",
            "Epoch 71 Batch 0 Loss 0.0206\n",
            "Epoch 71 Loss 0.0278\n",
            "Time taken for 1 epoch 7.411947011947632 sec\n",
            "\n",
            "Epoch 72 Batch 0 Loss 0.0324\n",
            "Epoch 72 Loss 0.0261\n",
            "Time taken for 1 epoch 7.77696967124939 sec\n",
            "\n",
            "Epoch 73 Batch 0 Loss 0.0405\n",
            "Epoch 73 Loss 0.0269\n",
            "Time taken for 1 epoch 7.415101051330566 sec\n",
            "\n",
            "Epoch 74 Batch 0 Loss 0.0188\n",
            "Epoch 74 Loss 0.0256\n",
            "Time taken for 1 epoch 7.75556492805481 sec\n",
            "\n",
            "Epoch 75 Batch 0 Loss 0.0213\n",
            "Epoch 75 Loss 0.0256\n",
            "Time taken for 1 epoch 7.406794786453247 sec\n",
            "\n",
            "Epoch 76 Batch 0 Loss 0.0148\n",
            "Epoch 76 Loss 0.0255\n",
            "Time taken for 1 epoch 7.756490230560303 sec\n",
            "\n",
            "Epoch 77 Batch 0 Loss 0.0280\n",
            "Epoch 77 Loss 0.0274\n",
            "Time taken for 1 epoch 7.394277095794678 sec\n",
            "\n",
            "Epoch 78 Batch 0 Loss 0.0220\n",
            "Epoch 78 Loss 0.0262\n",
            "Time taken for 1 epoch 7.757843494415283 sec\n",
            "\n",
            "Epoch 79 Batch 0 Loss 0.0210\n",
            "Epoch 79 Loss 0.0253\n",
            "Time taken for 1 epoch 7.4037024974823 sec\n",
            "\n",
            "Epoch 80 Batch 0 Loss 0.0254\n",
            "Epoch 80 Loss 0.0237\n",
            "Time taken for 1 epoch 7.7726922035217285 sec\n",
            "\n",
            "Epoch 81 Batch 0 Loss 0.0189\n",
            "Epoch 81 Loss 0.0240\n",
            "Time taken for 1 epoch 7.418550252914429 sec\n",
            "\n",
            "Epoch 82 Batch 0 Loss 0.0320\n",
            "Epoch 82 Loss 0.0237\n",
            "Time taken for 1 epoch 7.777967691421509 sec\n",
            "\n",
            "Epoch 83 Batch 0 Loss 0.0155\n",
            "Epoch 83 Loss 0.0244\n",
            "Time taken for 1 epoch 7.398994207382202 sec\n",
            "\n",
            "Epoch 84 Batch 0 Loss 0.0325\n",
            "Epoch 84 Loss 0.0247\n",
            "Time taken for 1 epoch 7.755829811096191 sec\n",
            "\n",
            "Epoch 85 Batch 0 Loss 0.0179\n",
            "Epoch 85 Loss 0.0253\n",
            "Time taken for 1 epoch 7.388503551483154 sec\n",
            "\n",
            "Epoch 86 Batch 0 Loss 0.0159\n",
            "Epoch 86 Loss 0.0236\n",
            "Time taken for 1 epoch 7.769258737564087 sec\n",
            "\n",
            "Epoch 87 Batch 0 Loss 0.0414\n",
            "Epoch 87 Loss 0.0257\n",
            "Time taken for 1 epoch 7.385871648788452 sec\n",
            "\n",
            "Epoch 88 Batch 0 Loss 0.0193\n",
            "Epoch 88 Loss 0.0237\n",
            "Time taken for 1 epoch 7.790806531906128 sec\n",
            "\n",
            "Epoch 89 Batch 0 Loss 0.0188\n",
            "Epoch 89 Loss 0.0254\n",
            "Time taken for 1 epoch 7.404717922210693 sec\n",
            "\n",
            "Epoch 90 Batch 0 Loss 0.0307\n",
            "Epoch 90 Loss 0.0246\n",
            "Time taken for 1 epoch 7.761132001876831 sec\n",
            "\n",
            "Epoch 91 Batch 0 Loss 0.0376\n",
            "Epoch 91 Loss 0.0249\n",
            "Time taken for 1 epoch 7.389974117279053 sec\n",
            "\n",
            "Epoch 92 Batch 0 Loss 0.0189\n",
            "Epoch 92 Loss 0.0241\n",
            "Time taken for 1 epoch 7.7589943408966064 sec\n",
            "\n",
            "Epoch 93 Batch 0 Loss 0.0146\n",
            "Epoch 93 Loss 0.0259\n",
            "Time taken for 1 epoch 7.4287190437316895 sec\n",
            "\n",
            "Epoch 94 Batch 0 Loss 0.0235\n",
            "Epoch 94 Loss 0.0233\n",
            "Time taken for 1 epoch 7.783734560012817 sec\n",
            "\n",
            "Epoch 95 Batch 0 Loss 0.0223\n",
            "Epoch 95 Loss 0.0258\n",
            "Time taken for 1 epoch 7.404337167739868 sec\n",
            "\n",
            "Epoch 96 Batch 0 Loss 0.0204\n",
            "Epoch 96 Loss 0.0237\n",
            "Time taken for 1 epoch 7.818178653717041 sec\n",
            "\n",
            "Epoch 97 Batch 0 Loss 0.0212\n",
            "Epoch 97 Loss 0.0250\n",
            "Time taken for 1 epoch 7.42230749130249 sec\n",
            "\n",
            "Epoch 98 Batch 0 Loss 0.0166\n",
            "Epoch 98 Loss 0.0241\n",
            "Time taken for 1 epoch 7.755590200424194 sec\n",
            "\n",
            "Epoch 99 Batch 0 Loss 0.0320\n",
            "Epoch 99 Loss 0.0250\n",
            "Time taken for 1 epoch 7.414089918136597 sec\n",
            "\n",
            "Epoch 100 Batch 0 Loss 0.0200\n",
            "Epoch 100 Loss 0.0243\n",
            "Time taken for 1 epoch 7.779242753982544 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    #print(\"inp shape: {} tar shape: {}\".format(inp.shape,targ.shape[1]))\n",
        "    #input()\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "HlRgCUIExZUY",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  \n",
        "  #inputs = [inp_lang.word_index[i] for i in sentence.split(' ')] #-  old code\n",
        "     \n",
        "  # Handle all the unknown words\n",
        "  inputs = list()\n",
        "  for i in sentence.split(' '):\n",
        "    try:\n",
        "      inputs.append(inp_lang.word_index[i])\n",
        "    except KeyError:\n",
        "      continue\n",
        "      #inputs.append()\n",
        "\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "eGj4sOWMxeqC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# function for plotting the attention weights\n",
        "#plt.rcParams['font.sans-serif'] = ['Source Han Sans TW', 'sans-serif']\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "  #hindi_font = FontProperties(fname = 'Nirmala.ttf')\n",
        "  #hindi_font = FontProperties(fname = 'Nirmala.ttf')\n",
        "  #plt.yticks(list(range(len(words))), words, color=\"b\", )\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence,rotation=90)\n",
        "  #ax.set_xticklabels([''] + sentence, rotation=90,fontproperties=hindi_font)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  #plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zLRAe85t0bV",
        "outputId": "e80cc438-51b6-42a7-efce-dbec72d9ab73",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: <start> जन्मदिन मुबारक हो ! <end>\n",
            "Predicted translation: happy birthday ! <end> \n"
          ]
        }
      ],
      "source": [
        "translate(u\"जन्मदिन मुबारक हो!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_NH9hztRxov5",
        "outputId": "5df23a55-e2cd-4386-b5e0-c549ab44d83a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: <start> बाहर निकल जाओ <end>\n",
            "Predicted translation: it s go out . <end> \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2344 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2354 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2332 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2323 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2348 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2366 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2344 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2367 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2325 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2354 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2332 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2323 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: <start> बाहर निकल जाओ <end>\n",
            "Predicted translation: it s go out . <end> \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "translate(u'बाहर निकल जाओ')\n",
        "translate(u'बाहर निकल जाओ')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "44qsDCn9svQw",
        "outputId": "261c0a06-d6e8-451b-ca56-34539eeb7f10",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: <start> सर्दी आ रही है। <end>\n",
            "Predicted translation: it s like to go to go to go to go to go to go to go to go to go to go to go to go to \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2360 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2381 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2342 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2368 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2310 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2376 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2360 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2352 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2381 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2342 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2368 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2310 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2361 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2376 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 2404 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "translate(u\"सर्दी आ रही है।\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61icBggSxz1i",
        "outputId": "a4650f88-e3e8-4945-d7d0-e7b23234e9a3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: <start> मेरा पेट भर गया है। <end>\n",
            "Predicted translation: i m full . <end> \n",
            "Input: <start> मैं १९६० में पैदा हुआ था। <end>\n",
            "Predicted translation: i was born in . <end> \n",
            "Input: <start> अंग्रेज़ी बोलना आसान नहीं है। <end>\n",
            "Predicted translation: speaking english isn t easy . <end> \n",
            "Input: <start> सौभाग्य न सब दिन सोता है , देखें आगे क्या होता है। <end>\n",
            "Predicted translation: it is true . <end> \n",
            "Input: <start> इसे पढ़ें दोबारा । <end>\n",
            "Predicted translation: i ve made it s go there . <end> \n",
            "Input: <start> कुछ मछलियाँ उड़ सकतीं हैं। <end>\n",
            "Predicted translation: few people live away . <end> \n",
            "Input: <start> तुम्हें मन लगाकर पढ़ना होगा। <end>\n",
            "Predicted translation: i ve read her room . <end> \n"
          ]
        }
      ],
      "source": [
        "# correct translation\n",
        "translate(u'मेरा पेट भर गया है।')\n",
        "translate(u'मैं १९६० में पैदा हुआ था।')\n",
        "translate(u'अंग्रेज़ी बोलना आसान नहीं है।')\n",
        "translate(u'सौभाग्य न सब दिन सोता है, देखें आगे क्या होता है।')\n",
        "translate(u'इसे पढ़ें दोबारा ।')\n",
        "translate(u'कुछ मछलियाँ उड़ सकतीं हैं।')\n",
        "translate(u\"तुम्हें मन लगाकर पढ़ना होगा।\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNBqdhto0TyB"
      },
      "source": [
        "Which parts of the sentence are used as a token? Each character, each word, or are some words split up?\n",
        "Do the same tokens in different language have the same ID?\n",
        "e.g. Would the same token index map to the German word die and to the English word die?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzzoSQeJ0YF9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Ans: Each Words are used as tokens. No. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj6qs8ol0bJx"
      },
      "source": [
        "What is the relation between the encoder output and the encoder hidden state which is used to initialize the decoder hidden state (for the architecture used in the tutorial)?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfJX-9VT0cq7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Ans: encoderoutput = a1 * h1 + a2 * h2 + .... + an * hn\n",
        "      where a1,a2,..,an are attention weights\n",
        "            h1,h2,...,hn are encoder hidden states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bet99nCQ22-0"
      },
      "source": [
        "Is the decoder attending to all previous positions, including the previous decoder predictions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRhfGe4y2vni",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Ans: Yes, decoder is attending all the previous positions of the encoder and only the last decoder predictied position."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FczeOIm00gGm"
      },
      "source": [
        "Does the Encoder output change in different decoding steps?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4YvmBhh0hGu",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "No, Encoder output doesn't changes at different decoding steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXy3DS9i0i0j"
      },
      "source": [
        "Does the context vector change in different decoding steps?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFRHufw-0kMR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Yes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTBhK9oO0nPb"
      },
      "source": [
        "The decoder uses teacher forcing. Does this mean the time steps can be computed in parallel?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odZ5WeeH0oWS",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "No. Since we have Recurrrence connection between decoder hidden state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzAjwyHa0p6M"
      },
      "source": [
        "Why is a mask applied to the loss function?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G3hn-1f0raC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Since we have a variable lenghth sequence , we do not calculate loss of the padded values in the sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAGNdGY50tDi"
      },
      "source": [
        "Bonus1: Can you prevent the attention mechanism from attending to padded positions in the sequence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytEeWMmX0yc4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjuMjCXL015q"
      },
      "source": [
        "Bonus2: The tutorial suggests to restore checkpoints for loading a model. This is inconvenient, because you first need to process the data, build the whole architecture and then initialize it from the checkpoint. It would be much nicer to simply load a model and run translations with it. Can you find a way to achieve this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I4NqW480LLm",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "https://www.tensorflow.org/guide/keras/save_and_serialize\n",
        "model.save\n",
        "keras.models.load_model('path/to/location')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment_7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
